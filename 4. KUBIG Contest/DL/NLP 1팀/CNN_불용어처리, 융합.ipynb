{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["LSTM "],"metadata":{"id":"NlVr__mr0k3-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9bpnjFq0c5E"},"outputs":[],"source":["inp = Input(shape=(maxlen,))\n","x = Embedding(49391, 300, weights=[embedding_matrix])(inp)\n","x = SpatialDropout1D(S_DROPOUT)(x)\n","x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n","avg_pool = GlobalAveragePooling1D()(x)\n","max_pool = GlobalMaxPooling1D()(x)\n","conc = concatenate([avg_pool, max_pool])\n","x = Dense(16, activation=\"relu\")(conc)\n","x = Dropout(DROPOUT)(x)\n","x = Dense(1, activation=\"sigmoid\")(x)\n","model = Model(inputs=inp, outputs=x)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n","model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))\n","pred_val_lstm_y = model.predict([val_X], batch_size=1024, verbose=1)\n","pred_test_lstm_y = model.predict([test_X], batch_size=1024, verbose=1)\n","del all_embs, model, inp, x\n","import gc; gc.collect()\n","time.sleep(10)"]},{"cell_type":"markdown","source":["CNN"],"metadata":{"id":"H3d9MQ_S0sQp"}},{"cell_type":"code","source":["from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n","from keras.layers.convolutional import Conv2D\n","import tensorflow as tf\n","from keras.layers import concatenate\n","def model_cnn(embedding_matrix):\n","    filter_sizes = [1,2,3,5]\n","    num_filters = 36\n","\n","    inp = Input(shape=(maxlen,))\n","    x = Embedding(34176, embed_size, weights=[embedding_matrix])(inp)\n","    x = Reshape((maxlen, embed_size, 1))(x)\n","\n","    maxpool_pool = []\n","    for i in range(len(filter_sizes)):\n","        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embed_size),\n","                                     kernel_initializer='he_normal', activation='elu')(x)\n","        maxpool_pool.append(tf.keras.layers.MaxPool2D(pool_size=(maxlen - filter_sizes[i] + 1, 1))(conv))\n","\n","    z = tf.keras.layers.Concatenate(axis=1)(maxpool_pool)   \n","    z = Flatten()(z)\n","    z = Dropout(0.1)(z)\n","\n","    outp = Dense(5, activation=\"sigmoid\")(z)\n","\n","    model = Model(inputs=inp, outputs=outp)\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    return model\n","\n","model = model_cnn(embedding_matrix)\n","model.summary()\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import Model\n","\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.layers import Input, Dense, BatchNormalization\n","from IPython.core.display import Image\n","keras.utils.plot_model(model, \"Document_Classification_Model.png\", show_shapes=True)\n","\n","model.fit(train_X, train_y, batch_size=512, epochs=4, validation_data=(val_X, val_y))\n","pred_val_cnn_y = model.predict([val_X], batch_size=1024, verbose=1)\n","pred_test_cnn_y = model.predict([test_X], batch_size=1024, verbose=1)\n","pred_test_cnn_y1 = np.round(pred_test_cnn_y,4)\n","\n","# del word_index, embedding_matrix, model, inp, x\n","import gc; gc.collect()\n","time.sleep(10)"],"metadata":{"id":"l-j5z3wS0tDn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mix two models"],"metadata":{"id":"U_--1nch08eb"}},{"cell_type":"code","source":["pred_val_y = 0.6 * pred_val_lstm_y + 0.4 * pred_val_cnn_y  # two random numbers :)\n","pred_test_y = 0.6 * pred_test_lstm_y + 0.4 * pred_test_cnn_y \n","sample1  = pd.read_csv(\"C:\\\\Users\\\\82107\\\\Downloads\\\\sample_submission.csv\", index_col=0)\n","sample1[sample1.columns] = pred_test_y\n","sample1.to_csv(\"C:\\\\Users\\\\82107\\\\Downloads\\\\submission3.csv\")"],"metadata":{"id":"U70eWKB_0-W7"},"execution_count":null,"outputs":[]}]}