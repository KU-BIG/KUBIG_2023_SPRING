{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinkyuRamen/KubigFinancialProject/blob/main/ky/FINRL_Application_KY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q_sBJhapy0I"
      },
      "source": [
        "## Prediction 없이"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4pQ_cvyHsy9H"
      },
      "source": [
        "### Package Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks2t8YRMpycx",
        "outputId": "0b4cafb5-ab41-42be-ef20-5d9cff3e6bba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ujdWOaWstCPL"
      },
      "source": [
        "### Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VvGt8QWfs8_H"
      },
      "outputs": [],
      "source": [
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KyNf4zQhtFTE",
        "outputId": "217e8465-53f2-411f-f457-ce76dddcc2b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2020-07-31'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from config.py, TRAIN_START_DATE is a string\n",
        "TRAIN_START_DATE\n",
        "# from config.py, TRAIN_END_DATE is a string\n",
        "TRAIN_END_DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E3BOB4cVtKCE"
      },
      "outputs": [],
      "source": [
        "TRAIN_START_DATE = '2010-01-01'\n",
        "TRAIN_END_DATE = '2021-10-01'\n",
        "TRADE_START_DATE = '2021-10-01'\n",
        "TRADE_END_DATE = '2023-05-05'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YPBNJIR9u3Ik"
      },
      "outputs": [],
      "source": [
        "tickers = ['XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJCRqPxOtVVP",
        "outputId": "0a97d095-3d7c-40af-fff6-c2780f6036bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (30213, 8)\n"
          ]
        }
      ],
      "source": [
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TRADE_END_DATE,\n",
        "                     ticker_list = tickers).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "T6Dgh-r9wosC",
        "outputId": "a43b4b28-8af6-4c9d-c285-18f0bd3205b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>33.580002</td>\n",
              "      <td>34.020000</td>\n",
              "      <td>33.450001</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>7567500</td>\n",
              "      <td>XLB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.919998</td>\n",
              "      <td>58.810001</td>\n",
              "      <td>57.790001</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>16928400</td>\n",
              "      <td>XLE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>11.795288</td>\n",
              "      <td>11.965881</td>\n",
              "      <td>11.770918</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>92942347</td>\n",
              "      <td>XLF</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>28.090000</td>\n",
              "      <td>28.320000</td>\n",
              "      <td>27.959999</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>7471500</td>\n",
              "      <td>XLI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>23.139999</td>\n",
              "      <td>23.290001</td>\n",
              "      <td>23.100000</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>8449400</td>\n",
              "      <td>XLK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30208</th>\n",
              "      <td>2023-05-04</td>\n",
              "      <td>147.660004</td>\n",
              "      <td>148.539993</td>\n",
              "      <td>146.929993</td>\n",
              "      <td>147.231598</td>\n",
              "      <td>5430500</td>\n",
              "      <td>XLK</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30209</th>\n",
              "      <td>2023-05-04</td>\n",
              "      <td>76.739998</td>\n",
              "      <td>76.860001</td>\n",
              "      <td>76.220001</td>\n",
              "      <td>75.931320</td>\n",
              "      <td>11682600</td>\n",
              "      <td>XLP</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30210</th>\n",
              "      <td>2023-05-04</td>\n",
              "      <td>68.190002</td>\n",
              "      <td>68.860001</td>\n",
              "      <td>67.550003</td>\n",
              "      <td>68.042702</td>\n",
              "      <td>14631100</td>\n",
              "      <td>XLU</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30211</th>\n",
              "      <td>2023-05-04</td>\n",
              "      <td>132.899994</td>\n",
              "      <td>132.979996</td>\n",
              "      <td>131.839996</td>\n",
              "      <td>131.857208</td>\n",
              "      <td>9625300</td>\n",
              "      <td>XLV</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30212</th>\n",
              "      <td>2023-05-04</td>\n",
              "      <td>145.410004</td>\n",
              "      <td>146.039993</td>\n",
              "      <td>144.039993</td>\n",
              "      <td>143.980392</td>\n",
              "      <td>5331500</td>\n",
              "      <td>XLY</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30213 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             date        open        high         low       close    volume  \\\n",
              "0      2010-01-04   33.580002   34.020000   33.450001   25.364527   7567500   \n",
              "1      2010-01-04   57.919998   58.810001   57.790001   37.747696  16928400   \n",
              "2      2010-01-04   11.795288   11.965881   11.770918    9.344016  92942347   \n",
              "3      2010-01-04   28.090000   28.320000   27.959999   21.793039   7471500   \n",
              "4      2010-01-04   23.139999   23.290001   23.100000   19.110195   8449400   \n",
              "...           ...         ...         ...         ...         ...       ...   \n",
              "30208  2023-05-04  147.660004  148.539993  146.929993  147.231598   5430500   \n",
              "30209  2023-05-04   76.739998   76.860001   76.220001   75.931320  11682600   \n",
              "30210  2023-05-04   68.190002   68.860001   67.550003   68.042702  14631100   \n",
              "30211  2023-05-04  132.899994  132.979996  131.839996  131.857208   9625300   \n",
              "30212  2023-05-04  145.410004  146.039993  144.039993  143.980392   5331500   \n",
              "\n",
              "       tic  day  \n",
              "0      XLB    0  \n",
              "1      XLE    0  \n",
              "2      XLF    0  \n",
              "3      XLI    0  \n",
              "4      XLK    0  \n",
              "...    ...  ...  \n",
              "30208  XLK    3  \n",
              "30209  XLP    3  \n",
              "30210  XLU    3  \n",
              "30211  XLV    3  \n",
              "30212  XLY    3  \n",
              "\n",
              "[30213 rows x 8 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SCGsiv7CxB33",
        "outputId": "1c0d5c26-ea01-43ae-be3e-cc28fbb4da06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>33.580002</td>\n",
              "      <td>34.020000</td>\n",
              "      <td>33.450001</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>7567500</td>\n",
              "      <td>XLB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.919998</td>\n",
              "      <td>58.810001</td>\n",
              "      <td>57.790001</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>16928400</td>\n",
              "      <td>XLE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>11.795288</td>\n",
              "      <td>11.965881</td>\n",
              "      <td>11.770918</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>92942347</td>\n",
              "      <td>XLF</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>28.090000</td>\n",
              "      <td>28.320000</td>\n",
              "      <td>27.959999</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>7471500</td>\n",
              "      <td>XLI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>23.139999</td>\n",
              "      <td>23.290001</td>\n",
              "      <td>23.100000</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>8449400</td>\n",
              "      <td>XLK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close    volume  tic  day\n",
              "0  2010-01-04  33.580002  34.020000  33.450001  25.364527   7567500  XLB    0\n",
              "1  2010-01-04  57.919998  58.810001  57.790001  37.747696  16928400  XLE    0\n",
              "2  2010-01-04  11.795288  11.965881  11.770918   9.344016  92942347  XLF    0\n",
              "3  2010-01-04  28.090000  28.320000  27.959999  21.793039   7471500  XLI    0\n",
              "4  2010-01-04  23.139999  23.290001  23.100000  19.110195   8449400  XLK    0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic'],ignore_index=True).head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I59mngP0w4DT"
      },
      "source": [
        "### ETF 도메인 별로 최적의 하이퍼 파라미터 튜닝을 진행해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIvKRzd0xqrC",
        "outputId": "7f0d192b-1661-4b91-a43b-710eeb07d59b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INDICATORS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jRoD98Wex-VP"
      },
      "source": [
        "INDICATORS는 FINRL 기본 베이스라인으로 해도 괜찮을 것 같음\n",
        "\n",
        "https://github.com/jealous/stockstats\n",
        "\n",
        "\n",
        "- change (in percent)\n",
        "- delta\n",
        "- permutation (zero-based)\n",
        "- log return\n",
        "- max in range\n",
        "- min in range\n",
        "- middle = (close + high + low) / 3\n",
        "- compare: le, ge, lt, gt, eq, ne\n",
        "- count: both backward(c) and forward(fc)\n",
        "- cross: including upward cross and downward cross\n",
        "- SMA: Simple Moving Average\n",
        "- EMA: Exponential Moving Average\n",
        "- MSTD: Moving Standard Deviation\n",
        "- MVAR: Moving Variance\n",
        "- RSV: Raw Stochastic Value\n",
        "- RSI: Relative Strength Index\n",
        "- KDJ: Stochastic Oscillator\n",
        "- Bolling: Bollinger Band\n",
        "- MACD: Moving Average Convergence Divergence\n",
        "- CR: Energy Index (Intermediate Willingness Index)\n",
        "- WR: Williams Overbought/Oversold index\n",
        "- CCI: Commodity Channel Index\n",
        "- TR: True Range\n",
        "- ATR: Average True Range\n",
        "- DMA: Different of Moving Average (10, 50)\n",
        "- DMI: Directional Moving Index, including\n",
        "- +DI: Positive Directional Indicator\n",
        "- -DI: Negative Directional Indicator\n",
        "- ADX: Average Directional Movement Index\n",
        "- ADXR: Smoothed Moving Average of ADX\n",
        "- TRIX: Triple Exponential Moving Average\n",
        "- TEMA: Another Triple Exponential Moving Average\n",
        "- VR: Volume Variation Index\n",
        "- MFI: Money Flow Index\n",
        "- VWMA: Volume Weighted Moving Average\n",
        "- CHOP: Choppiness Index\n",
        "- KAMA: Kaufman's Adaptive Moving Average\n",
        "- PPO: Percentage Price Oscillator\n",
        "- StochRSI: Stochastic RSI\n",
        "- WT: LazyBear's Wave Trend\n",
        "- Supertrend: with the Upper Band and Lower Band"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFpMwSyxwpUc",
        "outputId": "6c10eade-5730-4e98-f088-af9039b0b4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3356, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = INDICATORS,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "Btg_ORpzxjam",
        "outputId": "e3e123fd-ccd2-4d84-8193-d99c6a0f0527"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>33.580002</td>\n",
              "      <td>34.020000</td>\n",
              "      <td>33.450001</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>7567500</td>\n",
              "      <td>XLB</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.919998</td>\n",
              "      <td>58.810001</td>\n",
              "      <td>57.790001</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>16928400</td>\n",
              "      <td>XLE</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>11.795288</td>\n",
              "      <td>11.965881</td>\n",
              "      <td>11.770918</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>92942347</td>\n",
              "      <td>XLF</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>28.090000</td>\n",
              "      <td>28.320000</td>\n",
              "      <td>27.959999</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>7471500</td>\n",
              "      <td>XLI</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>23.139999</td>\n",
              "      <td>23.290001</td>\n",
              "      <td>23.100000</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>8449400</td>\n",
              "      <td>XLK</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30199</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>149.690002</td>\n",
              "      <td>150.660004</td>\n",
              "      <td>148.179993</td>\n",
              "      <td>147.940125</td>\n",
              "      <td>5815100</td>\n",
              "      <td>XLK</td>\n",
              "      <td>2</td>\n",
              "      <td>1.101266</td>\n",
              "      <td>151.344400</td>\n",
              "      <td>144.908068</td>\n",
              "      <td>55.182961</td>\n",
              "      <td>46.442993</td>\n",
              "      <td>6.225843</td>\n",
              "      <td>147.699630</td>\n",
              "      <td>143.517544</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30200</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>77.059998</td>\n",
              "      <td>77.379997</td>\n",
              "      <td>76.639999</td>\n",
              "      <td>76.119987</td>\n",
              "      <td>11656600</td>\n",
              "      <td>XLP</td>\n",
              "      <td>2</td>\n",
              "      <td>0.875702</td>\n",
              "      <td>77.189108</td>\n",
              "      <td>74.079747</td>\n",
              "      <td>58.998060</td>\n",
              "      <td>93.547472</td>\n",
              "      <td>22.508083</td>\n",
              "      <td>74.795711</td>\n",
              "      <td>73.269687</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30201</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>68.639999</td>\n",
              "      <td>69.050003</td>\n",
              "      <td>67.989998</td>\n",
              "      <td>67.526855</td>\n",
              "      <td>11857200</td>\n",
              "      <td>XLU</td>\n",
              "      <td>2</td>\n",
              "      <td>0.319781</td>\n",
              "      <td>69.807814</td>\n",
              "      <td>67.590043</td>\n",
              "      <td>50.161291</td>\n",
              "      <td>8.126302</td>\n",
              "      <td>8.132944</td>\n",
              "      <td>67.692193</td>\n",
              "      <td>66.656867</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30202</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>134.899994</td>\n",
              "      <td>133.270004</td>\n",
              "      <td>132.912888</td>\n",
              "      <td>8961500</td>\n",
              "      <td>XLV</td>\n",
              "      <td>2</td>\n",
              "      <td>0.915705</td>\n",
              "      <td>134.927106</td>\n",
              "      <td>131.520086</td>\n",
              "      <td>53.906948</td>\n",
              "      <td>54.096702</td>\n",
              "      <td>6.687990</td>\n",
              "      <td>131.318106</td>\n",
              "      <td>129.596837</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30203</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>145.940002</td>\n",
              "      <td>147.889999</td>\n",
              "      <td>145.279999</td>\n",
              "      <td>145.098145</td>\n",
              "      <td>4256000</td>\n",
              "      <td>XLY</td>\n",
              "      <td>2</td>\n",
              "      <td>0.418781</td>\n",
              "      <td>148.824533</td>\n",
              "      <td>143.067334</td>\n",
              "      <td>50.679820</td>\n",
              "      <td>23.335247</td>\n",
              "      <td>0.925005</td>\n",
              "      <td>145.369260</td>\n",
              "      <td>145.068298</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30204 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             date        open        high         low       close    volume  \\\n",
              "0      2010-01-04   33.580002   34.020000   33.450001   25.364527   7567500   \n",
              "1      2010-01-04   57.919998   58.810001   57.790001   37.747696  16928400   \n",
              "2      2010-01-04   11.795288   11.965881   11.770918    9.344016  92942347   \n",
              "3      2010-01-04   28.090000   28.320000   27.959999   21.793039   7471500   \n",
              "4      2010-01-04   23.139999   23.290001   23.100000   19.110195   8449400   \n",
              "...           ...         ...         ...         ...         ...       ...   \n",
              "30199  2023-05-03  149.690002  150.660004  148.179993  147.940125   5815100   \n",
              "30200  2023-05-03   77.059998   77.379997   76.639999   76.119987  11656600   \n",
              "30201  2023-05-03   68.639999   69.050003   67.989998   67.526855  11857200   \n",
              "30202  2023-05-03  134.259995  134.899994  133.270004  132.912888   8961500   \n",
              "30203  2023-05-03  145.940002  147.889999  145.279999  145.098145   4256000   \n",
              "\n",
              "       tic  day      macd     boll_ub     boll_lb      rsi_30     cci_30  \\\n",
              "0      XLB    0  0.000000   25.521516   25.289550  100.000000  66.666667   \n",
              "1      XLE    0  0.000000   25.521516   25.289550  100.000000  66.666667   \n",
              "2      XLF    0  0.000000   25.521516   25.289550  100.000000  66.666667   \n",
              "3      XLI    0  0.000000   25.521516   25.289550  100.000000  66.666667   \n",
              "4      XLK    0  0.000000   25.521516   25.289550  100.000000  66.666667   \n",
              "...    ...  ...       ...         ...         ...         ...        ...   \n",
              "30199  XLK    2  1.101266  151.344400  144.908068   55.182961  46.442993   \n",
              "30200  XLP    2  0.875702   77.189108   74.079747   58.998060  93.547472   \n",
              "30201  XLU    2  0.319781   69.807814   67.590043   50.161291   8.126302   \n",
              "30202  XLV    2  0.915705  134.927106  131.520086   53.906948  54.096702   \n",
              "30203  XLY    2  0.418781  148.824533  143.067334   50.679820  23.335247   \n",
              "\n",
              "            dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
              "0      100.000000     25.364527     25.364527  20.040001     0.00000  \n",
              "1      100.000000     37.747696     37.747696  20.040001     0.00000  \n",
              "2      100.000000      9.344016      9.344016  20.040001     0.00000  \n",
              "3      100.000000     21.793039     21.793039  20.040001     0.00000  \n",
              "4      100.000000     19.110195     19.110195  20.040001     0.00000  \n",
              "...           ...           ...           ...        ...         ...  \n",
              "30199    6.225843    147.699630    143.517544  18.340000     4.21999  \n",
              "30200   22.508083     74.795711     73.269687  18.340000     4.21999  \n",
              "30201    8.132944     67.692193     66.656867  18.340000     4.21999  \n",
              "30202    6.687990    131.318106    129.596837  18.340000     4.21999  \n",
              "30203    0.925005    145.369260    145.068298  18.340000     4.21999  \n",
              "\n",
              "[30204 rows x 18 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "4EFU1ksJyFNc",
        "outputId": "a4c0c02e-7a59-4ec2-8b50-fe3a1430c4f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>XLB</td>\n",
              "      <td>33.580002</td>\n",
              "      <td>34.020000</td>\n",
              "      <td>33.450001</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>7567500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>25.364527</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>XLE</td>\n",
              "      <td>57.919998</td>\n",
              "      <td>58.810001</td>\n",
              "      <td>57.790001</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>16928400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>37.747696</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>XLF</td>\n",
              "      <td>11.795288</td>\n",
              "      <td>11.965881</td>\n",
              "      <td>11.770918</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>92942347.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>9.344016</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>XLI</td>\n",
              "      <td>28.090000</td>\n",
              "      <td>28.320000</td>\n",
              "      <td>27.959999</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>7471500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>21.793039</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>XLK</td>\n",
              "      <td>23.139999</td>\n",
              "      <td>23.290001</td>\n",
              "      <td>23.100000</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>8449400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.521516</td>\n",
              "      <td>25.289550</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>19.110195</td>\n",
              "      <td>20.040001</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43807</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>XLK</td>\n",
              "      <td>149.690002</td>\n",
              "      <td>150.660004</td>\n",
              "      <td>148.179993</td>\n",
              "      <td>147.940125</td>\n",
              "      <td>5815100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.101266</td>\n",
              "      <td>151.344400</td>\n",
              "      <td>144.908068</td>\n",
              "      <td>55.182961</td>\n",
              "      <td>46.442993</td>\n",
              "      <td>6.225843</td>\n",
              "      <td>147.699630</td>\n",
              "      <td>143.517544</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43808</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>XLP</td>\n",
              "      <td>77.059998</td>\n",
              "      <td>77.379997</td>\n",
              "      <td>76.639999</td>\n",
              "      <td>76.119987</td>\n",
              "      <td>11656600.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.875702</td>\n",
              "      <td>77.189108</td>\n",
              "      <td>74.079747</td>\n",
              "      <td>58.998060</td>\n",
              "      <td>93.547472</td>\n",
              "      <td>22.508083</td>\n",
              "      <td>74.795711</td>\n",
              "      <td>73.269687</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43809</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>XLU</td>\n",
              "      <td>68.639999</td>\n",
              "      <td>69.050003</td>\n",
              "      <td>67.989998</td>\n",
              "      <td>67.526855</td>\n",
              "      <td>11857200.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.319781</td>\n",
              "      <td>69.807814</td>\n",
              "      <td>67.590043</td>\n",
              "      <td>50.161291</td>\n",
              "      <td>8.126302</td>\n",
              "      <td>8.132944</td>\n",
              "      <td>67.692193</td>\n",
              "      <td>66.656867</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43810</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>XLV</td>\n",
              "      <td>134.259995</td>\n",
              "      <td>134.899994</td>\n",
              "      <td>133.270004</td>\n",
              "      <td>132.912888</td>\n",
              "      <td>8961500.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.915705</td>\n",
              "      <td>134.927106</td>\n",
              "      <td>131.520086</td>\n",
              "      <td>53.906948</td>\n",
              "      <td>54.096702</td>\n",
              "      <td>6.687990</td>\n",
              "      <td>131.318106</td>\n",
              "      <td>129.596837</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43811</th>\n",
              "      <td>2023-05-03</td>\n",
              "      <td>XLY</td>\n",
              "      <td>145.940002</td>\n",
              "      <td>147.889999</td>\n",
              "      <td>145.279999</td>\n",
              "      <td>145.098145</td>\n",
              "      <td>4256000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.418781</td>\n",
              "      <td>148.824533</td>\n",
              "      <td>143.067334</td>\n",
              "      <td>50.679820</td>\n",
              "      <td>23.335247</td>\n",
              "      <td>0.925005</td>\n",
              "      <td>145.369260</td>\n",
              "      <td>145.068298</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>4.21999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30204 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             date  tic        open        high         low       close  \\\n",
              "0      2010-01-04  XLB   33.580002   34.020000   33.450001   25.364527   \n",
              "1      2010-01-04  XLE   57.919998   58.810001   57.790001   37.747696   \n",
              "2      2010-01-04  XLF   11.795288   11.965881   11.770918    9.344016   \n",
              "3      2010-01-04  XLI   28.090000   28.320000   27.959999   21.793039   \n",
              "4      2010-01-04  XLK   23.139999   23.290001   23.100000   19.110195   \n",
              "...           ...  ...         ...         ...         ...         ...   \n",
              "43807  2023-05-03  XLK  149.690002  150.660004  148.179993  147.940125   \n",
              "43808  2023-05-03  XLP   77.059998   77.379997   76.639999   76.119987   \n",
              "43809  2023-05-03  XLU   68.639999   69.050003   67.989998   67.526855   \n",
              "43810  2023-05-03  XLV  134.259995  134.899994  133.270004  132.912888   \n",
              "43811  2023-05-03  XLY  145.940002  147.889999  145.279999  145.098145   \n",
              "\n",
              "           volume  day      macd     boll_ub     boll_lb      rsi_30  \\\n",
              "0       7567500.0  0.0  0.000000   25.521516   25.289550  100.000000   \n",
              "1      16928400.0  0.0  0.000000   25.521516   25.289550  100.000000   \n",
              "2      92942347.0  0.0  0.000000   25.521516   25.289550  100.000000   \n",
              "3       7471500.0  0.0  0.000000   25.521516   25.289550  100.000000   \n",
              "4       8449400.0  0.0  0.000000   25.521516   25.289550  100.000000   \n",
              "...           ...  ...       ...         ...         ...         ...   \n",
              "43807   5815100.0  2.0  1.101266  151.344400  144.908068   55.182961   \n",
              "43808  11656600.0  2.0  0.875702   77.189108   74.079747   58.998060   \n",
              "43809  11857200.0  2.0  0.319781   69.807814   67.590043   50.161291   \n",
              "43810   8961500.0  2.0  0.915705  134.927106  131.520086   53.906948   \n",
              "43811   4256000.0  2.0  0.418781  148.824533  143.067334   50.679820   \n",
              "\n",
              "          cci_30       dx_30  close_30_sma  close_60_sma        vix  \\\n",
              "0      66.666667  100.000000     25.364527     25.364527  20.040001   \n",
              "1      66.666667  100.000000     37.747696     37.747696  20.040001   \n",
              "2      66.666667  100.000000      9.344016      9.344016  20.040001   \n",
              "3      66.666667  100.000000     21.793039     21.793039  20.040001   \n",
              "4      66.666667  100.000000     19.110195     19.110195  20.040001   \n",
              "...          ...         ...           ...           ...        ...   \n",
              "43807  46.442993    6.225843    147.699630    143.517544  18.340000   \n",
              "43808  93.547472   22.508083     74.795711     73.269687  18.340000   \n",
              "43809   8.126302    8.132944     67.692193     66.656867  18.340000   \n",
              "43810  54.096702    6.687990    131.318106    129.596837  18.340000   \n",
              "43811  23.335247    0.925005    145.369260    145.068298  18.340000   \n",
              "\n",
              "       turbulence  \n",
              "0         0.00000  \n",
              "1         0.00000  \n",
              "2         0.00000  \n",
              "3         0.00000  \n",
              "4         0.00000  \n",
              "...           ...  \n",
              "43807     4.21999  \n",
              "43808     4.21999  \n",
              "43809     4.21999  \n",
              "43810     4.21999  \n",
              "43811     4.21999  \n",
              "\n",
              "[30204 rows x 18 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_ticker = processed[\"tic\"].unique().tolist() #ticker 리스트 불러오기\n",
        "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str)) #전체 데이터 날짜 날짜 리스트\n",
        "combination = list(itertools.product(list_date,list_ticker)) #date, ticker 의 combination\n",
        "\n",
        "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\") #date, tic combination 기준으로 우측에 해당되는 정보들 정리\n",
        "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "processed_full = processed_full.fillna(0)\n",
        "processed_full"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kkdv2hgKzG_x"
      },
      "source": [
        "### Data split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "otTt2fmZzRy8"
      },
      "source": [
        "전체를 다 학습하면 안되는거 아닌가? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfK0AIhbzAea",
        "outputId": "68b7aaae-9a2e-4f6e-e13f-463417d0e565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26613\n",
            "3591\n"
          ]
        }
      ],
      "source": [
        "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
        "print(len(train))\n",
        "print(len(trade))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iBHgkPpp0zZk"
      },
      "source": [
        "### environment setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSJur4uLzIkR",
        "outputId": "6bcee5d8-b445-4f70-fcf2-b94814125235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 9, State Space: 91\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique()) \n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension #현재 상태를 나타내는 state를 정의. 1+ ticker 개수 x2 + 인디케이터 개수 x ticker개수 \n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c5eCtykc0ZUr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 179         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -0.198      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -22.2       |\n",
            "|    reward             | 0.120480224 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 3.8         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -0.631     |\n",
            "|    reward             | 0.52715683 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.3        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 175        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -4.27      |\n",
            "|    reward             | -2.4676492 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.63       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 175         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0.335       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -13.5       |\n",
            "|    reward             | 0.075991735 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 1.46        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 173        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0631     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -21.1      |\n",
            "|    reward             | -0.7419106 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.85       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 167          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 0.786        |\n",
            "|    reward             | -0.005878143 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.0122       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 166        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0391    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 13         |\n",
            "|    reward             | -1.2178588 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.95       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 164        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.000991  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 19.2       |\n",
            "|    reward             | -0.6305907 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.48       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 160       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.138     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 2.23      |\n",
            "|    reward             | 2.4926715 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2         |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | -0.0305  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -80.4    |\n",
            "|    reward             | 1.557822 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 60       |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 151       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.132    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -10.7     |\n",
            "|    reward             | 1.2305987 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 4.12      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 147         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -6.43       |\n",
            "|    reward             | -0.32017836 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.297       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 142       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.174     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -4.29     |\n",
            "|    reward             | 1.0288018 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.266     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 139       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 50        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.0508   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 14.5      |\n",
            "|    reward             | 0.6008585 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 3.69      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 136       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.255    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 10.7      |\n",
            "|    reward             | 1.3419564 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.81      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 135        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 59         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0851    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 13.3       |\n",
            "|    reward             | 0.71061766 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.97       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 133       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.00928   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 75.3      |\n",
            "|    reward             | 4.9972777 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 68.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 132        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -18.6      |\n",
            "|    reward             | 0.66486734 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.67       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 126        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 75         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.00604   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -36.5      |\n",
            "|    reward             | -0.0653574 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 8.44       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 121        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 82         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0637     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 13.9       |\n",
            "|    reward             | 0.94104666 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.37       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 117       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 89        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.143     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -9.97     |\n",
            "|    reward             | 1.3462406 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.19      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | -0.347   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 19.8     |\n",
            "|    reward             | 0.470311 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 3.44     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 109       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0118    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 112       |\n",
            "|    reward             | 2.1858919 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 74.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 106       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0442    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 30.8      |\n",
            "|    reward             | 0.3099143 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 6.74      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 102        |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 121        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0754     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | -12.5      |\n",
            "|    reward             | 0.24812937 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.67       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 129       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.362     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 4.54      |\n",
            "|    reward             | 0.7118428 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.565     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 99          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 136         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -5.82       |\n",
            "|    reward             | -0.25591573 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 1.92        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 142         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -1.74       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | -42.7       |\n",
            "|    reward             | -0.17619458 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 15.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 97         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 149        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.455     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 29.6       |\n",
            "|    reward             | 0.11380119 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 7.14       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 155        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.142     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | 5.9        |\n",
            "|    reward             | -0.7848766 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.275      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 95          |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 162         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -0.261      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | -20.4       |\n",
            "|    reward             | -0.44225278 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 5.39        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 169      |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 31.5     |\n",
            "|    reward             | 1.730797 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 11.2     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 92        |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 177       |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 9.99      |\n",
            "|    reward             | 0.3965541 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.832     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 185       |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -73       |\n",
            "|    reward             | 2.5305142 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 52.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 193        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | 103        |\n",
            "|    reward             | -1.2254468 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 84.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 200       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.00979  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | -0.442    |\n",
            "|    reward             | 0.7755117 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.0602    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 88          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 208         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -0.268      |\n",
            "|    reward             | -0.32657027 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.17        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 216        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.00122    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | 45.5       |\n",
            "|    reward             | 0.22284694 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 14.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 223       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 8.78      |\n",
            "|    reward             | 0.5364618 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.25      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 231       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0358    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -38.9     |\n",
            "|    reward             | -4.903084 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 11.4      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 85          |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 238         |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -18.5       |\n",
            "|    reward             | -0.12648061 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 6.13        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 245        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.143      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | 0.759      |\n",
            "|    reward             | -1.2273622 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.605      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 85          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 252         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 33.6        |\n",
            "|    reward             | -0.63108075 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 7.04        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 84         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 260        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.421     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -25.5      |\n",
            "|    reward             | -2.7527323 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 267       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.303    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 20.2      |\n",
            "|    reward             | 3.7813497 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 3.4       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 275        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 45.9       |\n",
            "|    reward             | 0.14919342 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 16.2       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 83          |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 282         |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | 96.1        |\n",
            "|    reward             | -0.37450132 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 55.8        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 289        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.00237    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -2.7       |\n",
            "|    reward             | -0.5580026 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.855      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 296         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.0446      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 16.8        |\n",
            "|    reward             | -0.41458562 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 2.1         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 304       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -40.8     |\n",
            "|    reward             | 1.4224954 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 9.92      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 312        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.0157    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 44.4       |\n",
            "|    reward             | 0.59530157 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 17.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 319        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | 43.2       |\n",
            "|    reward             | 0.16860943 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 14.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 326       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 124       |\n",
            "|    reward             | -8.726827 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 103       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 7843882.18\n",
            "total_reward: 6843882.18\n",
            "total_cost: 12561.26\n",
            "total_trades: 15610\n",
            "Sharpe: 1.011\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 332        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00121   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -27        |\n",
            "|    reward             | -0.9644534 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 5.19       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 339        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 13.9       |\n",
            "|    reward             | 0.41101792 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 348         |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | -21.5       |\n",
            "|    reward             | -0.32942227 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 10          |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 357        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -10.1      |\n",
            "|    reward             | -0.9184577 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.19       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 365       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 46.9      |\n",
            "|    reward             | 0.5084114 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 26.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 373         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -29.1       |\n",
            "|    reward             | -0.95214015 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 15.8        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 381       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -45.2     |\n",
            "|    reward             | 0.7416053 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 12.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 388       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | 5.23      |\n",
            "|    reward             | 0.7731504 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.319     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 396        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00585   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -64.7      |\n",
            "|    reward             | -2.9746473 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 33.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 403       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | -13.8     |\n",
            "|    reward             | 0.6201128 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.77      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 412       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 30.3      |\n",
            "|    reward             | 3.0127113 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 15.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 420        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | 8.47       |\n",
            "|    reward             | -1.2853391 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.7        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 427        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.182      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -39.7      |\n",
            "|    reward             | -1.7129246 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 9.86       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 435       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 7.52      |\n",
            "|    reward             | 1.4214888 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.579     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 442        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 6.85       |\n",
            "|    reward             | -1.5645133 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.835      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 449        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -9.51      |\n",
            "|    reward             | 0.18851666 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.815      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 456        |\n",
            "|    total_timesteps    | 35000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6999       |\n",
            "|    policy_loss        | 29.2       |\n",
            "|    reward             | 0.16517192 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 6.61       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 464         |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | -0.921      |\n",
            "|    reward             | -0.03174848 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0048      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 7200       |\n",
            "|    time_elapsed       | 471        |\n",
            "|    total_timesteps    | 36000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.0108     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7199       |\n",
            "|    policy_loss        | -12.2      |\n",
            "|    reward             | 0.14822274 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.836      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 480        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | -3.75      |\n",
            "|    reward             | 0.13380644 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.189      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 487        |\n",
            "|    total_timesteps    | 37000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.346     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7399       |\n",
            "|    policy_loss        | -25.6      |\n",
            "|    reward             | 0.39353445 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 6.48       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 495       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 6.91      |\n",
            "|    reward             | 0.3735382 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.288     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 503        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.061     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 4.02       |\n",
            "|    reward             | -0.1362401 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.423      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 511          |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | 0.011        |\n",
            "|    reward             | 9.018001e-05 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.0469       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 519        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.0961     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | 18.4       |\n",
            "|    reward             | -2.1263285 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.8        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 528       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -38.6     |\n",
            "|    reward             | 1.5139049 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 8.12      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 537         |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -21.1       |\n",
            "|    reward             | -0.16777898 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 6.63        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 546       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -64.8     |\n",
            "|    reward             | 4.769027  |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 27.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 553       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -284      |\n",
            "|    reward             | -8.832298 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 463       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 561       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | -29.9     |\n",
            "|    reward             | -1.984015 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 5         |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 8400       |\n",
            "|    time_elapsed       | 568        |\n",
            "|    total_timesteps    | 42000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8399       |\n",
            "|    policy_loss        | -56.6      |\n",
            "|    reward             | 0.40955555 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 18.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 577       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.372    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -6.65     |\n",
            "|    reward             | 1.6138059 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.911     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 585       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | -38.3     |\n",
            "|    reward             | 1.7805194 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 9.18      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 593       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -31.5     |\n",
            "|    reward             | 1.5294441 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 7.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 600        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 151        |\n",
            "|    reward             | -3.0572035 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 124        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 608       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 24.1      |\n",
            "|    reward             | 2.5436687 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 4.9       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 615        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.0372     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 39.6       |\n",
            "|    reward             | 0.11072077 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 8.01       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 623       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | 20.9      |\n",
            "|    reward             | 1.0637549 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.92      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 632        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 8.33       |\n",
            "|    reward             | 0.28783563 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.23       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 641        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | -8.03      |\n",
            "|    reward             | 0.34031734 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.953      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 9400        |\n",
            "|    time_elapsed       | 650         |\n",
            "|    total_timesteps    | 47000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9399        |\n",
            "|    policy_loss        | 13.5        |\n",
            "|    reward             | -0.64277893 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 7.5         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 662       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0459    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 12.5      |\n",
            "|    reward             | 1.3363093 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 1.56      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 672        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.0361    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 1.01       |\n",
            "|    reward             | -1.5356281 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.99       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 681        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.0492     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 8.2        |\n",
            "|    reward             | -0.8946081 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.26       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 690        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.122     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -66        |\n",
            "|    reward             | -0.8732715 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 23.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 700       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0723    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | -3.75     |\n",
            "|    reward             | 1.5633212 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.63      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 709        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.133     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | -4.68      |\n",
            "|    reward             | -4.9951053 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 717       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 4.06      |\n",
            "|    reward             | 1.2332373 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 725       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 25.1      |\n",
            "|    reward             | 1.2353597 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 4.55      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 733       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -13       |\n",
            "|    reward             | 1.4925125 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 1.8       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 741         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | -0.0673     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 35.7        |\n",
            "|    reward             | -0.75894344 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 7.46        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 749       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 43.8      |\n",
            "|    reward             | -2.708324 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 17.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 757         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | -0.12       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | -65.4       |\n",
            "|    reward             | -0.00418629 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 46.3        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 10700    |\n",
            "|    time_elapsed       | 765      |\n",
            "|    total_timesteps    | 53500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0.203    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10699    |\n",
            "|    policy_loss        | 2.13     |\n",
            "|    reward             | 0.325484 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.316    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 10800      |\n",
            "|    time_elapsed       | 772        |\n",
            "|    total_timesteps    | 54000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.22       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10799      |\n",
            "|    policy_loss        | 5.54       |\n",
            "|    reward             | -0.4528434 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.471      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 779        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | 13         |\n",
            "|    reward             | -2.2285917 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.65       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 11000     |\n",
            "|    time_elapsed       | 785       |\n",
            "|    total_timesteps    | 55000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10999     |\n",
            "|    policy_loss        | -18.5     |\n",
            "|    reward             | 1.4657146 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 2.87      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 11100      |\n",
            "|    time_elapsed       | 793        |\n",
            "|    total_timesteps    | 55500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11099      |\n",
            "|    policy_loss        | 19.8       |\n",
            "|    reward             | 0.21998139 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 8.99       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 800        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -29.2      |\n",
            "|    reward             | -1.8543624 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 4.76       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3567297.76\n",
            "total_reward: 2567297.76\n",
            "total_cost: 11357.76\n",
            "total_trades: 14359\n",
            "Sharpe: 0.787\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 11300       |\n",
            "|    time_elapsed       | 808         |\n",
            "|    total_timesteps    | 56500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0.142       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11299       |\n",
            "|    policy_loss        | 19.2        |\n",
            "|    reward             | -0.34539238 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 2.27        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 814       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 10.6      |\n",
            "|    reward             | 0.9263134 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 821       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 19.1      |\n",
            "|    reward             | 2.2210274 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 3.05      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 11600       |\n",
            "|    time_elapsed       | 829         |\n",
            "|    total_timesteps    | 58000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11599       |\n",
            "|    policy_loss        | 13.8        |\n",
            "|    reward             | -0.41982397 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 1.45        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 11700      |\n",
            "|    time_elapsed       | 837        |\n",
            "|    total_timesteps    | 58500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11699      |\n",
            "|    policy_loss        | 37         |\n",
            "|    reward             | -1.7141793 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 10.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 845       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | 76.2      |\n",
            "|    reward             | 1.0111042 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 36.5      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 11900       |\n",
            "|    time_elapsed       | 854         |\n",
            "|    total_timesteps    | 59500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11899       |\n",
            "|    policy_loss        | -21.9       |\n",
            "|    reward             | -0.11442076 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 2.85        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 862        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -23.5      |\n",
            "|    reward             | -2.1298692 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 3.67       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 12100       |\n",
            "|    time_elapsed       | 869         |\n",
            "|    total_timesteps    | 60500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12099       |\n",
            "|    policy_loss        | -15.6       |\n",
            "|    reward             | 0.042267643 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 1.89        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 12200     |\n",
            "|    time_elapsed       | 877       |\n",
            "|    total_timesteps    | 61000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12199     |\n",
            "|    policy_loss        | -35.1     |\n",
            "|    reward             | 0.7047759 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 5.74      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 12300      |\n",
            "|    time_elapsed       | 885        |\n",
            "|    total_timesteps    | 61500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12299      |\n",
            "|    policy_loss        | -12.6      |\n",
            "|    reward             | 0.39455137 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 2.57       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 893      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | 70       |\n",
            "|    reward             | 3.216583 |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 33.8     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 12500    |\n",
            "|    time_elapsed       | 901      |\n",
            "|    total_timesteps    | 62500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.5    |\n",
            "|    explained_variance | 0.101    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12499    |\n",
            "|    policy_loss        | -63.3    |\n",
            "|    reward             | 4.752634 |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 29.1     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 910        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | -17        |\n",
            "|    reward             | -0.5842923 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 2.38       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 12700       |\n",
            "|    time_elapsed       | 918         |\n",
            "|    total_timesteps    | 63500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12699       |\n",
            "|    policy_loss        | -33.4       |\n",
            "|    reward             | -0.22110625 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 6.44        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 12800       |\n",
            "|    time_elapsed       | 927         |\n",
            "|    total_timesteps    | 64000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12799       |\n",
            "|    policy_loss        | 12.2        |\n",
            "|    reward             | -0.29649436 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 1.11        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 937       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | 10.8      |\n",
            "|    reward             | 2.0783105 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 1.74      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13000      |\n",
            "|    time_elapsed       | 946        |\n",
            "|    total_timesteps    | 65000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12999      |\n",
            "|    policy_loss        | 14.2       |\n",
            "|    reward             | -0.3430293 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 2.85       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 955       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -68.8     |\n",
            "|    reward             | 3.3182595 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 26.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 13200       |\n",
            "|    time_elapsed       | 965         |\n",
            "|    total_timesteps    | 66000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13199       |\n",
            "|    policy_loss        | -33.2       |\n",
            "|    reward             | -0.91525555 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 7.88        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 13300       |\n",
            "|    time_elapsed       | 975         |\n",
            "|    total_timesteps    | 66500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13299       |\n",
            "|    policy_loss        | -17.9       |\n",
            "|    reward             | 0.040057395 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 4.43        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13400      |\n",
            "|    time_elapsed       | 982        |\n",
            "|    total_timesteps    | 67000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13399      |\n",
            "|    policy_loss        | 0.893      |\n",
            "|    reward             | 0.43515462 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.111      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13500      |\n",
            "|    time_elapsed       | 990        |\n",
            "|    total_timesteps    | 67500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13499      |\n",
            "|    policy_loss        | -37.8      |\n",
            "|    reward             | 0.98942155 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 7.15       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13600      |\n",
            "|    time_elapsed       | 997        |\n",
            "|    total_timesteps    | 68000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13599      |\n",
            "|    policy_loss        | -29.6      |\n",
            "|    reward             | -1.1492697 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 8.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 1005      |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0.0138    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 25.7      |\n",
            "|    reward             | 1.5652413 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 1013      |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -13.3     |\n",
            "|    reward             | 2.3218558 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1         |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 1021       |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 14.7       |\n",
            "|    reward             | -1.6849984 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 2.18       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 67         |\n",
            "|    iterations         | 14000      |\n",
            "|    time_elapsed       | 1030       |\n",
            "|    total_timesteps    | 70000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13999      |\n",
            "|    policy_loss        | 2.46       |\n",
            "|    reward             | 0.16546778 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.1        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 67         |\n",
            "|    iterations         | 14100      |\n",
            "|    time_elapsed       | 1038       |\n",
            "|    total_timesteps    | 70500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14099      |\n",
            "|    policy_loss        | 16.4       |\n",
            "|    reward             | -1.3421019 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 2.02       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 67         |\n",
            "|    iterations         | 14200      |\n",
            "|    time_elapsed       | 1045       |\n",
            "|    total_timesteps    | 71000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14199      |\n",
            "|    policy_loss        | 6.21       |\n",
            "|    reward             | 0.09417841 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.187      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 67         |\n",
            "|    iterations         | 14300      |\n",
            "|    time_elapsed       | 1051       |\n",
            "|    total_timesteps    | 71500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14299      |\n",
            "|    policy_loss        | 7.08       |\n",
            "|    reward             | 0.53491956 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.873      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14400      |\n",
            "|    time_elapsed       | 1058       |\n",
            "|    total_timesteps    | 72000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14399      |\n",
            "|    policy_loss        | -66.9      |\n",
            "|    reward             | 0.67358863 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 26.2       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 14500       |\n",
            "|    time_elapsed       | 1065        |\n",
            "|    total_timesteps    | 72500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14499       |\n",
            "|    policy_loss        | 18.9        |\n",
            "|    reward             | -0.06647397 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 3.71        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 1072       |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 23.6       |\n",
            "|    reward             | -1.8829955 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 6.48       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 1079       |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 32.3       |\n",
            "|    reward             | -2.1422734 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 9.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 14800     |\n",
            "|    time_elapsed       | 1086      |\n",
            "|    total_timesteps    | 74000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14799     |\n",
            "|    policy_loss        | 2.01      |\n",
            "|    reward             | 0.2656803 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.0324    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 14900     |\n",
            "|    time_elapsed       | 1093      |\n",
            "|    total_timesteps    | 74500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14899     |\n",
            "|    policy_loss        | -39.9     |\n",
            "|    reward             | 0.6033066 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 8.32      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 1099       |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -11.6      |\n",
            "|    reward             | -1.4126434 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.16       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 1106       |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 6.49       |\n",
            "|    reward             | -2.6245801 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.39       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 1114      |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -37.9     |\n",
            "|    reward             | 3.1993496 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 24        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 1123       |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -243       |\n",
            "|    reward             | -3.5666065 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 414        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 1131        |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | -0.0269     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 27.4        |\n",
            "|    reward             | -0.32282865 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 6.74        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 1138      |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 32.3      |\n",
            "|    reward             | 0.7668794 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 7.35      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 1145       |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0.000221   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 14.2       |\n",
            "|    reward             | 0.31912288 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.15       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 1151      |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | 11.6      |\n",
            "|    reward             | 1.1379541 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.861     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 1158      |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -11.9     |\n",
            "|    reward             | 1.6257915 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.671     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 15900       |\n",
            "|    time_elapsed       | 1166        |\n",
            "|    total_timesteps    | 79500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15899       |\n",
            "|    policy_loss        | 1.77        |\n",
            "|    reward             | -0.19893293 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 8.08        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 1172       |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.0759    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | 6.32       |\n",
            "|    reward             | -1.5091623 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 2.36       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 1179      |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 9.57      |\n",
            "|    reward             | 0.9330086 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.47      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1186      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.0817    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -13.1     |\n",
            "|    reward             | 0.5488683 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.32      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 16300    |\n",
            "|    time_elapsed       | 1192     |\n",
            "|    total_timesteps    | 81500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16299    |\n",
            "|    policy_loss        | -15.8    |\n",
            "|    reward             | 0.317524 |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 1.77     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 16400    |\n",
            "|    time_elapsed       | 1199     |\n",
            "|    total_timesteps    | 82000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16399    |\n",
            "|    policy_loss        | 24.6     |\n",
            "|    reward             | 2.402459 |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 3.8      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1205       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | 33.7       |\n",
            "|    reward             | -1.4204212 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 8.46       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1212      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.0593    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 6.31      |\n",
            "|    reward             | 0.8808522 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.301     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 16700      |\n",
            "|    time_elapsed       | 1219       |\n",
            "|    total_timesteps    | 83500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16699      |\n",
            "|    policy_loss        | -29.4      |\n",
            "|    reward             | 0.95416445 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 4.47       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1225       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.0125     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 17.3       |\n",
            "|    reward             | -1.2242658 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 2.37       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1231      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00779   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -0.531    |\n",
            "|    reward             | 0.7630917 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.908     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1237       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.053     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -63.1      |\n",
            "|    reward             | -0.7875235 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 25.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1244      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.00749  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -154      |\n",
            "|    reward             | 2.8822474 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 132       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3376361.53\n",
            "total_reward: 2376361.53\n",
            "total_cost: 23641.17\n",
            "total_trades: 11974\n",
            "Sharpe: 0.734\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 1250        |\n",
            "|    total_timesteps    | 86000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | -0.276      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | 1.92        |\n",
            "|    reward             | -0.26129174 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.216       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 1257      |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.0351    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | -7.89     |\n",
            "|    reward             | 0.8930364 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.528     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 17400      |\n",
            "|    time_elapsed       | 1263       |\n",
            "|    total_timesteps    | 87000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.101      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17399      |\n",
            "|    policy_loss        | -48.4      |\n",
            "|    reward             | 0.22089316 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 17.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 17500      |\n",
            "|    time_elapsed       | 1269       |\n",
            "|    total_timesteps    | 87500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.0484     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17499      |\n",
            "|    policy_loss        | 37.8       |\n",
            "|    reward             | 0.68515307 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 12.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 17600     |\n",
            "|    time_elapsed       | 1276      |\n",
            "|    total_timesteps    | 88000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.0123   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17599     |\n",
            "|    policy_loss        | 21.9      |\n",
            "|    reward             | -2.362668 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 4.16      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1282      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00329   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | 56.4      |\n",
            "|    reward             | 1.4338186 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 17.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 1288      |\n",
            "|    total_timesteps    | 89000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00683   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | 12.3      |\n",
            "|    reward             | 1.1516442 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1294       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.0588     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -7.59      |\n",
            "|    reward             | -3.1654656 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.424      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1301       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | 7.53       |\n",
            "|    reward             | 0.22116603 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 2.21       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 18100    |\n",
            "|    time_elapsed       | 1307     |\n",
            "|    total_timesteps    | 90500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.7    |\n",
            "|    explained_variance | 0.129    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18099    |\n",
            "|    policy_loss        | -7.53    |\n",
            "|    reward             | 1.704403 |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.47     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 18200       |\n",
            "|    time_elapsed       | 1313        |\n",
            "|    total_timesteps    | 91000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0.157       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18199       |\n",
            "|    policy_loss        | 0.18        |\n",
            "|    reward             | -0.40384492 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.964       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 18300     |\n",
            "|    time_elapsed       | 1319      |\n",
            "|    total_timesteps    | 91500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.00345  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18299     |\n",
            "|    policy_loss        | -205      |\n",
            "|    reward             | 0.9549815 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 193       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 1325      |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.00925  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | 30.8      |\n",
            "|    reward             | 0.6165129 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 5.45      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 18500      |\n",
            "|    time_elapsed       | 1332       |\n",
            "|    total_timesteps    | 92500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18499      |\n",
            "|    policy_loss        | -3.15      |\n",
            "|    reward             | -1.2045656 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 3.23       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 18600      |\n",
            "|    time_elapsed       | 1338       |\n",
            "|    total_timesteps    | 93000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.354     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18599      |\n",
            "|    policy_loss        | 12.2       |\n",
            "|    reward             | 0.98961353 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.971      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1344      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -16.2     |\n",
            "|    reward             | 3.5717134 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 2.46      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 1350      |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 56.1      |\n",
            "|    reward             | 1.527293  |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 25.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 18900     |\n",
            "|    time_elapsed       | 1357      |\n",
            "|    total_timesteps    | 94500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18899     |\n",
            "|    policy_loss        | 66.5      |\n",
            "|    reward             | 1.697957  |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 46.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1363      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | 4.15      |\n",
            "|    reward             | 1.0954328 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 1.4       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 19100      |\n",
            "|    time_elapsed       | 1369       |\n",
            "|    total_timesteps    | 95500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19099      |\n",
            "|    policy_loss        | -62.8      |\n",
            "|    reward             | 0.93630975 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 17.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 19200      |\n",
            "|    time_elapsed       | 1375       |\n",
            "|    total_timesteps    | 96000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19199      |\n",
            "|    policy_loss        | 0.215      |\n",
            "|    reward             | 0.12437432 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 1.01       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 69           |\n",
            "|    iterations         | 19300        |\n",
            "|    time_elapsed       | 1381         |\n",
            "|    total_timesteps    | 96500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.8        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 19299        |\n",
            "|    policy_loss        | 74.5         |\n",
            "|    reward             | -0.043890446 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 33.3         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1387      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 78.6      |\n",
            "|    reward             | 0.9034543 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 51.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 19500       |\n",
            "|    time_elapsed       | 1393        |\n",
            "|    total_timesteps    | 97500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19499       |\n",
            "|    policy_loss        | 59.1        |\n",
            "|    reward             | -0.96959984 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 25.5        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1400      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0.00929   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 22.8      |\n",
            "|    reward             | 0.5790695 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 10.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 19700       |\n",
            "|    time_elapsed       | 1406        |\n",
            "|    total_timesteps    | 98500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19699       |\n",
            "|    policy_loss        | -26.1       |\n",
            "|    reward             | 0.055820167 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 6.23        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 19800      |\n",
            "|    time_elapsed       | 1412       |\n",
            "|    total_timesteps    | 99000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19799      |\n",
            "|    policy_loss        | 4.59       |\n",
            "|    reward             | -7.3243985 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 1.71       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1418       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -70.6      |\n",
            "|    reward             | -3.9913814 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 22.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 20000     |\n",
            "|    time_elapsed       | 1424      |\n",
            "|    total_timesteps    | 100000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19999     |\n",
            "|    policy_loss        | -106      |\n",
            "|    reward             | -9.637429 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 77.5      |\n",
            "-------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.998680e+05  9.905746e+05\n",
            "2021-10-05  1.000196e+06  9.996566e+05\n",
            "2021-10-06  1.000151e+06  1.002637e+06\n",
            "2021-10-07  1.000821e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  8.880192e+05  9.854252e+05\n",
            "2023-04-28  8.985841e+05  9.933491e+05\n",
            "2023-05-01  8.961462e+05  9.919956e+05\n",
            "2023-05-02  8.758291e+05  9.812993e+05\n",
            "2023-05-03  8.658059e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -13.42 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.488     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -15.7      |\n",
            "|    reward             | 0.38463306 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.47       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.02     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -5.29     |\n",
            "|    reward             | 0.6555611 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.63      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 18         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.0988    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -16.3      |\n",
            "|    reward             | -2.3803387 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.06       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.0977    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -0.289    |\n",
            "|    reward             | -0.072814 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.19      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.623      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -30.3      |\n",
            "|    reward             | -0.8560658 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 5.97       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 82           |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 0.614        |\n",
            "|    reward             | 0.0041158823 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.0266       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.256      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 8.02       |\n",
            "|    reward             | -0.8047727 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.642      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -0.00943    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 0.015       |\n",
            "|    reward             | -0.02264057 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.589       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.0194   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 9.58      |\n",
            "|    reward             | 2.9300675 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 6.01      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | -0.029   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -68.1    |\n",
            "|    reward             | 4.641748 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 87.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.057     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 47        |\n",
            "|    reward             | 1.2812362 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 17.3      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -5.98       |\n",
            "|    reward             | -0.22766629 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.265       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 78       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 0.0235   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -16.6    |\n",
            "|    reward             | 0.665825 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 2.14     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.176     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 35.2       |\n",
            "|    reward             | 0.98845315 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 7.98       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.153     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 27.9      |\n",
            "|    reward             | 1.0399951 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 6.87      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.112     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 14.3      |\n",
            "|    reward             | 1.3956658 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 4.81      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0436    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 67.5      |\n",
            "|    reward             | 2.2099335 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 48.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -17.5      |\n",
            "|    reward             | 0.48989582 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.17       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 117         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0.308       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -47.7       |\n",
            "|    reward             | -0.09310455 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 12          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0328    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 16        |\n",
            "|    reward             | 0.4884829 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.14      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0097    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -9.63     |\n",
            "|    reward             | 2.4453251 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.93      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 143        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0398     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 6.25       |\n",
            "|    reward             | -3.3805497 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.23       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0819    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 81.2      |\n",
            "|    reward             | 2.3865528 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 54.7      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 160          |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 9.57         |\n",
            "|    reward             | -0.018459182 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 0.75         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 168        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | -13.3      |\n",
            "|    reward             | 0.66943604 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.38       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 174      |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0.0884   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 1.81     |\n",
            "|    reward             | 0.308934 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.273    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 180        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.742     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -8.47      |\n",
            "|    reward             | -0.5423305 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.3        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 186        |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.556     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | -29.1      |\n",
            "|    reward             | 0.27588752 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 7.39       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 193        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -1.14      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 39.1       |\n",
            "|    reward             | 0.14497432 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 199        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | 1.39       |\n",
            "|    reward             | -0.4123641 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.0127     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 205         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | -11.5       |\n",
            "|    reward             | -0.10100972 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.55        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 212       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -2.98e-06 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 29.3      |\n",
            "|    reward             | 1.0051801 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 7.84      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 218        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.108      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 0.282      |\n",
            "|    reward             | 0.29362908 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.118      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 225       |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.0457   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -75.6     |\n",
            "|    reward             | 3.5086596 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 47        |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 231         |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0.0295      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 45.4        |\n",
            "|    reward             | -0.49369204 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 15.1        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 243        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.4       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | 1.48       |\n",
            "|    reward             | 0.67747986 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.173      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 249        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.0636    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 2.03       |\n",
            "|    reward             | -0.4298378 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.55       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 255       |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0556    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 53        |\n",
            "|    reward             | 0.6520502 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 16.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 262        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.0171     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | 15.4       |\n",
            "|    reward             | 0.20057769 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.49       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 268       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.18     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -19.5     |\n",
            "|    reward             | -2.174098 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 2.04      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 274        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00231   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | -26.7      |\n",
            "|    reward             | -1.9089134 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.56       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 280        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.226     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | 0.322      |\n",
            "|    reward             | -1.3044419 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.859      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 286        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.137     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | 21         |\n",
            "|    reward             | -0.3187949 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 292       |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.0615   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | -28       |\n",
            "|    reward             | -3.438601 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 5.49      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 299       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.000926 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 20        |\n",
            "|    reward             | 2.4172933 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.84      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 305        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.0671    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 27.3       |\n",
            "|    reward             | -0.5378077 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 6.49       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 311          |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | -0.0146      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | -5.95        |\n",
            "|    reward             | -0.015294731 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.721        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 317         |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0.0358      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | -7.65       |\n",
            "|    reward             | -0.31141946 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 1.79        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 323         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0.126       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -25.2       |\n",
            "|    reward             | -0.42884278 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 4.22        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 329       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.519    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -32.1     |\n",
            "|    reward             | 0.7994776 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 7.53      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 336        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.0248     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 15.2       |\n",
            "|    reward             | 0.16736196 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.05       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 342        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -32.8      |\n",
            "|    reward             | -1.2294316 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 8.62       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 350      |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | 78.3     |\n",
            "|    reward             | -2.60885 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 40.8     |\n",
            "------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3359747.01\n",
            "total_reward: 2359747.01\n",
            "total_cost: 22986.74\n",
            "total_trades: 13013\n",
            "Sharpe: 0.683\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 360        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.0933    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -36.2      |\n",
            "|    reward             | -1.0058864 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 6.83       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 366       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 14.4      |\n",
            "|    reward             | 2.0646985 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.65      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 372        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -0.336     |\n",
            "|    reward             | -1.4995918 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.807      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 378         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | -12.2       |\n",
            "|    reward             | -0.14882553 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 3.3         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 384       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 28.5      |\n",
            "|    reward             | 1.8077568 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 6.63      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 390        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.0487     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | -38.6      |\n",
            "|    reward             | -1.5155224 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 8.69       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 396       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.0144   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -45.9     |\n",
            "|    reward             | 1.1409369 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 12.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 402        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.0237    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 5.55       |\n",
            "|    reward             | 0.70902085 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.403      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 408        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.00584    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -74.1      |\n",
            "|    reward             | -2.8864834 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 48.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 414        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.0361     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | 6.01       |\n",
            "|    reward             | 0.50877804 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.53       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 420       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.567    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 55.8      |\n",
            "|    reward             | 4.2120376 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 45        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 426       |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0.00371   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | -50.5     |\n",
            "|    reward             | 1.4650275 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 433        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.295      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -33.7      |\n",
            "|    reward             | -2.1405094 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 9.2        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 6700     |\n",
            "|    time_elapsed       | 439      |\n",
            "|    total_timesteps    | 33500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0.133    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6699     |\n",
            "|    policy_loss        | -6.79    |\n",
            "|    reward             | 2.267957 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.408    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 445        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.00266    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 51.7       |\n",
            "|    reward             | -3.0398052 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 17         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 451        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.219     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -16.2      |\n",
            "|    reward             | -1.8496914 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.56       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 458       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.0411   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -33.1     |\n",
            "|    reward             | 2.6939669 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 6.35      |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 76            |\n",
            "|    iterations         | 7100          |\n",
            "|    time_elapsed       | 464           |\n",
            "|    total_timesteps    | 35500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.4         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7099          |\n",
            "|    policy_loss        | -3.66         |\n",
            "|    reward             | -0.0024862995 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 0.0992        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 470         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | -2.46       |\n",
            "|    reward             | -0.49658662 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0826      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 7300      |\n",
            "|    time_elapsed       | 476       |\n",
            "|    total_timesteps    | 36500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.129    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7299      |\n",
            "|    policy_loss        | 0.245     |\n",
            "|    reward             | 0.0203117 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.176     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 482       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0.0359    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -32.8     |\n",
            "|    reward             | 0.6781554 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 11.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 7500       |\n",
            "|    time_elapsed       | 488        |\n",
            "|    total_timesteps    | 37500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0.0252     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7499       |\n",
            "|    policy_loss        | 4.88       |\n",
            "|    reward             | 0.64965206 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.921      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 494       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0.000274  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 15.6      |\n",
            "|    reward             | 0.9213329 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.56      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 501         |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 1.34        |\n",
            "|    reward             | -0.01144895 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.0315      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 507         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0.00307     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | 11.9        |\n",
            "|    reward             | -0.30988508 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 1.14        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 7900       |\n",
            "|    time_elapsed       | 513        |\n",
            "|    total_timesteps    | 39500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7899       |\n",
            "|    policy_loss        | -14.1      |\n",
            "|    reward             | 0.88132083 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.4        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 520       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.243    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | -28.4     |\n",
            "|    reward             | -2.686315 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 4.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 526       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -54       |\n",
            "|    reward             | 3.770788  |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 32        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 532        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -294       |\n",
            "|    reward             | -7.3915715 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 505        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 538        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | -26.9      |\n",
            "|    reward             | -1.6126114 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 5.71       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 544         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -30.9       |\n",
            "|    reward             | -0.04678184 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 7.31        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 551       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 13.3      |\n",
            "|    reward             | 1.7789408 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.08      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 557       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | 9.13      |\n",
            "|    reward             | 3.2112298 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.71      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 563       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -102      |\n",
            "|    reward             | 3.7776883 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 67.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 569        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.0171    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 126        |\n",
            "|    reward             | -3.8072665 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 104        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 575       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.0162    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 26.3      |\n",
            "|    reward             | 2.4219584 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 4.38      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 581        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.00251    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 12.3       |\n",
            "|    reward             | 0.13282487 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.43       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 587       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.0742   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | -9.23     |\n",
            "|    reward             | 0.9360407 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.659     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 593        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.0452     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 23.3       |\n",
            "|    reward             | 0.56408644 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 5.07       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 599       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.00457  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 21.8      |\n",
            "|    reward             | 0.8088893 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 2.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 605       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.00512  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 29        |\n",
            "|    reward             | 0.4757065 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 17        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 611       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.122     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 10.1      |\n",
            "|    reward             | 0.5953011 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.14      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 617        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.00278    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | -8.19      |\n",
            "|    reward             | -0.9201351 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.04       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 623         |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | -0.0603     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9699        |\n",
            "|    policy_loss        | 4.58        |\n",
            "|    reward             | -0.85146254 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.871       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 629        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.192      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -90.6      |\n",
            "|    reward             | 0.37394497 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 35.7       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 635         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0.057       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 20.5        |\n",
            "|    reward             | -0.11389199 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 2.95        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 641       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.143     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | -4.51     |\n",
            "|    reward             | -3.552307 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.813     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 646       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.22     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 3.74      |\n",
            "|    reward             | 1.2149786 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.878     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 653       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.105    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 8.8       |\n",
            "|    reward             | 0.5919297 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 1.59      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 659       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -1.45     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -3.16     |\n",
            "|    reward             | 1.7229631 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.675     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 665        |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.0001    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 91.4       |\n",
            "|    reward             | -0.5792245 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 47.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 671        |\n",
            "|    total_timesteps    | 52500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.0988    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 64.5       |\n",
            "|    reward             | -2.9719553 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 40.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 10600     |\n",
            "|    time_elapsed       | 677       |\n",
            "|    total_timesteps    | 53000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.162    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10599     |\n",
            "|    policy_loss        | -61.3     |\n",
            "|    reward             | 0.3696908 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 56.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 683        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.035      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | 8          |\n",
            "|    reward             | 0.41942292 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.634      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 689         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0.0839      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 18          |\n",
            "|    reward             | -0.88339096 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 2.08        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 695        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.444     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | 19.9       |\n",
            "|    reward             | -0.6191547 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 3.27       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11000     |\n",
            "|    time_elapsed       | 702       |\n",
            "|    total_timesteps    | 55000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.0648   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10999     |\n",
            "|    policy_loss        | 3.24      |\n",
            "|    reward             | 0.8942828 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.732     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11100     |\n",
            "|    time_elapsed       | 707       |\n",
            "|    total_timesteps    | 55500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.00474  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11099     |\n",
            "|    policy_loss        | 26.5      |\n",
            "|    reward             | 1.2583126 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 8.05      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 714        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.0621     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -24.2      |\n",
            "|    reward             | -1.5891893 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 8.15       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3131486.29\n",
            "total_reward: 2131486.29\n",
            "total_cost: 37238.72\n",
            "total_trades: 14421\n",
            "Sharpe: 0.653\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11300      |\n",
            "|    time_elapsed       | 720        |\n",
            "|    total_timesteps    | 56500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.138      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11299      |\n",
            "|    policy_loss        | 19.9       |\n",
            "|    reward             | 0.36560395 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.99       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 726       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.0622   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 8.46      |\n",
            "|    reward             | 1.3095292 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.703     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 11500    |\n",
            "|    time_elapsed       | 732      |\n",
            "|    total_timesteps    | 57500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.7    |\n",
            "|    explained_variance | -0.0183  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11499    |\n",
            "|    policy_loss        | 21.6     |\n",
            "|    reward             | 2.17225  |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 4.67     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 11600       |\n",
            "|    time_elapsed       | 739         |\n",
            "|    total_timesteps    | 58000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11599       |\n",
            "|    policy_loss        | -3.42       |\n",
            "|    reward             | -0.63609165 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 1.3         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11700      |\n",
            "|    time_elapsed       | 747        |\n",
            "|    total_timesteps    | 58500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.0735    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11699      |\n",
            "|    policy_loss        | 54.4       |\n",
            "|    reward             | -0.7693018 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 17.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 753       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0.00896   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | 3.39      |\n",
            "|    reward             | 3.1664324 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 12.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 11900       |\n",
            "|    time_elapsed       | 759         |\n",
            "|    total_timesteps    | 59500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | -0.00598    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11899       |\n",
            "|    policy_loss        | -22         |\n",
            "|    reward             | -0.37333864 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 2.65        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 764        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.00409   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -54.8      |\n",
            "|    reward             | -1.8814675 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 14.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 770       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.000833  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -4.47     |\n",
            "|    reward             | 0.6091999 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.373     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 12200    |\n",
            "|    time_elapsed       | 776      |\n",
            "|    total_timesteps    | 61000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.9    |\n",
            "|    explained_variance | -0.0215  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12199    |\n",
            "|    policy_loss        | -27.5    |\n",
            "|    reward             | 1.23237  |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 4.07     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 782       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.003     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | 28        |\n",
            "|    reward             | 0.6653617 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 15.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 788       |\n",
            "|    total_timesteps    | 62000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.0115    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | -19.8     |\n",
            "|    reward             | 1.8925859 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 13.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 794       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.00198   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -53.4     |\n",
            "|    reward             | 4.5078454 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 18.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 800        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | 2.2        |\n",
            "|    reward             | -0.7737423 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 0.475      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 12700     |\n",
            "|    time_elapsed       | 806       |\n",
            "|    total_timesteps    | 63500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12699     |\n",
            "|    policy_loss        | -32       |\n",
            "|    reward             | 1.5846639 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 8.88      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 12800    |\n",
            "|    time_elapsed       | 812      |\n",
            "|    total_timesteps    | 64000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14      |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12799    |\n",
            "|    policy_loss        | 26.7     |\n",
            "|    reward             | 2.157995 |\n",
            "|    std                | 1.15     |\n",
            "|    value_loss         | 4.3      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 12900      |\n",
            "|    time_elapsed       | 818        |\n",
            "|    total_timesteps    | 64500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12899      |\n",
            "|    policy_loss        | -30        |\n",
            "|    reward             | -1.7992723 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 4.99       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 13000    |\n",
            "|    time_elapsed       | 824      |\n",
            "|    total_timesteps    | 65000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12999    |\n",
            "|    policy_loss        | 16.1     |\n",
            "|    reward             | 3.35244  |\n",
            "|    std                | 1.15     |\n",
            "|    value_loss         | 3.08     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 830       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -0.0023   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -59.2     |\n",
            "|    reward             | 2.8723638 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 21.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 835        |\n",
            "|    total_timesteps    | 66000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0.00988    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | -25.8      |\n",
            "|    reward             | -0.8294447 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 4.18       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 13300      |\n",
            "|    time_elapsed       | 841        |\n",
            "|    total_timesteps    | 66500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13299      |\n",
            "|    policy_loss        | -26.6      |\n",
            "|    reward             | -0.8961629 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 5.96       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13400      |\n",
            "|    time_elapsed       | 847        |\n",
            "|    total_timesteps    | 67000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0.0978     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13399      |\n",
            "|    policy_loss        | -3.75      |\n",
            "|    reward             | 0.15654017 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.163      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13500      |\n",
            "|    time_elapsed       | 853        |\n",
            "|    total_timesteps    | 67500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -0.0435    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13499      |\n",
            "|    policy_loss        | -3.98      |\n",
            "|    reward             | 0.28139177 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 1.92       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 13600     |\n",
            "|    time_elapsed       | 859       |\n",
            "|    total_timesteps    | 68000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13599     |\n",
            "|    policy_loss        | -22.6     |\n",
            "|    reward             | -2.069239 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 8.08      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 865       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 24.8      |\n",
            "|    reward             | 1.6907107 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 9.4       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 871       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -0.197    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -9.34     |\n",
            "|    reward             | 1.8918554 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.576     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 877        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -0.00316   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | -1.15      |\n",
            "|    reward             | -2.9447606 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 1.27       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14000     |\n",
            "|    time_elapsed       | 884       |\n",
            "|    total_timesteps    | 70000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -0.0301   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13999     |\n",
            "|    policy_loss        | -6.25     |\n",
            "|    reward             | 0.2943352 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.804     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 14100       |\n",
            "|    time_elapsed       | 889         |\n",
            "|    total_timesteps    | 70500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0.0027      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14099       |\n",
            "|    policy_loss        | 16.8        |\n",
            "|    reward             | -0.92272764 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 2.16        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 14200       |\n",
            "|    time_elapsed       | 896         |\n",
            "|    total_timesteps    | 71000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14199       |\n",
            "|    policy_loss        | 1.27        |\n",
            "|    reward             | 0.096152425 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.0106      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 902       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0.00303   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 6.13      |\n",
            "|    reward             | 0.2967033 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.647     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14400      |\n",
            "|    time_elapsed       | 908        |\n",
            "|    total_timesteps    | 72000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0611    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14399      |\n",
            "|    policy_loss        | -28.9      |\n",
            "|    reward             | 0.82778436 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 5.07       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 14500       |\n",
            "|    time_elapsed       | 914         |\n",
            "|    total_timesteps    | 72500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0.00687     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14499       |\n",
            "|    policy_loss        | 31.3        |\n",
            "|    reward             | -0.40776768 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 6.64        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14600     |\n",
            "|    time_elapsed       | 919       |\n",
            "|    total_timesteps    | 73000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -0.0211   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14599     |\n",
            "|    policy_loss        | 30        |\n",
            "|    reward             | -2.026353 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 7.27      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 925        |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0398    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 48.5       |\n",
            "|    reward             | -1.7618318 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 16.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 931        |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -5.76      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | 11.9       |\n",
            "|    reward             | 0.40542427 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.919      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14900     |\n",
            "|    time_elapsed       | 937       |\n",
            "|    total_timesteps    | 74500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14899     |\n",
            "|    policy_loss        | -28       |\n",
            "|    reward             | 0.9231502 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 5.35      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 15000       |\n",
            "|    time_elapsed       | 943         |\n",
            "|    total_timesteps    | 75000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0.00345     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14999       |\n",
            "|    policy_loss        | -3.29       |\n",
            "|    reward             | -0.77975845 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.316       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 949        |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0462    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 19.2       |\n",
            "|    reward             | -1.4518207 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 3.19       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 15200    |\n",
            "|    time_elapsed       | 955      |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | 0.00932  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15199    |\n",
            "|    policy_loss        | -35.5    |\n",
            "|    reward             | 2.53947  |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 20.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15300     |\n",
            "|    time_elapsed       | 961       |\n",
            "|    total_timesteps    | 76500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -0.00712  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15299     |\n",
            "|    policy_loss        | -385      |\n",
            "|    reward             | -2.016732 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 978       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 967         |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 17.4        |\n",
            "|    reward             | -0.24489823 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 2.43        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15500      |\n",
            "|    time_elapsed       | 973        |\n",
            "|    total_timesteps    | 77500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15499      |\n",
            "|    policy_loss        | 32.9       |\n",
            "|    reward             | 0.84656334 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 7.28       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 979        |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 13         |\n",
            "|    reward             | 0.83689713 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.56       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 985       |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | 26.7      |\n",
            "|    reward             | 1.0225552 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 3.95      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 991       |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | 31.8      |\n",
            "|    reward             | -1.175378 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 6.88      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 997       |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | -2.56     |\n",
            "|    reward             | 0.9901462 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 14.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 1003       |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0.264      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | 8.71       |\n",
            "|    reward             | -1.0772387 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.5        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 16100       |\n",
            "|    time_elapsed       | 1010        |\n",
            "|    total_timesteps    | 80500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16099       |\n",
            "|    policy_loss        | -7.11       |\n",
            "|    reward             | -0.05421228 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.758       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1019      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -21.7     |\n",
            "|    reward             | 1.3460983 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 4.96      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 16300       |\n",
            "|    time_elapsed       | 1028        |\n",
            "|    total_timesteps    | 81500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16299       |\n",
            "|    policy_loss        | -18.7       |\n",
            "|    reward             | 0.005095085 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 2.47        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 16400    |\n",
            "|    time_elapsed       | 1036     |\n",
            "|    total_timesteps    | 82000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16399    |\n",
            "|    policy_loss        | 17.5     |\n",
            "|    reward             | 2.466402 |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 3.07     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 16500       |\n",
            "|    time_elapsed       | 1044        |\n",
            "|    total_timesteps    | 82500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16499       |\n",
            "|    policy_loss        | 54          |\n",
            "|    reward             | -0.89509755 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 18.7        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 16600      |\n",
            "|    time_elapsed       | 1051       |\n",
            "|    total_timesteps    | 83000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0.0471     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16599      |\n",
            "|    policy_loss        | 0.731      |\n",
            "|    reward             | 0.45393634 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.0688     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1058      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -12.7     |\n",
            "|    reward             | 1.5339997 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.863     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1068       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 45.8       |\n",
            "|    reward             | -2.2894106 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 8.62       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1077      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -80.6     |\n",
            "|    reward             | 1.4550407 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 32.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 17000     |\n",
            "|    time_elapsed       | 1084      |\n",
            "|    total_timesteps    | 85000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16999     |\n",
            "|    policy_loss        | -38.5     |\n",
            "|    reward             | 1.2710541 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 18.9      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 17100    |\n",
            "|    time_elapsed       | 1090     |\n",
            "|    total_timesteps    | 85500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17099    |\n",
            "|    policy_loss        | -105     |\n",
            "|    reward             | 2.751585 |\n",
            "|    std                | 1.18     |\n",
            "|    value_loss         | 74.4     |\n",
            "------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3392739.05\n",
            "total_reward: 2392739.05\n",
            "total_cost: 4656.30\n",
            "total_trades: 16773\n",
            "Sharpe: 0.710\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 17200      |\n",
            "|    time_elapsed       | 1097       |\n",
            "|    total_timesteps    | 86000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | -0.0083    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17199      |\n",
            "|    policy_loss        | 4.93       |\n",
            "|    reward             | 0.13962702 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 0.278      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 1103      |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | -11       |\n",
            "|    reward             | 0.6883076 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 0.507     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 17400       |\n",
            "|    time_elapsed       | 1109        |\n",
            "|    total_timesteps    | 87000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17399       |\n",
            "|    policy_loss        | 9.27        |\n",
            "|    reward             | -0.70415986 |\n",
            "|    std                | 1.19        |\n",
            "|    value_loss         | 0.56        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 1116      |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | -30.6     |\n",
            "|    reward             | 1.9138997 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 8.85      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 17600       |\n",
            "|    time_elapsed       | 1122        |\n",
            "|    total_timesteps    | 88000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.3       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17599       |\n",
            "|    policy_loss        | 37.1        |\n",
            "|    reward             | -0.47684407 |\n",
            "|    std                | 1.19        |\n",
            "|    value_loss         | 8.09        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1128      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | -62.1     |\n",
            "|    reward             | 2.7279756 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 53.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1134       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 1.06       |\n",
            "|    reward             | 0.95412016 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 0.052      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1141       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -6.13      |\n",
            "|    reward             | -2.0394256 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 0.23       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1147       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | -20.3      |\n",
            "|    reward             | -0.7048504 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 4.91       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1153      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | -1.15     |\n",
            "|    reward             | 1.0690948 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 0.341     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 1159       |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | 49         |\n",
            "|    reward             | 0.59666646 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 16.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 1166       |\n",
            "|    total_timesteps    | 91500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -136       |\n",
            "|    reward             | -1.3228114 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 105        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 18400       |\n",
            "|    time_elapsed       | 1172        |\n",
            "|    total_timesteps    | 92000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18399       |\n",
            "|    policy_loss        | 19.7        |\n",
            "|    reward             | 0.020378415 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 2.09        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 1178        |\n",
            "|    total_timesteps    | 92500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.4       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | -3.22       |\n",
            "|    reward             | -0.24318588 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 2.35        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 1184      |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | -1.83     |\n",
            "|    reward             | 0.7072955 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 0.28      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1190      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -15.7     |\n",
            "|    reward             | 2.1755648 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 1.4       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 1197      |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 43.1      |\n",
            "|    reward             | 0.6509745 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 13        |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 78            |\n",
            "|    iterations         | 18900         |\n",
            "|    time_elapsed       | 1204          |\n",
            "|    total_timesteps    | 94500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 18899         |\n",
            "|    policy_loss        | 33.8          |\n",
            "|    reward             | -0.0036425882 |\n",
            "|    std                | 1.21          |\n",
            "|    value_loss         | 17.3          |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 19000    |\n",
            "|    time_elapsed       | 1211     |\n",
            "|    total_timesteps    | 95000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18999    |\n",
            "|    policy_loss        | 1.5      |\n",
            "|    reward             | 0.858739 |\n",
            "|    std                | 1.21     |\n",
            "|    value_loss         | 0.797    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1218      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -83.2     |\n",
            "|    reward             | 1.0148152 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 29.5      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 19200       |\n",
            "|    time_elapsed       | 1224        |\n",
            "|    total_timesteps    | 96000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19199       |\n",
            "|    policy_loss        | -1.39       |\n",
            "|    reward             | -0.38474795 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 1.07        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 19300      |\n",
            "|    time_elapsed       | 1230       |\n",
            "|    total_timesteps    | 96500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19299      |\n",
            "|    policy_loss        | -64.2      |\n",
            "|    reward             | 0.34678963 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 15.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1236      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 126       |\n",
            "|    reward             | 1.0455381 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 96.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 19500      |\n",
            "|    time_elapsed       | 1242       |\n",
            "|    total_timesteps    | 97500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19499      |\n",
            "|    policy_loss        | -49.1      |\n",
            "|    reward             | -1.7172074 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 13.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1249      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 38.7      |\n",
            "|    reward             | 0.6288688 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 11.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 19700     |\n",
            "|    time_elapsed       | 1256      |\n",
            "|    total_timesteps    | 98500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0.0164    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19699     |\n",
            "|    policy_loss        | -34.3     |\n",
            "|    reward             | 0.8254848 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 7.87      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 19800      |\n",
            "|    time_elapsed       | 1262       |\n",
            "|    total_timesteps    | 99000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19799      |\n",
            "|    policy_loss        | 33.2       |\n",
            "|    reward             | -7.5812416 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 5.22       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1269       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -25.4      |\n",
            "|    reward             | -2.7465224 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 3.39       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 20000      |\n",
            "|    time_elapsed       | 1275       |\n",
            "|    total_timesteps    | 100000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19999      |\n",
            "|    policy_loss        | -22.6      |\n",
            "|    reward             | -5.1472864 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 12.3       |\n",
            "--------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.995508e+05  9.905746e+05\n",
            "2021-10-05  1.000363e+06  9.996566e+05\n",
            "2021-10-06  1.001133e+06  1.002637e+06\n",
            "2021-10-07  1.003060e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  1.018303e+06  9.854252e+05\n",
            "2023-04-28  1.025462e+06  9.933491e+05\n",
            "2023-05-01  1.022658e+06  9.919956e+05\n",
            "2023-05-02  1.009662e+06  9.812993e+05\n",
            "2023-05-03  1.000957e+06  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> 0.1 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.405     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -10.7      |\n",
            "|    reward             | 0.03887803 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.733      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.176     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -6.34      |\n",
            "|    reward             | 0.61847246 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.12       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 18         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -15.8      |\n",
            "|    reward             | -2.3233395 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.1        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -1.79      |\n",
            "|    reward             | 0.11999389 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.96       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.065     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -46       |\n",
            "|    reward             | -1.003657 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 12.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.00701     |\n",
            "|    reward             | 0.008772142 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.00407     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.762     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 1.76       |\n",
            "|    reward             | -0.5064193 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.641      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 0.116        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -6.6         |\n",
            "|    reward             | -0.009642381 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.656        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.00371  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.13      |\n",
            "|    reward             | 2.5792797 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 4.89      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0025    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -73.1     |\n",
            "|    reward             | 4.5200224 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 87        |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | -0.00252 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 39.4     |\n",
            "|    reward             | 1.366621 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 11.7     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -7.64       |\n",
            "|    reward             | -0.66268474 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.656       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -9.96      |\n",
            "|    reward             | 0.78307086 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.14       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 47.9      |\n",
            "|    reward             | 1.2445272 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 92          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 39.6        |\n",
            "|    reward             | 0.088697955 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 11          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -10.6     |\n",
            "|    reward             | 1.0065831 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 8.66      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 170       |\n",
            "|    reward             | 11.420798 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 268       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 110      |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -23.8    |\n",
            "|    reward             | 0.605429 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 7.17     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 116        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.00816   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -45.7      |\n",
            "|    reward             | 0.45297435 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 12.4       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 122         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 3.32        |\n",
            "|    reward             | -0.12891024 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.661       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 129       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -18.3     |\n",
            "|    reward             | 3.0691395 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 5.76      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 135        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 38.1       |\n",
            "|    reward             | -0.5714792 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 13.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 141       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 224       |\n",
            "|    reward             | 4.1138344 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 426       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0764    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 24.3      |\n",
            "|    reward             | 0.4075447 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 5.46      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 154       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -0.802    |\n",
            "|    reward             | 0.62278   |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.355     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 160      |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 21.4     |\n",
            "|    reward             | 0.102846 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 4.12     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 166        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -15.4      |\n",
            "|    reward             | -1.1245947 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.43       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 171       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0144    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -46.8     |\n",
            "|    reward             | 2.5664175 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 13.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 177        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 93.4       |\n",
            "|    reward             | -0.3232101 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 59.1       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 184         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | -1.43       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 5.09        |\n",
            "|    reward             | -0.97484034 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.453       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 189       |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -34.3     |\n",
            "|    reward             | 0.3579632 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 10.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 196       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 54.4      |\n",
            "|    reward             | 1.9767181 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 27.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 201        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 12.5       |\n",
            "|    reward             | -1.1998088 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.52       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 207       |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -83.6     |\n",
            "|    reward             | 1.8955313 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 55.6      |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 81            |\n",
            "|    iterations         | 3500          |\n",
            "|    time_elapsed       | 213           |\n",
            "|    total_timesteps    | 17500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.2         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3499          |\n",
            "|    policy_loss        | 162           |\n",
            "|    reward             | -0.0027533958 |\n",
            "|    std                | 1.05          |\n",
            "|    value_loss         | 164           |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 220       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.15     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | -0.0886   |\n",
            "|    reward             | 0.3731401 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.148     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 226         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | 4.62        |\n",
            "|    reward             | -0.42861694 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.71        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 232        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.000267  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | 48         |\n",
            "|    reward             | -0.3048493 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 14.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 238       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.0446   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | -7.47     |\n",
            "|    reward             | 0.8074888 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.74      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 244        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.0408    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -40.5      |\n",
            "|    reward             | -4.4429717 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 9.93       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 81           |\n",
            "|    iterations         | 4100         |\n",
            "|    time_elapsed       | 251          |\n",
            "|    total_timesteps    | 20500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4099         |\n",
            "|    policy_loss        | -29.8        |\n",
            "|    reward             | -0.029739613 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 4.6          |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 257        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.00372    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | -0.252     |\n",
            "|    reward             | -1.1099606 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.855      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 262        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | 39.1       |\n",
            "|    reward             | -0.5063418 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 10.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 268        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -2.72      |\n",
            "|    reward             | -2.8661275 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.729      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 274       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 16.9      |\n",
            "|    reward             | 2.2207928 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.76      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 281        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 42.1       |\n",
            "|    reward             | 0.07039112 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 11.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 287       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.125     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -21.9     |\n",
            "|    reward             | -4.581586 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 3.73      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 293       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.00113  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -9.93     |\n",
            "|    reward             | -1.149043 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.22      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 299         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 26.6        |\n",
            "|    reward             | 0.033719562 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 6.29        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 305       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.0121   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -63.2     |\n",
            "|    reward             | 1.0462433 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 19.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 311        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.00918   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 36         |\n",
            "|    reward             | 0.20741178 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 6.61       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 317        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.0608    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -18        |\n",
            "|    reward             | -1.2020171 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.34       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 323      |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | -0.0328  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | 64       |\n",
            "|    reward             | -3.86573 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 32       |\n",
            "------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4473696.97\n",
            "total_reward: 3473696.97\n",
            "total_cost: 41737.72\n",
            "total_trades: 20363\n",
            "Sharpe: 0.866\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 329       |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | -37.6     |\n",
            "|    reward             | -1.287257 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 9.12      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 81           |\n",
            "|    iterations         | 5500         |\n",
            "|    time_elapsed       | 336          |\n",
            "|    total_timesteps    | 27500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5499         |\n",
            "|    policy_loss        | 37.9         |\n",
            "|    reward             | -0.051799443 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 10.1         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 342         |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.0063      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | 0.156       |\n",
            "|    reward             | -0.07653778 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 3.64        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 348         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | -14.5       |\n",
            "|    reward             | -0.44524613 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 4.26        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 354       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 36.2      |\n",
            "|    reward             | 1.5365888 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 360        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | -70        |\n",
            "|    reward             | -4.3118567 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 24         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 366       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -52.1     |\n",
            "|    reward             | 1.14904   |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 15        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 372       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | -0.938    |\n",
            "|    reward             | 0.8822471 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.233     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 378       |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.00455   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | -77.3     |\n",
            "|    reward             | -2.380086 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 43.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 384        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | 9.32       |\n",
            "|    reward             | -0.1994063 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.808      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 390       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 48.6      |\n",
            "|    reward             | 3.3303027 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 23.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 397         |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | -43.2       |\n",
            "|    reward             | -0.22673544 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 12.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 403        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -39.1      |\n",
            "|    reward             | -2.1862404 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 10.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 409       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 0.244     |\n",
            "|    reward             | 2.5609338 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.113     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 414       |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 9.95      |\n",
            "|    reward             | -1.916218 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.839     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 420         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | -11         |\n",
            "|    reward             | -0.79407966 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 1.43        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 426       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -2.49     |\n",
            "|    reward             | 2.8149316 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.46      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 432        |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -1.33      |\n",
            "|    reward             | 0.04851478 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.0108     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 438         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0.000371    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | -1.64       |\n",
            "|    reward             | -0.66463935 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0535      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 82           |\n",
            "|    iterations         | 7300         |\n",
            "|    time_elapsed       | 444          |\n",
            "|    total_timesteps    | 36500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7299         |\n",
            "|    policy_loss        | -3           |\n",
            "|    reward             | -0.037208606 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.332        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 450        |\n",
            "|    total_timesteps    | 37000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7399       |\n",
            "|    policy_loss        | -35.6      |\n",
            "|    reward             | 0.80968946 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 13.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 7500       |\n",
            "|    time_elapsed       | 456        |\n",
            "|    total_timesteps    | 37500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7499       |\n",
            "|    policy_loss        | 2.82       |\n",
            "|    reward             | 0.73861676 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.76       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 462        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -0.036     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | -3.54      |\n",
            "|    reward             | -0.5961306 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.837      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 82           |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 468          |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.5        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | 2.75         |\n",
            "|    reward             | -0.006469869 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.0612       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 474         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | -0.0267     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | 0.45        |\n",
            "|    reward             | -0.19032775 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.341       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 7900       |\n",
            "|    time_elapsed       | 480        |\n",
            "|    total_timesteps    | 39500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7899       |\n",
            "|    policy_loss        | -4.35      |\n",
            "|    reward             | 0.44067958 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.378      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 486        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0.146      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | 10.3       |\n",
            "|    reward             | 0.23751095 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 493       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -0.0128   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -47.3     |\n",
            "|    reward             | 2.6286976 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 27.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 498       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -306      |\n",
            "|    reward             | -9.365869 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 733       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 504        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | -17.8      |\n",
            "|    reward             | -0.7097943 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 2.1        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 8400       |\n",
            "|    time_elapsed       | 510        |\n",
            "|    total_timesteps    | 42000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 9.54e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8399       |\n",
            "|    policy_loss        | -24.5      |\n",
            "|    reward             | 0.19490848 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 4.22       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 517       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -20       |\n",
            "|    reward             | 1.2231476 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.66      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 523       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | 2.97      |\n",
            "|    reward             | 1.22555   |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.999     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 530       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -46.6     |\n",
            "|    reward             | 1.6120616 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 18        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 536        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 101        |\n",
            "|    reward             | -3.2941713 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 62.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 542       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 17.8      |\n",
            "|    reward             | 1.0631788 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 1.9       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 548         |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0.0223      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | 14.7        |\n",
            "|    reward             | -0.11453523 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 1.82        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 9100       |\n",
            "|    time_elapsed       | 554        |\n",
            "|    total_timesteps    | 45500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9099       |\n",
            "|    policy_loss        | -11.9      |\n",
            "|    reward             | 0.43372166 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.14       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 559        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.000489  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 39.5       |\n",
            "|    reward             | 0.64384407 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 12.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 565       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 23.9      |\n",
            "|    reward             | 2.447402  |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 3.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 571       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 46.3      |\n",
            "|    reward             | 2.6930997 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 34.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 577        |\n",
            "|    total_timesteps    | 47500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | 10.1       |\n",
            "|    reward             | 0.33412942 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.87       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 583        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | -5.39      |\n",
            "|    reward             | -1.5259534 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 1.05       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 589      |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | 0.861    |\n",
            "|    reward             | -1.45297 |\n",
            "|    std                | 1.13     |\n",
            "|    value_loss         | 0.609    |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 9800        |\n",
            "|    time_elapsed       | 595         |\n",
            "|    total_timesteps    | 49000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9799        |\n",
            "|    policy_loss        | -89.8       |\n",
            "|    reward             | -0.33926988 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 45.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 601        |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.00272   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | -19        |\n",
            "|    reward             | 0.73704964 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 2.96       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 607        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.00236   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | 19.8       |\n",
            "|    reward             | -6.0434103 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 3.2        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 613       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -0.00427  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 1.28      |\n",
            "|    reward             | 1.3639187 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.606     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 10200    |\n",
            "|    time_elapsed       | 619      |\n",
            "|    total_timesteps    | 51000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10199    |\n",
            "|    policy_loss        | 22.2     |\n",
            "|    reward             | 1.274218 |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 2.95     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 625       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -11.9     |\n",
            "|    reward             | 1.0857501 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.944     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 632         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0.433       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 98.4        |\n",
            "|    reward             | -0.46180373 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 46.3        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 640       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.94e-05  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 64        |\n",
            "|    reward             | -4.682872 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 31.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 647         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | -2.23e-05   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | -176        |\n",
            "|    reward             | -0.46421266 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 236         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 653       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0.0174    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | 6.06      |\n",
            "|    reward             | 0.6982509 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.218     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 660         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0.000942    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 15.2        |\n",
            "|    reward             | -0.32037637 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 1.68        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 666        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | -4.75      |\n",
            "|    reward             | -1.3857265 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 1.93       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 672        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0.000918   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -5.79      |\n",
            "|    reward             | 0.35503313 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.253      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 81           |\n",
            "|    iterations         | 11100        |\n",
            "|    time_elapsed       | 679          |\n",
            "|    total_timesteps    | 55500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 11099        |\n",
            "|    policy_loss        | 91.1         |\n",
            "|    reward             | -0.025326952 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 73.2         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 685        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | -0.00141   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -12.5      |\n",
            "|    reward             | -2.9999254 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 4.87       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4681187.27\n",
            "total_reward: 3681187.27\n",
            "total_cost: 36698.63\n",
            "total_trades: 21122\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 11300      |\n",
            "|    time_elapsed       | 691        |\n",
            "|    total_timesteps    | 56500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11299      |\n",
            "|    policy_loss        | 17.6       |\n",
            "|    reward             | 0.11260081 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 1.69       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 11400      |\n",
            "|    time_elapsed       | 699        |\n",
            "|    total_timesteps    | 57000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11399      |\n",
            "|    policy_loss        | 12.4       |\n",
            "|    reward             | 0.78243107 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 1.05       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 11500    |\n",
            "|    time_elapsed       | 705      |\n",
            "|    total_timesteps    | 57500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11499    |\n",
            "|    policy_loss        | 23.3     |\n",
            "|    reward             | 2.693862 |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 4.75     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 11600       |\n",
            "|    time_elapsed       | 711         |\n",
            "|    total_timesteps    | 58000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0.368       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11599       |\n",
            "|    policy_loss        | 7.23        |\n",
            "|    reward             | -0.17770916 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.635       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 11700       |\n",
            "|    time_elapsed       | 717         |\n",
            "|    total_timesteps    | 58500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0.0149      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11699       |\n",
            "|    policy_loss        | 43.5        |\n",
            "|    reward             | -0.12122866 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 15.3        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 724       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | -0.12     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | -80.3     |\n",
            "|    reward             | 3.2826612 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 55.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 11900      |\n",
            "|    time_elapsed       | 730        |\n",
            "|    total_timesteps    | 59500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11899      |\n",
            "|    policy_loss        | -28.1      |\n",
            "|    reward             | -0.9189861 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 4.5        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 736        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -24.8      |\n",
            "|    reward             | -2.3881547 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 3.42       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 12100      |\n",
            "|    time_elapsed       | 742        |\n",
            "|    total_timesteps    | 60500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 2.58e-05   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12099      |\n",
            "|    policy_loss        | -4.44      |\n",
            "|    reward             | 0.47160918 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 0.206      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 748        |\n",
            "|    total_timesteps    | 61000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -5.2       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | -35.9      |\n",
            "|    reward             | 0.16557482 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 9.51       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 755       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | -80.2     |\n",
            "|    reward             | 2.6815877 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 42        |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 761      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14      |\n",
            "|    explained_variance | 0.0134   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | 33.2     |\n",
            "|    reward             | 7.100538 |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 13.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 12500    |\n",
            "|    time_elapsed       | 767      |\n",
            "|    total_timesteps    | 62500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14      |\n",
            "|    explained_variance | 0.0117   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12499    |\n",
            "|    policy_loss        | -67.5    |\n",
            "|    reward             | 4.603585 |\n",
            "|    std                | 1.15     |\n",
            "|    value_loss         | 32.4     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 12600       |\n",
            "|    time_elapsed       | 773         |\n",
            "|    total_timesteps    | 63000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12599       |\n",
            "|    policy_loss        | -13.5       |\n",
            "|    reward             | -0.81591517 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.942       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 12700       |\n",
            "|    time_elapsed       | 780         |\n",
            "|    total_timesteps    | 63500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0.0715      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12699       |\n",
            "|    policy_loss        | -40.3       |\n",
            "|    reward             | 0.119016334 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 11          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 12800     |\n",
            "|    time_elapsed       | 786       |\n",
            "|    total_timesteps    | 64000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12799     |\n",
            "|    policy_loss        | 29.1      |\n",
            "|    reward             | 0.5059886 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 6.09      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 792       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | 7.12      |\n",
            "|    reward             | 2.3254268 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 4.92      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 13000     |\n",
            "|    time_elapsed       | 799       |\n",
            "|    total_timesteps    | 65000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12999     |\n",
            "|    policy_loss        | 53.6      |\n",
            "|    reward             | -4.313527 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 27.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 805       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -90.3     |\n",
            "|    reward             | 3.5739472 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 39.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 13200    |\n",
            "|    time_elapsed       | 811      |\n",
            "|    total_timesteps    | 66000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13199    |\n",
            "|    policy_loss        | -21.5    |\n",
            "|    reward             | -1.74262 |\n",
            "|    std                | 1.16     |\n",
            "|    value_loss         | 2.37     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 818       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | -44.9     |\n",
            "|    reward             | 0.8942524 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 13.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 13400     |\n",
            "|    time_elapsed       | 824       |\n",
            "|    total_timesteps    | 67000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13399     |\n",
            "|    policy_loss        | -11.8     |\n",
            "|    reward             | 0.5106975 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 1.28      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 13500     |\n",
            "|    time_elapsed       | 831       |\n",
            "|    total_timesteps    | 67500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13499     |\n",
            "|    policy_loss        | -50.3     |\n",
            "|    reward             | 1.3968877 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 16        |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 13600    |\n",
            "|    time_elapsed       | 837      |\n",
            "|    total_timesteps    | 68000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13599    |\n",
            "|    policy_loss        | -29.4    |\n",
            "|    reward             | 1.719484 |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 5.66     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 843       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0.019     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 35.2      |\n",
            "|    reward             | 1.9116995 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 13.5      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 13800    |\n",
            "|    time_elapsed       | 850      |\n",
            "|    total_timesteps    | 69000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13799    |\n",
            "|    policy_loss        | 13       |\n",
            "|    reward             | 1.695316 |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 1.1      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 856        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 22.7       |\n",
            "|    reward             | -1.9165205 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 7.62       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 14000      |\n",
            "|    time_elapsed       | 862        |\n",
            "|    total_timesteps    | 70000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0.0183     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13999      |\n",
            "|    policy_loss        | 14.1       |\n",
            "|    reward             | 0.14765882 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 2.18       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 14100      |\n",
            "|    time_elapsed       | 868        |\n",
            "|    total_timesteps    | 70500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14099      |\n",
            "|    policy_loss        | 2.47       |\n",
            "|    reward             | -2.3185396 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.192      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 14200      |\n",
            "|    time_elapsed       | 874        |\n",
            "|    total_timesteps    | 71000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14199      |\n",
            "|    policy_loss        | 4.86       |\n",
            "|    reward             | 0.07927778 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.139      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 882       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 12.7      |\n",
            "|    reward             | 0.8138674 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 1.55      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 14400      |\n",
            "|    time_elapsed       | 889        |\n",
            "|    total_timesteps    | 72000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14399      |\n",
            "|    policy_loss        | -64.5      |\n",
            "|    reward             | 0.20352332 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 23.6       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 80           |\n",
            "|    iterations         | 14500        |\n",
            "|    time_elapsed       | 895          |\n",
            "|    total_timesteps    | 72500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 14499        |\n",
            "|    policy_loss        | 0.981        |\n",
            "|    reward             | -0.102986135 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 3.78         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 901        |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 73.4       |\n",
            "|    reward             | -3.2474573 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 31.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 907        |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 3.58e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 105        |\n",
            "|    reward             | -10.862723 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 61.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 14800     |\n",
            "|    time_elapsed       | 914       |\n",
            "|    total_timesteps    | 74000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14799     |\n",
            "|    policy_loss        | 8.24      |\n",
            "|    reward             | 0.2694335 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.475     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 80           |\n",
            "|    iterations         | 14900        |\n",
            "|    time_elapsed       | 920          |\n",
            "|    total_timesteps    | 74500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | 0.000447     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 14899        |\n",
            "|    policy_loss        | -36.6        |\n",
            "|    reward             | -0.067324966 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 8.54         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 926        |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | -0.000635  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -24.7      |\n",
            "|    reward             | -2.1625538 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 6.73       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 933        |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | -0.000769  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 13.5       |\n",
            "|    reward             | -2.7227764 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 2.09       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 939       |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0.000118  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -37.7     |\n",
            "|    reward             | 3.9045575 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 52.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 946        |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -316       |\n",
            "|    reward             | -12.086878 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 723        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 15400      |\n",
            "|    time_elapsed       | 952        |\n",
            "|    total_timesteps    | 77000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0.0118     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15399      |\n",
            "|    policy_loss        | 31.1       |\n",
            "|    reward             | -0.5046548 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 6.82       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 958       |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 39.1      |\n",
            "|    reward             | 1.2671496 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 8         |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 15600     |\n",
            "|    time_elapsed       | 965       |\n",
            "|    total_timesteps    | 78000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15599     |\n",
            "|    policy_loss        | 31.5      |\n",
            "|    reward             | 0.5317254 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 5         |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 15700      |\n",
            "|    time_elapsed       | 971        |\n",
            "|    total_timesteps    | 78500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0.0596     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15699      |\n",
            "|    policy_loss        | 1.01       |\n",
            "|    reward             | 0.81684494 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 0.317      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 977       |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -11.5     |\n",
            "|    reward             | 1.0837673 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 1.81      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 983       |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 76.8      |\n",
            "|    reward             | 1.0965877 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 77.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 990        |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | -0.0215    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | -5.4       |\n",
            "|    reward             | -1.4664147 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 3.34       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 996       |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 12.4      |\n",
            "|    reward             | 1.4476014 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 2.18      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 16200    |\n",
            "|    time_elapsed       | 1003     |\n",
            "|    total_timesteps    | 81000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.4    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16199    |\n",
            "|    policy_loss        | -37.7    |\n",
            "|    reward             | 0.669123 |\n",
            "|    std                | 1.2      |\n",
            "|    value_loss         | 5.65     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 16300      |\n",
            "|    time_elapsed       | 1009       |\n",
            "|    total_timesteps    | 81500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0.0341     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16299      |\n",
            "|    policy_loss        | -25.5      |\n",
            "|    reward             | 0.31767097 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 3.68       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 16400    |\n",
            "|    time_elapsed       | 1015     |\n",
            "|    total_timesteps    | 82000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16399    |\n",
            "|    policy_loss        | -30.2    |\n",
            "|    reward             | 1.683439 |\n",
            "|    std                | 1.21     |\n",
            "|    value_loss         | 7.32     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1021       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0.000779   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | 21.6       |\n",
            "|    reward             | -4.0946984 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 7.4        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1028      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | -0.134    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 2.8       |\n",
            "|    reward             | 0.2932249 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 0.146     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 16700      |\n",
            "|    time_elapsed       | 1034       |\n",
            "|    total_timesteps    | 83500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16699      |\n",
            "|    policy_loss        | -14.8      |\n",
            "|    reward             | 0.99890566 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 1.51       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 16800       |\n",
            "|    time_elapsed       | 1040        |\n",
            "|    total_timesteps    | 84000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.5       |\n",
            "|    explained_variance | 0.604       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16799       |\n",
            "|    policy_loss        | 21.4        |\n",
            "|    reward             | -0.30851406 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 2.34        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1047      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -0.595    |\n",
            "|    reward             | 0.9718019 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 0.649     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1053       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -101       |\n",
            "|    reward             | -0.9798089 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 39.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1059      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -232      |\n",
            "|    reward             | 2.7724128 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 241       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3527587.93\n",
            "total_reward: 2527587.93\n",
            "total_cost: 61944.01\n",
            "total_trades: 24359\n",
            "Sharpe: 0.653\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 17200      |\n",
            "|    time_elapsed       | 1066       |\n",
            "|    total_timesteps    | 86000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | -0.0514    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17199      |\n",
            "|    policy_loss        | -3.5       |\n",
            "|    reward             | 0.06127133 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 0.219      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 1072      |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | -2.27     |\n",
            "|    reward             | 1.2559925 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 0.452     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 17400     |\n",
            "|    time_elapsed       | 1079      |\n",
            "|    total_timesteps    | 87000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17399     |\n",
            "|    policy_loss        | -8.66     |\n",
            "|    reward             | -1.197712 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.739     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 17500      |\n",
            "|    time_elapsed       | 1085       |\n",
            "|    total_timesteps    | 87500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17499      |\n",
            "|    policy_loss        | 9.59       |\n",
            "|    reward             | 0.44791472 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 1.74       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 17600      |\n",
            "|    time_elapsed       | 1091       |\n",
            "|    total_timesteps    | 88000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | -0.000507  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17599      |\n",
            "|    policy_loss        | 75         |\n",
            "|    reward             | -2.6004286 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 23.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1098      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | -5.04     |\n",
            "|    reward             | 3.5588436 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 9.17      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1104       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | -3.98      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 15.1       |\n",
            "|    reward             | 0.82196003 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1111       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -5.99      |\n",
            "|    reward             | -2.7465756 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.166      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1123       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | 23         |\n",
            "|    reward             | 0.28084496 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 2.83       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1129      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | 11.6      |\n",
            "|    reward             | 1.9689133 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 1.81      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 80           |\n",
            "|    iterations         | 18200        |\n",
            "|    time_elapsed       | 1135         |\n",
            "|    total_timesteps    | 91000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.6        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 18199        |\n",
            "|    policy_loss        | 35           |\n",
            "|    reward             | -0.053356282 |\n",
            "|    std                | 1.23         |\n",
            "|    value_loss         | 9.84         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 18300     |\n",
            "|    time_elapsed       | 1141      |\n",
            "|    total_timesteps    | 91500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18299     |\n",
            "|    policy_loss        | -251      |\n",
            "|    reward             | 1.1347266 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 334       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 1147      |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | 18.7      |\n",
            "|    reward             | 0.1720247 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 2.14      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 1153        |\n",
            "|    total_timesteps    | 92500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | -21.8       |\n",
            "|    reward             | -0.53025097 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 6.36        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 1159      |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | 11.9      |\n",
            "|    reward             | 1.1015035 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.873     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1165      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -10.2     |\n",
            "|    reward             | 2.6361392 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.791     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 1171      |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0.0463    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 68.8      |\n",
            "|    reward             | 0.8390613 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 25.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1177       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 60.2       |\n",
            "|    reward             | -2.0297613 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 43.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1183      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | -1.86     |\n",
            "|    reward             | 1.1701459 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 0.465     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1189      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -56.5     |\n",
            "|    reward             | 1.1596614 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 20.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 19200       |\n",
            "|    time_elapsed       | 1195        |\n",
            "|    total_timesteps    | 96000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.5       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19199       |\n",
            "|    policy_loss        | -14.3       |\n",
            "|    reward             | -0.07773372 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 2.19        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 19300      |\n",
            "|    time_elapsed       | 1201       |\n",
            "|    total_timesteps    | 96500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0.000387   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19299      |\n",
            "|    policy_loss        | 6.32       |\n",
            "|    reward             | 0.18660603 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 0.609      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1207      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 111       |\n",
            "|    reward             | 1.7411364 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 75.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 1212      |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | 36.4      |\n",
            "|    reward             | 0.5602293 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 9.96      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 19600      |\n",
            "|    time_elapsed       | 1219       |\n",
            "|    total_timesteps    | 98000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19599      |\n",
            "|    policy_loss        | 31.9       |\n",
            "|    reward             | 0.48327908 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 12.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 19700      |\n",
            "|    time_elapsed       | 1224       |\n",
            "|    total_timesteps    | 98500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19699      |\n",
            "|    policy_loss        | -29.4      |\n",
            "|    reward             | 0.72770184 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 6.14       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 19800    |\n",
            "|    time_elapsed       | 1230     |\n",
            "|    total_timesteps    | 99000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.5    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19799    |\n",
            "|    policy_loss        | 5.72     |\n",
            "|    reward             | -6.92819 |\n",
            "|    std                | 1.22     |\n",
            "|    value_loss         | 0.959    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 19900     |\n",
            "|    time_elapsed       | 1237      |\n",
            "|    total_timesteps    | 99500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19899     |\n",
            "|    policy_loss        | -59.8     |\n",
            "|    reward             | -3.656423 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 15.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 20000     |\n",
            "|    time_elapsed       | 1243      |\n",
            "|    total_timesteps    | 100000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0.000553  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19999     |\n",
            "|    policy_loss        | -70.5     |\n",
            "|    reward             | -9.144638 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 42.9      |\n",
            "-------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.995305e+05  9.905746e+05\n",
            "2021-10-05  1.000287e+06  9.996566e+05\n",
            "2021-10-06  1.000712e+06  1.002637e+06\n",
            "2021-10-07  1.002184e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  1.054705e+06  9.854252e+05\n",
            "2023-04-28  1.066252e+06  9.933491e+05\n",
            "2023-05-01  1.066890e+06  9.919956e+05\n",
            "2023-05-02  1.050525e+06  9.812993e+05\n",
            "2023-05-03  1.041996e+06  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> 4.2 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0.0485     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -16.6      |\n",
            "|    reward             | 0.20563628 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -20.9     |\n",
            "|    reward             | 0.7638232 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.71      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 18         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.019      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 10.5       |\n",
            "|    reward             | -2.8737328 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -35       |\n",
            "|    reward             | 1.1493013 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.36      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -14.6      |\n",
            "|    reward             | -2.5204794 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.39       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 4.06        |\n",
            "|    reward             | -0.08192997 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0997      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -0.182    |\n",
            "|    reward             | -1.144868 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.156     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 11.7        |\n",
            "|    reward             | -0.22210528 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 3.2         |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 14       |\n",
            "|    reward             | 3.131324 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 3.04     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -87.1    |\n",
            "|    reward             | 3.230125 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 114      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 33        |\n",
            "|    reward             | 2.2144144 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 26.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 72         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -10.9      |\n",
            "|    reward             | -0.9458068 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.11       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.0413    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -11.8     |\n",
            "|    reward             | 0.7157859 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.2       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -1.02      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 28.7       |\n",
            "|    reward             | 0.97432286 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.00799    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 23         |\n",
            "|    reward             | -0.6816463 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.16       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 95        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 18.6      |\n",
            "|    reward             | 0.5941767 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 12.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 182       |\n",
            "|    reward             | 11.039723 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 264       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -33.7     |\n",
            "|    reward             | 0.7011044 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 7.71      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 114        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -34.7      |\n",
            "|    reward             | 0.10647869 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 10.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 121        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 18.4       |\n",
            "|    reward             | -0.4656433 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.25       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -20.1     |\n",
            "|    reward             | 3.1660957 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 7         |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 133         |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 18.5        |\n",
            "|    reward             | -0.29642436 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 5.75        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 72.8      |\n",
            "|    reward             | 1.1680676 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 41.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.000103 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 25.1      |\n",
            "|    reward             | 0.3725176 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 4.7       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 151       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -3.86     |\n",
            "|    reward             | 0.7449883 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.3       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 157       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 5.19      |\n",
            "|    reward             | 0.6878057 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 162        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -17.8      |\n",
            "|    reward             | -3.7548025 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.82       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 168       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -32.9     |\n",
            "|    reward             | 1.243888  |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 6.21      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 174        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 10.8       |\n",
            "|    reward             | -0.5539377 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.72       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 181         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -3.58e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 6.59        |\n",
            "|    reward             | -0.78691226 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.443       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 187        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | -23.4      |\n",
            "|    reward             | 0.14368133 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 6.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 194       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 74.7      |\n",
            "|    reward             | 3.5705867 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 50.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 199        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 10.8       |\n",
            "|    reward             | -0.9061542 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.08       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 205        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | -111       |\n",
            "|    reward             | -2.5214684 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 106        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 211       |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 91.3      |\n",
            "|    reward             | -2.431062 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 67.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 217       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 0.086     |\n",
            "|    reward             | 0.7212891 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.0674    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 82          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 223         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -1.2        |\n",
            "|    reward             | 0.038383868 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.899       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 229        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -13.9      |\n",
            "|    reward             | 0.53564155 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 6.6        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 235       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | -8.8      |\n",
            "|    reward             | 0.6088434 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.87      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 241        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -88.5      |\n",
            "|    reward             | -3.1073897 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 46         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 247        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 12.2       |\n",
            "|    reward             | -0.9644876 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.24       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 253        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | -4.75      |\n",
            "|    reward             | -0.8905679 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.07       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 258        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | 35.1       |\n",
            "|    reward             | 0.45893776 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 4.65       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 264       |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | -14.7     |\n",
            "|    reward             | -4.382441 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.69      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 270      |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | 7.57     |\n",
            "|    reward             | 2.979566 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 1.13     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 276        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 49.1       |\n",
            "|    reward             | -1.1526483 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 23.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 282        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 14.3       |\n",
            "|    reward             | -2.4434326 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.63       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 291        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -2.29      |\n",
            "|    reward             | -0.3805216 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 4.03       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 299        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | 8.2        |\n",
            "|    reward             | 0.45393887 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.69       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 305       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -64.5     |\n",
            "|    reward             | 1.0577737 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 26.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 311        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 49.3       |\n",
            "|    reward             | 0.60668665 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 14.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 317        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.00109   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -77        |\n",
            "|    reward             | -0.5268824 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 42.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 324        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 99.4       |\n",
            "|    reward             | -3.6409776 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 60.6       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4265348.21\n",
            "total_reward: 3265348.21\n",
            "total_cost: 11267.00\n",
            "total_trades: 16773\n",
            "Sharpe: 0.803\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 330        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -42.4      |\n",
            "|    reward             | -0.7164783 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 9.34       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 336         |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | 26          |\n",
            "|    reward             | 0.031265326 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 4.4         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 342        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.0832    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -32.4      |\n",
            "|    reward             | 0.85506314 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 11.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 349       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.177    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | 24        |\n",
            "|    reward             | 2.0499682 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 3.13      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 355       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 35.9      |\n",
            "|    reward             | 1.6374184 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 9.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 362        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | -55.6      |\n",
            "|    reward             | -1.6609555 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 20.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 368       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -60.9     |\n",
            "|    reward             | 0.3001715 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 17.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 374       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | 12.9      |\n",
            "|    reward             | 0.5144191 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.79      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 380        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -2.38e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -72.1      |\n",
            "|    reward             | -2.8834147 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 48.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 387        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | 7.48       |\n",
            "|    reward             | 0.28259808 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.84       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 393       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | -3.06     |\n",
            "|    reward             | 2.5549982 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 4.62      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 399        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | 74         |\n",
            "|    reward             | -0.2920565 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 38         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 405        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -37.2      |\n",
            "|    reward             | -2.1482203 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 9.64       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 412       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -5.11     |\n",
            "|    reward             | 1.1468469 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.308     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 418        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0133     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 44.3       |\n",
            "|    reward             | -1.5907776 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 13.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 424        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -33.5      |\n",
            "|    reward             | -1.1887679 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.69       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 430       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | 17.5      |\n",
            "|    reward             | 1.3130766 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2         |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 81           |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 437          |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | -0.0374      |\n",
            "|    reward             | 0.0031248482 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.00335      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 443         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 4.96        |\n",
            "|    reward             | -0.05040864 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.241       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 7300      |\n",
            "|    time_elapsed       | 449       |\n",
            "|    total_timesteps    | 36500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7299      |\n",
            "|    policy_loss        | 10.4      |\n",
            "|    reward             | 0.5567174 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.765     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 455       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0539    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -29.3     |\n",
            "|    reward             | 0.6207325 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 8.3       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 462       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.656     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 6.08      |\n",
            "|    reward             | 1.2519475 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.225     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 468        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 20.4       |\n",
            "|    reward             | -1.1914811 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.82       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 474         |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 1.25        |\n",
            "|    reward             | 0.027870782 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.0416      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 480        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00108   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | 0.425      |\n",
            "|    reward             | -1.6850718 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.232      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 487       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -38.6     |\n",
            "|    reward             | 0.5420715 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 8.96      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 493        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | -18.4      |\n",
            "|    reward             | -1.6629281 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.98       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 499       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -66.8     |\n",
            "|    reward             | 3.2875001 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 27.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 506        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -250       |\n",
            "|    reward             | -6.2482495 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 451        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 512       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | -29.2     |\n",
            "|    reward             | -2.217956 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 6.91      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 518         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -15.8       |\n",
            "|    reward             | -0.46812984 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 1.81        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 8500       |\n",
            "|    time_elapsed       | 524        |\n",
            "|    total_timesteps    | 42500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.0822    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8499       |\n",
            "|    policy_loss        | -2.44      |\n",
            "|    reward             | 0.92255914 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.734      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 530       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | 9.34      |\n",
            "|    reward             | 1.6452279 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.915     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 537       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -46.8     |\n",
            "|    reward             | 3.2798626 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 16.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 543        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 13.1       |\n",
            "|    reward             | -7.2605553 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 6.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 550       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -6.4      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 48.8      |\n",
            "|    reward             | 2.5989833 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 16        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 556        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 20.7       |\n",
            "|    reward             | 0.40350205 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 3.42       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 562      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -22.6    |\n",
            "|    reward             | 1.292255 |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 3.35     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 568       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 28.4      |\n",
            "|    reward             | 0.1763091 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 5.91      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 574       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 46.9      |\n",
            "|    reward             | 3.1204371 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 15.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 9400        |\n",
            "|    time_elapsed       | 581         |\n",
            "|    total_timesteps    | 47000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9399        |\n",
            "|    policy_loss        | 63.4        |\n",
            "|    reward             | -0.08096226 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 40.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 588       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 11.9      |\n",
            "|    reward             | 0.7542291 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 1.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 594        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0.00405    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 5.28       |\n",
            "|    reward             | -0.6208239 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.801      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 600        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 13.3       |\n",
            "|    reward             | -1.2635905 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 2.42       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 606        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -68.8      |\n",
            "|    reward             | 0.25939953 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 27.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 613       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | -10.1     |\n",
            "|    reward             | 1.5206892 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 1.94      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 621       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | 33.2      |\n",
            "|    reward             | -6.259086 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 11.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 627       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | -1.7      |\n",
            "|    reward             | 1.0789922 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.822     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 633       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 14.2      |\n",
            "|    reward             | 0.9564397 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.78      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 640       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -39.3     |\n",
            "|    reward             | 1.0896978 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 8.07      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 646        |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 107        |\n",
            "|    reward             | -1.2085707 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 78         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 652        |\n",
            "|    total_timesteps    | 52500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 50.3       |\n",
            "|    reward             | -3.6436622 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 12.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 659         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | -162        |\n",
            "|    reward             | -0.07030524 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 219         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 669        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | 4.01       |\n",
            "|    reward             | 0.17057595 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.172      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 10800      |\n",
            "|    time_elapsed       | 675        |\n",
            "|    total_timesteps    | 54000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10799      |\n",
            "|    policy_loss        | 13.5       |\n",
            "|    reward             | -0.2557414 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.45       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 682        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | 21.2       |\n",
            "|    reward             | -1.1697415 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 3.73       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 689        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -10.7      |\n",
            "|    reward             | -0.1620429 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.898      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 11100        |\n",
            "|    time_elapsed       | 695          |\n",
            "|    total_timesteps    | 55500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 11099        |\n",
            "|    policy_loss        | 51.3         |\n",
            "|    reward             | -0.086766206 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 26.3         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 11200       |\n",
            "|    time_elapsed       | 701         |\n",
            "|    total_timesteps    | 56000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11199       |\n",
            "|    policy_loss        | 1.3         |\n",
            "|    reward             | 0.048318606 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 5.69        |\n",
            "---------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4381958.56\n",
            "total_reward: 3381958.56\n",
            "total_cost: 4647.76\n",
            "total_trades: 17585\n",
            "Sharpe: 0.883\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 11300       |\n",
            "|    time_elapsed       | 708         |\n",
            "|    total_timesteps    | 56500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11299       |\n",
            "|    policy_loss        | 23.4        |\n",
            "|    reward             | -0.35254732 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 3           |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 714       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 15.1      |\n",
            "|    reward             | 1.1309141 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 1.46      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 720       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 24.7      |\n",
            "|    reward             | 2.4261608 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 5.82      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 11600      |\n",
            "|    time_elapsed       | 727        |\n",
            "|    total_timesteps    | 58000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11599      |\n",
            "|    policy_loss        | 4.99       |\n",
            "|    reward             | -0.5041289 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 2.46       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 11700       |\n",
            "|    time_elapsed       | 733         |\n",
            "|    total_timesteps    | 58500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11699       |\n",
            "|    policy_loss        | 59.9        |\n",
            "|    reward             | -0.37029538 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 19.9        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 11800    |\n",
            "|    time_elapsed       | 739      |\n",
            "|    total_timesteps    | 59000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11799    |\n",
            "|    policy_loss        | 36.3     |\n",
            "|    reward             | 2.617667 |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 19.6     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 11900       |\n",
            "|    time_elapsed       | 746         |\n",
            "|    total_timesteps    | 59500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11899       |\n",
            "|    policy_loss        | -20.2       |\n",
            "|    reward             | 0.051389657 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 2.53        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 752        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -31.3      |\n",
            "|    reward             | -2.3353913 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 6.66       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 758       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -7.98     |\n",
            "|    reward             | 0.6429721 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.312     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 12200     |\n",
            "|    time_elapsed       | 764       |\n",
            "|    total_timesteps    | 61000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12199     |\n",
            "|    policy_loss        | -46.1     |\n",
            "|    reward             | 1.0542488 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 10.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 771       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | -29.4     |\n",
            "|    reward             | 3.2422147 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 10.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 777      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | 107      |\n",
            "|    reward             | 3.646841 |\n",
            "|    std                | 1.13     |\n",
            "|    value_loss         | 89.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 783       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.0242    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -79.9     |\n",
            "|    reward             | 4.8305163 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 33.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 790        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | -6.3       |\n",
            "|    reward             | -1.0387558 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.434      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 12700      |\n",
            "|    time_elapsed       | 796        |\n",
            "|    total_timesteps    | 63500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0.0342     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12699      |\n",
            "|    policy_loss        | -71.5      |\n",
            "|    reward             | 0.13416989 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 20.9       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 12800        |\n",
            "|    time_elapsed       | 802          |\n",
            "|    total_timesteps    | 64000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.9        |\n",
            "|    explained_variance | 0.132        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 12799        |\n",
            "|    policy_loss        | 11.3         |\n",
            "|    reward             | -0.124447785 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 0.825        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 808       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | -1        |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | -36.2     |\n",
            "|    reward             | 2.0352547 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 7.83      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13000      |\n",
            "|    time_elapsed       | 815        |\n",
            "|    total_timesteps    | 65000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0.4        |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12999      |\n",
            "|    policy_loss        | 46.8       |\n",
            "|    reward             | -4.0786843 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 10.8       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 13100    |\n",
            "|    time_elapsed       | 821      |\n",
            "|    total_timesteps    | 65500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13099    |\n",
            "|    policy_loss        | -92.3    |\n",
            "|    reward             | 3.562323 |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 35.8     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 827        |\n",
            "|    total_timesteps    | 66000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | -0.0153    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | -25.8      |\n",
            "|    reward             | -1.3862205 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 4.34       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 834       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0.00917   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | -66.7     |\n",
            "|    reward             | 0.4753559 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 27.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13400      |\n",
            "|    time_elapsed       | 840        |\n",
            "|    total_timesteps    | 67000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -0.801     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13399      |\n",
            "|    policy_loss        | 9.36       |\n",
            "|    reward             | 0.10005683 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 1.12       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 13500        |\n",
            "|    time_elapsed       | 846          |\n",
            "|    total_timesteps    | 67500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14          |\n",
            "|    explained_variance | -0.419       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 13499        |\n",
            "|    policy_loss        | 42.6         |\n",
            "|    reward             | -0.110390544 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 16.2         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13600      |\n",
            "|    time_elapsed       | 853        |\n",
            "|    total_timesteps    | 68000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0.564      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13599      |\n",
            "|    policy_loss        | -23.7      |\n",
            "|    reward             | -1.9686342 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 5.51       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 859       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -0.152    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 43.9      |\n",
            "|    reward             | 2.3431067 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 26.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 865       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -0.126    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -12.7     |\n",
            "|    reward             | 1.7282293 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.898     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 871        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -0.549     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 12.9       |\n",
            "|    reward             | -1.9719526 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 2.67       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14000      |\n",
            "|    time_elapsed       | 878        |\n",
            "|    total_timesteps    | 70000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0.119      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13999      |\n",
            "|    policy_loss        | -23        |\n",
            "|    reward             | -0.6813989 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 4.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14100     |\n",
            "|    time_elapsed       | 884       |\n",
            "|    total_timesteps    | 70500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -4.09     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14099     |\n",
            "|    policy_loss        | -1.31     |\n",
            "|    reward             | 0.6187517 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.637     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14200      |\n",
            "|    time_elapsed       | 890        |\n",
            "|    total_timesteps    | 71000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14199      |\n",
            "|    policy_loss        | 2.47       |\n",
            "|    reward             | 0.13970532 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.0427     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 896       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0.0201    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 28.1      |\n",
            "|    reward             | 0.9338643 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 5.66      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 14400       |\n",
            "|    time_elapsed       | 903         |\n",
            "|    total_timesteps    | 72000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0.167       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14399       |\n",
            "|    policy_loss        | -44         |\n",
            "|    reward             | -0.17183034 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 12.2        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14500      |\n",
            "|    time_elapsed       | 909        |\n",
            "|    total_timesteps    | 72500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0554    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14499      |\n",
            "|    policy_loss        | 42.9       |\n",
            "|    reward             | 0.28545323 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 10.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 14600     |\n",
            "|    time_elapsed       | 916       |\n",
            "|    total_timesteps    | 73000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -0.124    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14599     |\n",
            "|    policy_loss        | 22.8      |\n",
            "|    reward             | -2.468128 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 3.39      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 922        |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.00801   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 36.2       |\n",
            "|    reward             | -4.6545124 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 8.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 929        |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | 2.9        |\n",
            "|    reward             | 0.07776812 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.0746     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 14900       |\n",
            "|    time_elapsed       | 935         |\n",
            "|    total_timesteps    | 74500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14899       |\n",
            "|    policy_loss        | -48.1       |\n",
            "|    reward             | 0.050163027 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 9.42        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 941        |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0.0893     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -11.6      |\n",
            "|    reward             | -1.1276643 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 1.25       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 948        |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0673    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 15.5       |\n",
            "|    reward             | -1.5057105 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 2.55       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 954       |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -0.0324   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -7.17     |\n",
            "|    reward             | 2.7182076 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 8.41      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 960        |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0137    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -189       |\n",
            "|    reward             | -4.8737016 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 261        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15400      |\n",
            "|    time_elapsed       | 966        |\n",
            "|    total_timesteps    | 77000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0.0217     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15399      |\n",
            "|    policy_loss        | 28.7       |\n",
            "|    reward             | -0.4782781 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 7.5        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 972       |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0.106     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 28.9      |\n",
            "|    reward             | 1.3374715 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 6.1       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15600     |\n",
            "|    time_elapsed       | 978       |\n",
            "|    total_timesteps    | 78000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | -0.0219   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15599     |\n",
            "|    policy_loss        | 24.1      |\n",
            "|    reward             | 1.0564885 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 3.74      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 985       |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | -1.22     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | -1.14     |\n",
            "|    reward             | 0.2977269 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.624     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 15800      |\n",
            "|    time_elapsed       | 991        |\n",
            "|    total_timesteps    | 79000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15799      |\n",
            "|    policy_loss        | -49        |\n",
            "|    reward             | 0.05227387 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 13.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 997       |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | -0.0548   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 19.8      |\n",
            "|    reward             | 0.4035646 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 15.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 1003       |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0.192      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | 5.98       |\n",
            "|    reward             | -1.4615163 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.83       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 1009      |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 22.9      |\n",
            "|    reward             | 1.1436354 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 5.28      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16200      |\n",
            "|    time_elapsed       | 1016       |\n",
            "|    total_timesteps    | 81000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.871     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16199      |\n",
            "|    policy_loss        | -20.9      |\n",
            "|    reward             | 0.51863873 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 4.19       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16300      |\n",
            "|    time_elapsed       | 1022       |\n",
            "|    total_timesteps    | 81500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0.0283     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16299      |\n",
            "|    policy_loss        | -25.1      |\n",
            "|    reward             | -0.3631315 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 4.25       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16400      |\n",
            "|    time_elapsed       | 1029       |\n",
            "|    total_timesteps    | 82000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16399      |\n",
            "|    policy_loss        | 5.14       |\n",
            "|    reward             | 0.92821234 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.803      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1036       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0.00593    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | 11.1       |\n",
            "|    reward             | -1.5667048 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 4.14       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1042      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 3.75      |\n",
            "|    reward             | 0.5806861 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.189     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1049      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0.0242    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -30.3     |\n",
            "|    reward             | 1.0468701 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 6.35      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1055       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 16.7       |\n",
            "|    reward             | -1.0446095 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 2.35       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1061      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -3.97     |\n",
            "|    reward             | 1.0556071 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.725     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1067       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -22        |\n",
            "|    reward             | -2.2599752 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 4.56       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1074      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0.0143    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -123      |\n",
            "|    reward             | 2.5297403 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 102       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4147494.27\n",
            "total_reward: 3147494.27\n",
            "total_cost: 16247.58\n",
            "total_trades: 18897\n",
            "Sharpe: 0.810\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 1081        |\n",
            "|    total_timesteps    | 86000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | -0.0849     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | 0.183       |\n",
            "|    reward             | -0.17690717 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.148       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 17300    |\n",
            "|    time_elapsed       | 1088     |\n",
            "|    total_timesteps    | 86500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17299    |\n",
            "|    policy_loss        | -11.4    |\n",
            "|    reward             | 0.612601 |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 0.873    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 17400      |\n",
            "|    time_elapsed       | 1096       |\n",
            "|    total_timesteps    | 87000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | -0.0612    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17399      |\n",
            "|    policy_loss        | -56        |\n",
            "|    reward             | -0.6809455 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 19         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 1102      |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | 2.94      |\n",
            "|    reward             | 0.6126405 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 1.36      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 17600      |\n",
            "|    time_elapsed       | 1108       |\n",
            "|    total_timesteps    | 88000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17599      |\n",
            "|    policy_loss        | 109        |\n",
            "|    reward             | -0.4422373 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 66.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1115      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | 41.4      |\n",
            "|    reward             | 2.3126876 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 13.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1121       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 14.6       |\n",
            "|    reward             | 0.95474195 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.3        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1127       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | -0.573     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -4.31      |\n",
            "|    reward             | -2.7301886 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.186      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 18000       |\n",
            "|    time_elapsed       | 1133        |\n",
            "|    total_timesteps    | 90000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17999       |\n",
            "|    policy_loss        | -5.99       |\n",
            "|    reward             | -0.19833586 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.841       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 18100      |\n",
            "|    time_elapsed       | 1142       |\n",
            "|    total_timesteps    | 90500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18099      |\n",
            "|    policy_loss        | -16.7      |\n",
            "|    reward             | 0.43336013 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 1.62       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 1150       |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | 22.2       |\n",
            "|    reward             | -0.7217854 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 8          |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 18300       |\n",
            "|    time_elapsed       | 1158        |\n",
            "|    total_timesteps    | 91500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18299       |\n",
            "|    policy_loss        | -159        |\n",
            "|    reward             | -0.88483083 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 140         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 1166      |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | 29.8      |\n",
            "|    reward             | 0.8458456 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 4.91      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 18500      |\n",
            "|    time_elapsed       | 1173       |\n",
            "|    total_timesteps    | 92500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18499      |\n",
            "|    policy_loss        | -13.3      |\n",
            "|    reward             | -0.4408193 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 5.22       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 18600    |\n",
            "|    time_elapsed       | 1180     |\n",
            "|    total_timesteps    | 93000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18599    |\n",
            "|    policy_loss        | 17.5     |\n",
            "|    reward             | 0.519609 |\n",
            "|    std                | 1.18     |\n",
            "|    value_loss         | 1.81     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1191      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -15.1     |\n",
            "|    reward             | 1.8714771 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 1.11      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 1202      |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 51.5      |\n",
            "|    reward             | 0.5055391 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 15.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1215       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 45.7       |\n",
            "|    reward             | -1.0052736 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 15.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1226      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | -1.6      |\n",
            "|    reward             | 1.1591804 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 0.857     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1235      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -63       |\n",
            "|    reward             | 0.8511552 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 29.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 19200       |\n",
            "|    time_elapsed       | 1246        |\n",
            "|    total_timesteps    | 96000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19199       |\n",
            "|    policy_loss        | -1.06       |\n",
            "|    reward             | 0.015355444 |\n",
            "|    std                | 1.19        |\n",
            "|    value_loss         | 0.919       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19300     |\n",
            "|    time_elapsed       | 1259      |\n",
            "|    total_timesteps    | 96500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | -0.000508 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19299     |\n",
            "|    policy_loss        | -22.6     |\n",
            "|    reward             | 0.9042093 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 4.02      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1268      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 82.6      |\n",
            "|    reward             | 2.1402972 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 36.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 19500    |\n",
            "|    time_elapsed       | 1279     |\n",
            "|    total_timesteps    | 97500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19499    |\n",
            "|    policy_loss        | 19.2     |\n",
            "|    reward             | 1.585081 |\n",
            "|    std                | 1.19     |\n",
            "|    value_loss         | 3.08     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1290      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 31.6      |\n",
            "|    reward             | 0.8135772 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 13.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 19700     |\n",
            "|    time_elapsed       | 1300      |\n",
            "|    total_timesteps    | 98500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19699     |\n",
            "|    policy_loss        | -31.4     |\n",
            "|    reward             | 1.3989084 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 7.94      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 19800      |\n",
            "|    time_elapsed       | 1310       |\n",
            "|    total_timesteps    | 99000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19799      |\n",
            "|    policy_loss        | 20.4       |\n",
            "|    reward             | -7.9638395 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 1.95       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1319       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -53.5      |\n",
            "|    reward             | -3.1766112 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 12.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 20000      |\n",
            "|    time_elapsed       | 1329       |\n",
            "|    total_timesteps    | 100000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0.00184    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19999      |\n",
            "|    policy_loss        | -39.6      |\n",
            "|    reward             | -7.9504776 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 26         |\n",
            "--------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.998259e+05  9.905746e+05\n",
            "2021-10-05  1.000212e+06  9.996566e+05\n",
            "2021-10-06  1.000129e+06  1.002637e+06\n",
            "2021-10-07  1.001189e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  9.430053e+05  9.854252e+05\n",
            "2023-04-28  9.483860e+05  9.933491e+05\n",
            "2023-05-01  9.405194e+05  9.919956e+05\n",
            "2023-05-02  9.268725e+05  9.812993e+05\n",
            "2023-05-03  9.174277e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A2C로 얻은 투자 수익률>> -8.26 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 56          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0.541       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -10.1       |\n",
            "|    reward             | 0.089778215 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 1.11        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 53         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 18         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.0136    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 3.36       |\n",
            "|    reward             | 0.80991584 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.75       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 55       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | -0.626   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -3.15    |\n",
            "|    reward             | -3.19821 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 4.12     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 59          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0.0102      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -29.5       |\n",
            "|    reward             | 0.046063937 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 6.61        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 62         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.195      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -60.9      |\n",
            "|    reward             | -1.5628017 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 22.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 65         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 45         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -2.19      |\n",
            "|    reward             | 0.01199847 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0349     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 67          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.492       |\n",
            "|    reward             | -0.13877404 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.023       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 68           |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | -0.178       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -8.52        |\n",
            "|    reward             | -0.050645478 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.821        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.161    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 8.63      |\n",
            "|    reward             | 1.6699114 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.48      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0104    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -70.6     |\n",
            "|    reward             | 3.3562217 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 63.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 76        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0206    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 66.1      |\n",
            "|    reward             | 1.0703032 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 27.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 82         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -10.2      |\n",
            "|    reward             | -0.7654263 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.04       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | -0.0474  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -14      |\n",
            "|    reward             | 0.631544 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 1.56     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 94         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.0921    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 36.8       |\n",
            "|    reward             | 0.75860935 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 10.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 31         |\n",
            "|    reward             | -0.3200455 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 8.83       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.0623    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -12.1      |\n",
            "|    reward             | 0.89537007 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 7.22       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0129    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 249       |\n",
            "|    reward             | 12.990798 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 310       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -21.4     |\n",
            "|    reward             | 0.5140361 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 4.4       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 125        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.16      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -51.6      |\n",
            "|    reward             | 0.32548934 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 16.7       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 132          |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | 0.011        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | 0.0746       |\n",
            "|    reward             | -0.117454864 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.438        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0483    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -12.8     |\n",
            "|    reward             | 2.6994872 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 4.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 145        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0111     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 33.5       |\n",
            "|    reward             | -1.5091227 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 8.96       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 151       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.00149   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 193       |\n",
            "|    reward             | 3.8897674 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 284       |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 157          |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | 0.275        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 33.4         |\n",
            "|    reward             | 0.0076362477 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 7.34         |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 164      |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0.0492   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -13.8    |\n",
            "|    reward             | 0.83184  |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 1.91     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2600       |\n",
            "|    time_elapsed       | 170        |\n",
            "|    total_timesteps    | 13000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0212    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2599       |\n",
            "|    policy_loss        | 11.7       |\n",
            "|    reward             | 0.13205384 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 176        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.037     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -8.37      |\n",
            "|    reward             | -1.0099179 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.959      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 182       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0191    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -46.4     |\n",
            "|    reward             | 1.5890181 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 16.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 188        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.021      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 88         |\n",
            "|    reward             | 0.61827946 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 64.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 194         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -0.0043     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 5.15        |\n",
            "|    reward             | -0.84574616 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.384       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 200        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0754     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | -31.9      |\n",
            "|    reward             | 0.19315983 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 8.09       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 206       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.00364  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 63        |\n",
            "|    reward             | 1.3658131 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 24.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 212        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0118     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 3.64       |\n",
            "|    reward             | -0.6788435 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.247      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 218        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.000767  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | -100       |\n",
            "|    reward             | -1.5477494 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 117        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 224        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.00376    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | 95         |\n",
            "|    reward             | 0.38996172 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 65.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 230       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | -2.45     |\n",
            "|    reward             | 0.3424705 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.141     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 236        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.000541  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 6.56       |\n",
            "|    reward             | -0.5763279 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.6        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 242         |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -0.0128     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | 26          |\n",
            "|    reward             | -0.66549176 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 8.66        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 248        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0187    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | -9.87      |\n",
            "|    reward             | 0.73120123 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.88       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 255       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.196     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -38.2     |\n",
            "|    reward             | -4.629286 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 9.6       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.212     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | -32.8      |\n",
            "|    reward             | -0.7965907 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 9.18       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 272         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0.0154      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | 1.1         |\n",
            "|    reward             | -0.81517863 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.998       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 280         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0.000185    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 28.1        |\n",
            "|    reward             | -0.40859392 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 6.76        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 289        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0235    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -16.9      |\n",
            "|    reward             | -3.9268985 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.64       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 297       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0288    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 29.1      |\n",
            "|    reward             | 1.3446637 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 4.77      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 305         |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -0.0116     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | 36.1        |\n",
            "|    reward             | 0.001426838 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 12.8        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 315       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -9.59     |\n",
            "|    reward             | -2.690768 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 3.6       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 324         |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0.0198      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | -5.26       |\n",
            "|    reward             | -0.84304786 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.801       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 334        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | 1.32       |\n",
            "|    reward             | 0.23091929 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.691      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 342       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.202    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -66.4     |\n",
            "|    reward             | 1.1310287 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 25.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 352        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.00458    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 35.4       |\n",
            "|    reward             | 0.46920627 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 9.3        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 71          |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 361         |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | 3.83        |\n",
            "|    reward             | -0.95820224 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.508       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 371        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.000179   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 92.1       |\n",
            "|    reward             | -7.0635157 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 63.1       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 6550786.86\n",
            "total_reward: 5550786.86\n",
            "total_cost: 37414.25\n",
            "total_trades: 19898\n",
            "Sharpe: 1.035\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 71          |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 380         |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.00174     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | -37.9       |\n",
            "|    reward             | -0.99139106 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 6.82        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 389       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.0166   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 18.8      |\n",
            "|    reward             | 0.3283698 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 3.43      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 399        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.000101   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -18.7      |\n",
            "|    reward             | 0.43111324 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.81       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 408         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | -0.0016     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | -9.21       |\n",
            "|    reward             | -0.15552486 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.35        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 417       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.00155   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 43.4      |\n",
            "|    reward             | 1.0321164 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 19.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 426       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.00405   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | -11.1     |\n",
            "|    reward             | 0.9345266 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 9.64      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 436       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.000924  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -45       |\n",
            "|    reward             | 1.0734257 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 12.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 444        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00207   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 5.98       |\n",
            "|    reward             | 0.35355595 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.769      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 453        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -61.6      |\n",
            "|    reward             | -2.5997467 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 41.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 462        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.0932    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | -2.36      |\n",
            "|    reward             | 0.45315403 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.76       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 469       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.00449  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 66.3      |\n",
            "|    reward             | 6.0438395 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 54.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 477        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.000856   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | -52.7      |\n",
            "|    reward             | 0.15843447 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 24.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 485        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.000599  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -42        |\n",
            "|    reward             | -1.8972771 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 10.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 492       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0297    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 1.4       |\n",
            "|    reward             | 1.5154784 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.139     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 67         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 500        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.318     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 47.2       |\n",
            "|    reward             | -1.6794206 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 11.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 506        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.00361    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -26.5      |\n",
            "|    reward             | -0.5916013 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 5.4        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 513       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0483    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -15.5     |\n",
            "|    reward             | 1.9932175 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 3.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 520        |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -2.63      |\n",
            "|    reward             | 0.05350582 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.0474     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 528         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.151       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 6.07        |\n",
            "|    reward             | -0.10049921 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.238       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 535        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | 2.72       |\n",
            "|    reward             | 0.10722846 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.435      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 542       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -67.1     |\n",
            "|    reward             | 2.6175532 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 37        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 549       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.00945   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | -17.6     |\n",
            "|    reward             | 3.5300982 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 3.47      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 7600     |\n",
            "|    time_elapsed       | 555      |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7599     |\n",
            "|    policy_loss        | 47.1     |\n",
            "|    reward             | 8.628451 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 20.2     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 561        |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | 6.36       |\n",
            "|    reward             | 0.03915644 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.233      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 567        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | 24         |\n",
            "|    reward             | -0.7705225 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.75       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 573       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -45.4     |\n",
            "|    reward             | 1.0168281 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 13.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 579        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | -24.3      |\n",
            "|    reward             | 0.22765994 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.76       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 585      |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | -0.0396  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | -74.6    |\n",
            "|    reward             | 5.818669 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 57.4     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 591        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.00165   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -401       |\n",
            "|    reward             | -12.475874 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.06e+03   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 597        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.806     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | 8.06       |\n",
            "|    reward             | -1.0714562 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 5.3        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 8400       |\n",
            "|    time_elapsed       | 603        |\n",
            "|    total_timesteps    | 42000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.0912    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8399       |\n",
            "|    policy_loss        | -31.9      |\n",
            "|    reward             | 0.25992322 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.83       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 609       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.0986   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 7.41      |\n",
            "|    reward             | 1.4806445 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.28      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 615       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0302    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | -7.4      |\n",
            "|    reward             | 2.7102253 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.35      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 621       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.102     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -58       |\n",
            "|    reward             | 3.4732614 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 27.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 627        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.0465    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 102        |\n",
            "|    reward             | -1.6028315 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 91.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 633       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.00298  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 37.6      |\n",
            "|    reward             | 1.9809954 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 7.46      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 639        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.108      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 21.8       |\n",
            "|    reward             | 0.19175631 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.54       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 70       |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 645      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0.00436  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -4.71    |\n",
            "|    reward             | 0.76948  |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.331    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 651        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.158      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 45.8       |\n",
            "|    reward             | 0.98090655 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 12.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 657       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0176    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 42.3      |\n",
            "|    reward             | 5.1725993 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 663       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.0187   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 84.2      |\n",
            "|    reward             | 6.3319793 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 71.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 669         |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.00128     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | 15.7        |\n",
            "|    reward             | 0.108863175 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.64        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 675        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00124   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 1.17       |\n",
            "|    reward             | -1.9160545 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.19       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 682        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | -4.4       |\n",
            "|    reward             | -1.1134174 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.801      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 688        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -93.1      |\n",
            "|    reward             | -0.6189433 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 56.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 694        |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.000429  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | -43.9      |\n",
            "|    reward             | 0.21079575 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 14.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 700        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00216   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | 70.7       |\n",
            "|    reward             | -14.231119 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 49.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 706       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.0016   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 3.52      |\n",
            "|    reward             | 1.2172691 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.645     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 712       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0297    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 19        |\n",
            "|    reward             | 1.0694867 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 3.77      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 718       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.123     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -12.6     |\n",
            "|    reward             | 0.9203502 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 1.25      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 71          |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 724         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 124         |\n",
            "|    reward             | -0.35839698 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 97.5        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 730       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0495    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 45.1      |\n",
            "|    reward             | -8.047052 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 27.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 10600      |\n",
            "|    time_elapsed       | 736        |\n",
            "|    total_timesteps    | 53000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.0154     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10599      |\n",
            "|    policy_loss        | -234       |\n",
            "|    reward             | 0.41653106 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 392        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 742        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.00252    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | 4.53       |\n",
            "|    reward             | 0.46511233 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.176      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 749         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.0798      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | -3.69       |\n",
            "|    reward             | -0.11938877 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.175       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 757        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0.107      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | 7.17       |\n",
            "|    reward             | -3.6951668 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.85       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 11000     |\n",
            "|    time_elapsed       | 765       |\n",
            "|    total_timesteps    | 55000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.0412   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10999     |\n",
            "|    policy_loss        | -8.67     |\n",
            "|    reward             | 0.8365295 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.556     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 11100      |\n",
            "|    time_elapsed       | 772        |\n",
            "|    total_timesteps    | 55500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11099      |\n",
            "|    policy_loss        | 129        |\n",
            "|    reward             | 0.26221815 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 121        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 779        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -97.4      |\n",
            "|    reward             | -5.0616236 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 54.8       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 7165503.30\n",
            "total_reward: 6165503.30\n",
            "total_cost: 27110.16\n",
            "total_trades: 16255\n",
            "Sharpe: 1.022\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 11300      |\n",
            "|    time_elapsed       | 785        |\n",
            "|    total_timesteps    | 56500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.000101   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11299      |\n",
            "|    policy_loss        | 11.6       |\n",
            "|    reward             | 0.33274105 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.09       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 11400      |\n",
            "|    time_elapsed       | 791        |\n",
            "|    total_timesteps    | 57000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11399      |\n",
            "|    policy_loss        | 2.69       |\n",
            "|    reward             | 0.44069955 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.398      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 797       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.00407  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 20.4      |\n",
            "|    reward             | 2.6154084 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.77      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 11600      |\n",
            "|    time_elapsed       | 803        |\n",
            "|    total_timesteps    | 58000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.511     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11599      |\n",
            "|    policy_loss        | -4.18      |\n",
            "|    reward             | -0.7163102 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 1.19       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 11700      |\n",
            "|    time_elapsed       | 810        |\n",
            "|    total_timesteps    | 58500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.00398    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11699      |\n",
            "|    policy_loss        | 85.9       |\n",
            "|    reward             | -1.9314433 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 51.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 816       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | -120      |\n",
            "|    reward             | 4.7153993 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 154       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 11900      |\n",
            "|    time_elapsed       | 822        |\n",
            "|    total_timesteps    | 59500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.0618    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11899      |\n",
            "|    policy_loss        | -17.7      |\n",
            "|    reward             | -0.3734188 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 2.03       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 828        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -0.209     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -24.9      |\n",
            "|    reward             | -2.1240695 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 3.59       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 12100      |\n",
            "|    time_elapsed       | 835        |\n",
            "|    total_timesteps    | 60500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.05       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12099      |\n",
            "|    policy_loss        | -2.35      |\n",
            "|    reward             | 0.85300696 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.338      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 841        |\n",
            "|    total_timesteps    | 61000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0.000184   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | -76.2      |\n",
            "|    reward             | 0.97550535 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 31.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 847       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | -0.00512  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | -75       |\n",
            "|    reward             | 3.7204833 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 61.9      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 853      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.4    |\n",
            "|    explained_variance | 0.00185  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | 57.8     |\n",
            "|    reward             | 9.281441 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 24.2     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 860       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -0.0105   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -78.1     |\n",
            "|    reward             | 4.7069726 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 36.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 867        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | -3.12      |\n",
            "|    reward             | -0.8940453 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.126      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 12700      |\n",
            "|    time_elapsed       | 873        |\n",
            "|    total_timesteps    | 63500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12699      |\n",
            "|    policy_loss        | -84.1      |\n",
            "|    reward             | 0.59934956 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 32.6       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 12800       |\n",
            "|    time_elapsed       | 879         |\n",
            "|    total_timesteps    | 64000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0.0292      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12799       |\n",
            "|    policy_loss        | 31.8        |\n",
            "|    reward             | -0.11177028 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 5.07        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 885       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -0.0445   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | -13.1     |\n",
            "|    reward             | 2.3921356 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.77      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 13000     |\n",
            "|    time_elapsed       | 891       |\n",
            "|    total_timesteps    | 65000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0.019     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12999     |\n",
            "|    policy_loss        | 59.4      |\n",
            "|    reward             | -5.057819 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 28.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 898       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.000285 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -92.3     |\n",
            "|    reward             | 3.3498175 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 42        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 904        |\n",
            "|    total_timesteps    | 66000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.00045    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | -18.8      |\n",
            "|    reward             | -1.8847479 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 2.3        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 910       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -0.0112   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | -53.7     |\n",
            "|    reward             | 1.3978313 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 24.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 13400      |\n",
            "|    time_elapsed       | 916        |\n",
            "|    total_timesteps    | 67000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.102      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13399      |\n",
            "|    policy_loss        | -25.9      |\n",
            "|    reward             | 0.14342579 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 3.94       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 13500        |\n",
            "|    time_elapsed       | 922          |\n",
            "|    total_timesteps    | 67500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | 0.0521       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 13499        |\n",
            "|    policy_loss        | -26.9        |\n",
            "|    reward             | -0.057384253 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 5.59         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 13600       |\n",
            "|    time_elapsed       | 929         |\n",
            "|    total_timesteps    | 68000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | -0.00835    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13599       |\n",
            "|    policy_loss        | -66         |\n",
            "|    reward             | -0.00448529 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 28.5        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 935       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -0.000536 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 37.5      |\n",
            "|    reward             | 1.9957346 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 12.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 942       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.0126    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | 6.47      |\n",
            "|    reward             | 1.7753394 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.459     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 949        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.0019     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 16.4       |\n",
            "|    reward             | -1.8611233 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 5.52       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 956         |\n",
            "|    total_timesteps    | 70000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 2.87e-05    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | 8.77        |\n",
            "|    reward             | 0.118699096 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 1.66        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 14100      |\n",
            "|    time_elapsed       | 962        |\n",
            "|    total_timesteps    | 70500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14099      |\n",
            "|    policy_loss        | 2.83       |\n",
            "|    reward             | -2.3195856 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.177      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 14200       |\n",
            "|    time_elapsed       | 968         |\n",
            "|    total_timesteps    | 71000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14199       |\n",
            "|    policy_loss        | 2.39        |\n",
            "|    reward             | 0.036328822 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.042       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 14300    |\n",
            "|    time_elapsed       | 975      |\n",
            "|    total_timesteps    | 71500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 0.000245 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14299    |\n",
            "|    policy_loss        | 14.5     |\n",
            "|    reward             | 0.958221 |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 2.15     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 14400      |\n",
            "|    time_elapsed       | 981        |\n",
            "|    total_timesteps    | 72000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14399      |\n",
            "|    policy_loss        | -77.4      |\n",
            "|    reward             | 0.08451599 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 30.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 14500      |\n",
            "|    time_elapsed       | 987        |\n",
            "|    total_timesteps    | 72500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.000615  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14499      |\n",
            "|    policy_loss        | 7.73       |\n",
            "|    reward             | -0.4850456 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 4.03       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 994        |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.00141    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 70.1       |\n",
            "|    reward             | -2.4092026 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 37.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 1000       |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.000632  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 68.8       |\n",
            "|    reward             | -8.3304615 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 29.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 1006       |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -61.6      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | 135        |\n",
            "|    reward             | 0.48346323 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 79.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 14900       |\n",
            "|    time_elapsed       | 1013        |\n",
            "|    total_timesteps    | 74500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | -0.00251    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14899       |\n",
            "|    policy_loss        | -37.8       |\n",
            "|    reward             | -0.33724102 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 10.2        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 1019       |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.045      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -25.7      |\n",
            "|    reward             | -2.0324624 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 5.33       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 1026       |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.128     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 3.46       |\n",
            "|    reward             | -2.6583188 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.17       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 1032      |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.0319   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -29.6     |\n",
            "|    reward             | 3.1062331 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 35.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 1038       |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.0165     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -236       |\n",
            "|    reward             | -11.347334 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 441        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 1046        |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | -0.582      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 28          |\n",
            "|    reward             | -0.10057309 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 6.29        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 1052      |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00442   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 29.3      |\n",
            "|    reward             | 1.1254501 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 6.24      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 15600     |\n",
            "|    time_elapsed       | 1059      |\n",
            "|    total_timesteps    | 78000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00475   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15599     |\n",
            "|    policy_loss        | 10.2      |\n",
            "|    reward             | 0.6222888 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.688     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 15700    |\n",
            "|    time_elapsed       | 1065     |\n",
            "|    total_timesteps    | 78500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.7    |\n",
            "|    explained_variance | -0.0078  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15699    |\n",
            "|    policy_loss        | -0.0198  |\n",
            "|    reward             | 0.770411 |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.278    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 1071      |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00144   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -18.6     |\n",
            "|    reward             | 2.1928105 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.47      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 1078      |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.00865   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 50.2      |\n",
            "|    reward             | 3.0927804 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 58.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 16000     |\n",
            "|    time_elapsed       | 1084      |\n",
            "|    total_timesteps    | 80000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.000126 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15999     |\n",
            "|    policy_loss        | -1.04     |\n",
            "|    reward             | -1.692615 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 2.78      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 1090      |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.0326    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 14.6      |\n",
            "|    reward             | 1.5629555 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 2.91      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1097      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.0653    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -18.7     |\n",
            "|    reward             | 0.6039723 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 3.02      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 16300       |\n",
            "|    time_elapsed       | 1103        |\n",
            "|    total_timesteps    | 81500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | -0.0397     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16299       |\n",
            "|    policy_loss        | -35.7       |\n",
            "|    reward             | -0.28939572 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 7.13        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 1110      |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.369    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | 23.6      |\n",
            "|    reward             | 1.6753217 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 7.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1132       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0.0708     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | 27.5       |\n",
            "|    reward             | -4.0251493 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 5.46       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1139      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.0745    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 3.64      |\n",
            "|    reward             | 1.1090904 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.166     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1145      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.0365   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -39.2     |\n",
            "|    reward             | 0.8535626 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 8.68      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1151       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.443     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | -4.3       |\n",
            "|    reward             | 0.15903819 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 2.88       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1157      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.119     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | 5.06      |\n",
            "|    reward             | 0.6038601 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.736     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1163       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.0386     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -49.6      |\n",
            "|    reward             | -1.2404487 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 17.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1169      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00092   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -158      |\n",
            "|    reward             | 1.6117945 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 145       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3507908.33\n",
            "total_reward: 2507908.33\n",
            "total_cost: 70174.22\n",
            "total_trades: 19617\n",
            "Sharpe: 0.671\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 1176        |\n",
            "|    total_timesteps    | 86000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | -0.197      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | 6.07        |\n",
            "|    reward             | 0.097981796 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.241       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 17300      |\n",
            "|    time_elapsed       | 1182       |\n",
            "|    total_timesteps    | 86500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.0718     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17299      |\n",
            "|    policy_loss        | -9.04      |\n",
            "|    reward             | 0.58775264 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.628      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 17400      |\n",
            "|    time_elapsed       | 1188       |\n",
            "|    total_timesteps    | 87000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.295      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17399      |\n",
            "|    policy_loss        | -14.2      |\n",
            "|    reward             | -1.3820419 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 1194      |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.0247    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | -11.2     |\n",
            "|    reward             | 1.4698741 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 1.2       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 17600       |\n",
            "|    time_elapsed       | 1200        |\n",
            "|    total_timesteps    | 88000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0.0681      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17599       |\n",
            "|    policy_loss        | 94.9        |\n",
            "|    reward             | -0.81326824 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 46.9        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1206      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.025     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | -16.3     |\n",
            "|    reward             | 2.1244645 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 12.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 1212      |\n",
            "|    total_timesteps    | 89000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0.104     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | 0.812     |\n",
            "|    reward             | 0.9212858 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.102     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1218       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.889     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -4.39      |\n",
            "|    reward             | -2.3026369 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.146      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1224       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.000973   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | 14.1       |\n",
            "|    reward             | 0.54534596 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.58       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1231      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.233    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | -5.26     |\n",
            "|    reward             | 1.0197768 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.55      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 1238       |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.000936  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | 40         |\n",
            "|    reward             | 0.49623096 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 18.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 1244       |\n",
            "|    total_timesteps    | 91500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.00636   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -153       |\n",
            "|    reward             | -1.3284004 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 159        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 18400      |\n",
            "|    time_elapsed       | 1250       |\n",
            "|    total_timesteps    | 92000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.000971  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18399      |\n",
            "|    policy_loss        | 23.8       |\n",
            "|    reward             | 0.28380054 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 3.22       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 1256        |\n",
            "|    total_timesteps    | 92500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | -13.8       |\n",
            "|    reward             | -0.27356476 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 4.25        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 1262      |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | 7.95      |\n",
            "|    reward             | 0.9458994 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.984     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1269      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -6.68     |\n",
            "|    reward             | 1.8898104 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.385     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 18800      |\n",
            "|    time_elapsed       | 1275       |\n",
            "|    total_timesteps    | 94000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0.000338   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18799      |\n",
            "|    policy_loss        | 25.3       |\n",
            "|    reward             | -0.6279711 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 8.52       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1281       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.00371   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 41.1       |\n",
            "|    reward             | -0.4441303 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 34.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1286      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0.00136   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | 3.01      |\n",
            "|    reward             | 1.1675758 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.655     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1293      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -0.0183   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -72.2     |\n",
            "|    reward             | 0.9059669 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 23.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 19200       |\n",
            "|    time_elapsed       | 1299        |\n",
            "|    total_timesteps    | 96000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | -0.0263     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19199       |\n",
            "|    policy_loss        | -10.4       |\n",
            "|    reward             | -0.24390142 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 2.51        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 19300    |\n",
            "|    time_elapsed       | 1305     |\n",
            "|    total_timesteps    | 96500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | -0.00242 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19299    |\n",
            "|    policy_loss        | -20.3    |\n",
            "|    reward             | 0.462203 |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 2.52     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1311      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0.0391    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 110       |\n",
            "|    reward             | 1.2102566 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 70.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 1317      |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | 31.3      |\n",
            "|    reward             | 1.1198848 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 7.5       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 19600    |\n",
            "|    time_elapsed       | 1323     |\n",
            "|    total_timesteps    | 98000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19599    |\n",
            "|    policy_loss        | 30.4     |\n",
            "|    reward             | 0.369576 |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 13.6     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19700      |\n",
            "|    time_elapsed       | 1329       |\n",
            "|    total_timesteps    | 98500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19699      |\n",
            "|    policy_loss        | -24.6      |\n",
            "|    reward             | 0.26199126 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 5.85       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19800      |\n",
            "|    time_elapsed       | 1335       |\n",
            "|    total_timesteps    | 99000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19799      |\n",
            "|    policy_loss        | 8.96       |\n",
            "|    reward             | -7.4057965 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 2.09       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19900     |\n",
            "|    time_elapsed       | 1341      |\n",
            "|    total_timesteps    | 99500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19899     |\n",
            "|    policy_loss        | -60.5     |\n",
            "|    reward             | -4.760741 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 23.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 20000      |\n",
            "|    time_elapsed       | 1347       |\n",
            "|    total_timesteps    | 100000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19999      |\n",
            "|    policy_loss        | -55.4      |\n",
            "|    reward             | -10.503598 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 75         |\n",
            "--------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.992371e+05  9.905746e+05\n",
            "2021-10-05  1.000029e+06  9.996566e+05\n",
            "2021-10-06  1.000326e+06  1.002637e+06\n",
            "2021-10-07  1.002984e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  9.872588e+05  9.854252e+05\n",
            "2023-04-28  9.978986e+05  9.933491e+05\n",
            "2023-05-01  9.991818e+05  9.919956e+05\n",
            "2023-05-02  9.895949e+05  9.812993e+05\n",
            "2023-05-03  9.816709e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -1.83 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.317     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -10.8      |\n",
            "|    reward             | 0.15186559 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.971      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -13.3     |\n",
            "|    reward             | 0.9103223 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -16.5      |\n",
            "|    reward             | -2.8544278 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.43       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -0.0333     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 17.3        |\n",
            "|    reward             | -0.25128388 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 4.25        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -0.121      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 1.46        |\n",
            "|    reward             | -0.19156651 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.736       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 80           |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 1.2          |\n",
            "|    reward             | -0.014598672 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 0.0108       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 1.79        |\n",
            "|    reward             | -0.40412158 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.289       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 53         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.22       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 1.87       |\n",
            "|    reward             | 0.14648089 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.592      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.017    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 12.3      |\n",
            "|    reward             | 3.0432055 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.06      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.00165   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -68.6     |\n",
            "|    reward             | 2.6633382 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 54        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0362    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 49        |\n",
            "|    reward             | 1.4200742 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 17.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -9.4        |\n",
            "|    reward             | -0.67750585 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.721       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.199     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -3.66     |\n",
            "|    reward             | 1.0611537 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.362     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 92        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -8.73e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 17.8      |\n",
            "|    reward             | 0.2557991 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 3.17      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0889     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 25.5       |\n",
            "|    reward             | 0.56681687 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.74       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.0331   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -12.2     |\n",
            "|    reward             | 0.3382525 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 5.65      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 110      |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.2    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 133      |\n",
            "|    reward             | 8.697672 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 178      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 116        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -15.2      |\n",
            "|    reward             | 0.24938062 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.8        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 123        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.141     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -38.7      |\n",
            "|    reward             | 0.15867035 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 8.55       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 129         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0.261       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 5.81        |\n",
            "|    reward             | -0.22707595 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.662       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.0522   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -17.7     |\n",
            "|    reward             | 2.9596734 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 6.34      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 141        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.00208    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 14.3       |\n",
            "|    reward             | -0.7793809 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 4.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.00871   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 257       |\n",
            "|    reward             | 2.7370903 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 439       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 153        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 17.9       |\n",
            "|    reward             | 0.45583773 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.28       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 159       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0332    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -8.54     |\n",
            "|    reward             | 0.7445887 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.801     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2600       |\n",
            "|    time_elapsed       | 166        |\n",
            "|    total_timesteps    | 13000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0419     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2599       |\n",
            "|    policy_loss        | 8.77       |\n",
            "|    reward             | 0.57090724 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.58       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 172        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.221     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 3.49       |\n",
            "|    reward             | -0.1642661 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.161      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 178       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -78.4     |\n",
            "|    reward             | 0.9257472 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 42.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 185       |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.033     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 88.3      |\n",
            "|    reward             | 1.0698097 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 47        |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 191         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -23.6       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 10.3        |\n",
            "|    reward             | -0.48708683 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 1.34        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 197        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.00994    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | -18.5      |\n",
            "|    reward             | -0.2023445 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.8        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 203       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.0166   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 30.2      |\n",
            "|    reward             | 1.0482222 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 8.99      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 209         |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | 3.48        |\n",
            "|    reward             | -0.06885394 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.854       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 215       |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -155      |\n",
            "|    reward             | 1.0362765 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 198       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 221      |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 112      |\n",
            "|    reward             | 2.030207 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 59.7     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 227        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.119      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | -0.334     |\n",
            "|    reward             | 0.10060017 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.0699     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 233       |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.0256    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | -1.68     |\n",
            "|    reward             | -0.603167 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.902     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 239         |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0.0113      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | 33.1        |\n",
            "|    reward             | -0.13752647 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 12.7        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 246        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.244     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | -12.8      |\n",
            "|    reward             | 0.43010473 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.91       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 252        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -57.6      |\n",
            "|    reward             | -4.1562476 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 21.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 258        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.0956     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 22.1       |\n",
            "|    reward             | -1.6712455 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.27       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | 3.56       |\n",
            "|    reward             | -1.2537735 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.682      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 270         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 19.7        |\n",
            "|    reward             | -0.64695966 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 2.95        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 276        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -25.7      |\n",
            "|    reward             | -2.4804826 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.41       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 282      |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | 6.37     |\n",
            "|    reward             | 4.753524 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.719    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 288       |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -0.00418  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 40.3      |\n",
            "|    reward             | -0.788691 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 17.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 294       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -7.72e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 7.61      |\n",
            "|    reward             | 4.7353997 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 5.63      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 302        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.00686   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -9.76      |\n",
            "|    reward             | -0.5206656 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.02       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 310         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 22.2        |\n",
            "|    reward             | -0.27117273 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 4.18        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 319       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -36.7     |\n",
            "|    reward             | 1.0136923 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 6.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 326       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 58.7      |\n",
            "|    reward             | 0.4142301 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 21.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 332       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.00491   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | 11        |\n",
            "|    reward             | 1.5942472 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.8       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 339        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 12.9       |\n",
            "|    reward             | -2.9093747 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 3.54       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3931402.60\n",
            "total_reward: 2931402.60\n",
            "total_cost: 16421.26\n",
            "total_trades: 17319\n",
            "Sharpe: 0.715\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 346        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -39        |\n",
            "|    reward             | -1.1639043 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 8.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 352       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 19.4      |\n",
            "|    reward             | 1.2189027 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.57      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 359         |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | -5.38e-05   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | -11.9       |\n",
            "|    reward             | 0.096520975 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 4.62        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 5700     |\n",
            "|    time_elapsed       | 365      |\n",
            "|    total_timesteps    | 28500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5699     |\n",
            "|    policy_loss        | -14      |\n",
            "|    reward             | 1.584289 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 5.66     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 372       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 46        |\n",
            "|    reward             | 3.2257805 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 16.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 378       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | -48.8     |\n",
            "|    reward             | -0.723036 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 16.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 384        |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | -40.9      |\n",
            "|    reward             | 0.73208207 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 13         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 390       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | 3.64      |\n",
            "|    reward             | 0.7468923 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.142     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 397        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -69        |\n",
            "|    reward             | -2.1747525 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 33.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 6300        |\n",
            "|    time_elapsed       | 403         |\n",
            "|    total_timesteps    | 31500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6299        |\n",
            "|    policy_loss        | 8.49        |\n",
            "|    reward             | -0.13278481 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.821       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 409      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 30.4     |\n",
            "|    reward             | 3.493499 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 9.4      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 416        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | -8.04      |\n",
            "|    reward             | 0.18281849 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 3.54       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 423        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -0.00569   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -32.6      |\n",
            "|    reward             | -1.7582723 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.79       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 430       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 10.1      |\n",
            "|    reward             | 0.9443009 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.818     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 437        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 4.19       |\n",
            "|    reward             | -0.4799409 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.721      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 6900      |\n",
            "|    time_elapsed       | 443       |\n",
            "|    total_timesteps    | 34500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6899      |\n",
            "|    policy_loss        | -9.83     |\n",
            "|    reward             | 1.1217171 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.975     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 449       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | 36.4      |\n",
            "|    reward             | 1.4716691 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 8.71      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 456         |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | -2.04       |\n",
            "|    reward             | 0.030913904 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.0239      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 462         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | -5.53       |\n",
            "|    reward             | 0.012866115 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.35        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 469        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | 0.248      |\n",
            "|    reward             | 0.19741692 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.109      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 475       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -15.9     |\n",
            "|    reward             | 0.2936103 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 3.14      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 481       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 8.97      |\n",
            "|    reward             | 0.4411231 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.525     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 488        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 5.94       |\n",
            "|    reward             | 0.65136755 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.606      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 494          |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | 2.63         |\n",
            "|    reward             | -0.019793805 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.0429       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 500         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | 1.88        |\n",
            "|    reward             | -0.87725526 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.465       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 507       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -4.62     |\n",
            "|    reward             | 0.6621055 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.366     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 514        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | 23.1       |\n",
            "|    reward             | 0.12386999 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 5.76       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 520       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -61.2     |\n",
            "|    reward             | 2.5323756 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 26.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 526       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -295      |\n",
            "|    reward             | -7.246384 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 515       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 533        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | -22.3      |\n",
            "|    reward             | -1.1160624 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 5.18       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 539         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -19.3       |\n",
            "|    reward             | -0.16523759 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 2.7         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 546       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -12.7     |\n",
            "|    reward             | 0.6720988 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 2.11      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8600       |\n",
            "|    time_elapsed       | 552        |\n",
            "|    total_timesteps    | 43000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8599       |\n",
            "|    policy_loss        | 1.72       |\n",
            "|    reward             | 0.92173266 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.187      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 558       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -39.9     |\n",
            "|    reward             | 2.5548084 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 11.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 564       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | 47.8      |\n",
            "|    reward             | -6.955723 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 14.8      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 571      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | 28.3     |\n",
            "|    reward             | 2.205572 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 4.67     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 577         |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | 12.4        |\n",
            "|    reward             | 0.056116574 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 1.44        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 583          |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -6.39        |\n",
            "|    reward             | 0.0023709075 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.628        |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 590      |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | 10.4     |\n",
            "|    reward             | 0.332005 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 1.36     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 596        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | 34.3       |\n",
            "|    reward             | 0.36956123 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 5.24       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 603       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 15.9      |\n",
            "|    reward             | 1.9242402 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 12.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 610       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 10.8      |\n",
            "|    reward             | 0.6742115 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.31      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 617       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9599      |\n",
            "|    policy_loss        | -7.84     |\n",
            "|    reward             | -1.014231 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.04      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 623         |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9699        |\n",
            "|    policy_loss        | 13.2        |\n",
            "|    reward             | -0.68497145 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 1.84        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 629       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9799      |\n",
            "|    policy_loss        | -54.7     |\n",
            "|    reward             | 0.5480478 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 24.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 636         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 21.5        |\n",
            "|    reward             | 0.022124609 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 3.02        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 642        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | -14        |\n",
            "|    reward             | -2.7459867 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 3.21       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 648       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | -1.97     |\n",
            "|    reward             | 1.2115796 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.745     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 656       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 10.8      |\n",
            "|    reward             | 0.8212226 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.27      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 663       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -34.8     |\n",
            "|    reward             | 1.3687705 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 10.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 670        |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 12.1       |\n",
            "|    reward             | -1.4198627 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 3.83       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 676        |\n",
            "|    total_timesteps    | 52500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 32.6       |\n",
            "|    reward             | -2.0976133 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 6.61       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10600      |\n",
            "|    time_elapsed       | 683        |\n",
            "|    total_timesteps    | 53000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10599      |\n",
            "|    policy_loss        | -67.8      |\n",
            "|    reward             | -1.0732073 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 45.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 689        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | 5.77       |\n",
            "|    reward             | 0.55053407 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.344      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10800      |\n",
            "|    time_elapsed       | 695        |\n",
            "|    total_timesteps    | 54000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10799      |\n",
            "|    policy_loss        | 13.8       |\n",
            "|    reward             | -0.3398813 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 1.8        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 702        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | 12.4       |\n",
            "|    reward             | -0.9656798 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 1.86       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 708        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -7.36      |\n",
            "|    reward             | 0.69220877 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 1.94       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11100      |\n",
            "|    time_elapsed       | 715        |\n",
            "|    total_timesteps    | 55500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11099      |\n",
            "|    policy_loss        | 41.9       |\n",
            "|    reward             | 0.66554266 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 15.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 721        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -36.2      |\n",
            "|    reward             | -1.1145617 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 8.53       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3026550.14\n",
            "total_reward: 2026550.14\n",
            "total_cost: 3837.46\n",
            "total_trades: 17950\n",
            "Sharpe: 0.650\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 11300       |\n",
            "|    time_elapsed       | 728         |\n",
            "|    total_timesteps    | 56500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11299       |\n",
            "|    policy_loss        | 20.3        |\n",
            "|    reward             | 0.008953726 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 2.57        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 734       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 12.6      |\n",
            "|    reward             | 0.7590771 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.11      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 741       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 15.7      |\n",
            "|    reward             | 2.5754488 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 3.71      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11600      |\n",
            "|    time_elapsed       | 747        |\n",
            "|    total_timesteps    | 58000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11599      |\n",
            "|    policy_loss        | 3.55       |\n",
            "|    reward             | -0.5348845 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.2        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11700      |\n",
            "|    time_elapsed       | 754        |\n",
            "|    total_timesteps    | 58500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11699      |\n",
            "|    policy_loss        | 33.8       |\n",
            "|    reward             | 0.20267117 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 7.56       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 760       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | 71.8      |\n",
            "|    reward             | 1.7507564 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 38.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 11900     |\n",
            "|    time_elapsed       | 767       |\n",
            "|    total_timesteps    | 59500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11899     |\n",
            "|    policy_loss        | -16.6     |\n",
            "|    reward             | 0.0850893 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.73      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 774        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -40.9      |\n",
            "|    reward             | -1.6587106 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 10.3       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 12100       |\n",
            "|    time_elapsed       | 781         |\n",
            "|    total_timesteps    | 60500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12099       |\n",
            "|    policy_loss        | -8.52       |\n",
            "|    reward             | 0.061720915 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.454       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12200     |\n",
            "|    time_elapsed       | 789       |\n",
            "|    total_timesteps    | 61000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12199     |\n",
            "|    policy_loss        | -13.7     |\n",
            "|    reward             | 0.6366205 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.06      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 796       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | 13.7      |\n",
            "|    reward             | 0.8204543 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.77      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 802      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | 17.3     |\n",
            "|    reward             | 2.425309 |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 2.99     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 12500    |\n",
            "|    time_elapsed       | 809      |\n",
            "|    total_timesteps    | 62500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12499    |\n",
            "|    policy_loss        | -55.9    |\n",
            "|    reward             | 4.317746 |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 18.7     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 816        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | -3.78      |\n",
            "|    reward             | -0.8867525 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.569      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12700      |\n",
            "|    time_elapsed       | 822        |\n",
            "|    total_timesteps    | 63500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12699      |\n",
            "|    policy_loss        | -40.1      |\n",
            "|    reward             | 0.02717365 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 11.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12800     |\n",
            "|    time_elapsed       | 829       |\n",
            "|    total_timesteps    | 64000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12799     |\n",
            "|    policy_loss        | 21.2      |\n",
            "|    reward             | 1.1350695 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.21      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 12900       |\n",
            "|    time_elapsed       | 835         |\n",
            "|    total_timesteps    | 64500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12899       |\n",
            "|    policy_loss        | -19.9       |\n",
            "|    reward             | -0.43795374 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 2.63        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13000     |\n",
            "|    time_elapsed       | 842       |\n",
            "|    total_timesteps    | 65000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12999     |\n",
            "|    policy_loss        | 7.47      |\n",
            "|    reward             | 0.1947201 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 1.22      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 848       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -66.1     |\n",
            "|    reward             | 3.0823762 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 21.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 854        |\n",
            "|    total_timesteps    | 66000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | -21.4      |\n",
            "|    reward             | -0.9560953 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 3.49       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13300      |\n",
            "|    time_elapsed       | 861        |\n",
            "|    total_timesteps    | 66500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13299      |\n",
            "|    policy_loss        | -19.6      |\n",
            "|    reward             | -1.2302558 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 3.22       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 13400       |\n",
            "|    time_elapsed       | 867         |\n",
            "|    total_timesteps    | 67000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13399       |\n",
            "|    policy_loss        | -3.05       |\n",
            "|    reward             | -0.28234872 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.393       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 13500       |\n",
            "|    time_elapsed       | 873         |\n",
            "|    total_timesteps    | 67500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13499       |\n",
            "|    policy_loss        | 21.3        |\n",
            "|    reward             | 0.026841944 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 3.63        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13600      |\n",
            "|    time_elapsed       | 880        |\n",
            "|    total_timesteps    | 68000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13599      |\n",
            "|    policy_loss        | -21.2      |\n",
            "|    reward             | -2.3825889 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 6.8        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 886       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 28.4      |\n",
            "|    reward             | 1.9600527 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 892       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -18.4     |\n",
            "|    reward             | 1.8408686 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 2.47      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 899        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 1.12       |\n",
            "|    reward             | -3.4846282 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.898      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14000      |\n",
            "|    time_elapsed       | 906        |\n",
            "|    total_timesteps    | 70000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13999      |\n",
            "|    policy_loss        | -21.6      |\n",
            "|    reward             | 0.36074337 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 3.75       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14100       |\n",
            "|    time_elapsed       | 912         |\n",
            "|    total_timesteps    | 70500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14099       |\n",
            "|    policy_loss        | 16.8        |\n",
            "|    reward             | -0.21586056 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 2.54        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14200       |\n",
            "|    time_elapsed       | 919         |\n",
            "|    total_timesteps    | 71000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14199       |\n",
            "|    policy_loss        | 3.5         |\n",
            "|    reward             | 0.099665724 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.0838      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 925       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 10.4      |\n",
            "|    reward             | 0.4854005 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 1.04      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14400      |\n",
            "|    time_elapsed       | 931        |\n",
            "|    total_timesteps    | 72000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14399      |\n",
            "|    policy_loss        | -27.5      |\n",
            "|    reward             | 0.45685586 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 4.46       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14500       |\n",
            "|    time_elapsed       | 938         |\n",
            "|    total_timesteps    | 72500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14499       |\n",
            "|    policy_loss        | 38.9        |\n",
            "|    reward             | -0.21475707 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 10.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 944        |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 18.2       |\n",
            "|    reward             | -0.7143734 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 2.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 951        |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 80.3       |\n",
            "|    reward             | -2.0284173 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 30.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 958        |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | 6.17       |\n",
            "|    reward             | 0.44981098 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.262      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 14900     |\n",
            "|    time_elapsed       | 965       |\n",
            "|    total_timesteps    | 74500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14899     |\n",
            "|    policy_loss        | -27.3     |\n",
            "|    reward             | 0.7327249 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 4.96      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 15000       |\n",
            "|    time_elapsed       | 972         |\n",
            "|    total_timesteps    | 75000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14999       |\n",
            "|    policy_loss        | 2.24        |\n",
            "|    reward             | -0.57912666 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 0.267       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15100     |\n",
            "|    time_elapsed       | 979       |\n",
            "|    total_timesteps    | 75500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15099     |\n",
            "|    policy_loss        | 18.2      |\n",
            "|    reward             | -0.974502 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 2.97      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 985       |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -9.79     |\n",
            "|    reward             | 1.7387475 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 5.07      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 15300       |\n",
            "|    time_elapsed       | 992         |\n",
            "|    total_timesteps    | 76500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15299       |\n",
            "|    policy_loss        | -350        |\n",
            "|    reward             | -0.92016125 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 911         |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 998         |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | -0.271      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 25.2        |\n",
            "|    reward             | -0.19958515 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 5.79        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15500      |\n",
            "|    time_elapsed       | 1004       |\n",
            "|    total_timesteps    | 77500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15499      |\n",
            "|    policy_loss        | 31.7       |\n",
            "|    reward             | 0.85460955 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 6.56       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 1011       |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 14.7       |\n",
            "|    reward             | 0.92306334 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 1017      |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | 20.6      |\n",
            "|    reward             | 1.0880005 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 2.6       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 15800       |\n",
            "|    time_elapsed       | 1024        |\n",
            "|    total_timesteps    | 79000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15799       |\n",
            "|    policy_loss        | 15.3        |\n",
            "|    reward             | -0.99341834 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 2.38        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 1030      |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 10.8      |\n",
            "|    reward             | 0.9667155 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 14.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 1036       |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.0347    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | -0.533     |\n",
            "|    reward             | -0.7766474 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 1.69       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16100      |\n",
            "|    time_elapsed       | 1042       |\n",
            "|    total_timesteps    | 80500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.000174  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16099      |\n",
            "|    policy_loss        | 0.73       |\n",
            "|    reward             | 0.25296566 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.462      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1049      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -25.6     |\n",
            "|    reward             | 0.8062734 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 3.96      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 16300        |\n",
            "|    time_elapsed       | 1055         |\n",
            "|    total_timesteps    | 81500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 16299        |\n",
            "|    policy_loss        | -18.2        |\n",
            "|    reward             | -0.048253074 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 2.44         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 1061      |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | 23.5      |\n",
            "|    reward             | 1.8092406 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 4.9       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 16500       |\n",
            "|    time_elapsed       | 1067        |\n",
            "|    total_timesteps    | 82500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16499       |\n",
            "|    policy_loss        | 44.4        |\n",
            "|    reward             | -0.91696554 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 14.7        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16600      |\n",
            "|    time_elapsed       | 1074       |\n",
            "|    total_timesteps    | 83000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16599      |\n",
            "|    policy_loss        | 2.18       |\n",
            "|    reward             | 0.06634065 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.065      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1081      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -18.7     |\n",
            "|    reward             | 1.3551381 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 1.94      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1088       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 31.9       |\n",
            "|    reward             | -1.5675981 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 5.37       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1094      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -44.4     |\n",
            "|    reward             | 1.4225801 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 17000     |\n",
            "|    time_elapsed       | 1100      |\n",
            "|    total_timesteps    | 85000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16999     |\n",
            "|    policy_loss        | -26.9     |\n",
            "|    reward             | 0.6523985 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 10.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1107      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -92       |\n",
            "|    reward             | 1.8167713 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 68.1      |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3047360.29\n",
            "total_reward: 2047360.29\n",
            "total_cost: 3438.62\n",
            "total_trades: 17643\n",
            "Sharpe: 0.663\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 1113        |\n",
            "|    total_timesteps    | 86000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | -0.054      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | 4.02        |\n",
            "|    reward             | -0.13745636 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 0.175       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17300      |\n",
            "|    time_elapsed       | 1120       |\n",
            "|    total_timesteps    | 86500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17299      |\n",
            "|    policy_loss        | -8.79      |\n",
            "|    reward             | 0.68610156 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.439      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 17400        |\n",
            "|    time_elapsed       | 1126         |\n",
            "|    total_timesteps    | 87000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17399        |\n",
            "|    policy_loss        | -14.4        |\n",
            "|    reward             | -0.025253091 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 1.7          |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 17500    |\n",
            "|    time_elapsed       | 1132     |\n",
            "|    total_timesteps    | 87500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17499    |\n",
            "|    policy_loss        | -7.22    |\n",
            "|    reward             | 1.656988 |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 1.62     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 17600       |\n",
            "|    time_elapsed       | 1139        |\n",
            "|    total_timesteps    | 88000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 0.00293     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17599       |\n",
            "|    policy_loss        | 30.6        |\n",
            "|    reward             | -0.79344136 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 6.2         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1145      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | -25.5     |\n",
            "|    reward             | 1.7507114 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 23.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 1152      |\n",
            "|    total_timesteps    | 89000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | 8.72      |\n",
            "|    reward             | 0.9086367 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 0.462     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1159       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -4.86      |\n",
            "|    reward             | -2.2900512 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 0.117      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1165       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | -36.6      |\n",
            "|    reward             | -1.2789482 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 9.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1172      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | 0.571     |\n",
            "|    reward             | 1.3624524 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.79      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 1179       |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | 53.9       |\n",
            "|    reward             | 0.47722805 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 19.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 1185       |\n",
            "|    total_timesteps    | 91500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -115       |\n",
            "|    reward             | 0.39516494 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 86.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 1192      |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | 16.6      |\n",
            "|    reward             | 0.3028492 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 1.57      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 1199        |\n",
            "|    total_timesteps    | 92500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | 1.96        |\n",
            "|    reward             | -0.16300073 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 2.21        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 1208      |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | 9.07      |\n",
            "|    reward             | 0.6882055 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.792     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 18700    |\n",
            "|    time_elapsed       | 1216     |\n",
            "|    total_timesteps    | 93500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18699    |\n",
            "|    policy_loss        | -7.91    |\n",
            "|    reward             | 2.027278 |\n",
            "|    std                | 1.16     |\n",
            "|    value_loss         | 0.343    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 1222      |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 24.8      |\n",
            "|    reward             | 1.6334119 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 5.81      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1229       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 72.8       |\n",
            "|    reward             | -0.7510422 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 43.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19000      |\n",
            "|    time_elapsed       | 1235       |\n",
            "|    total_timesteps    | 95000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0165    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18999      |\n",
            "|    policy_loss        | -0.342     |\n",
            "|    reward             | 0.88076806 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.801      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1241      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -71.6     |\n",
            "|    reward             | 1.3066425 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 27.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19200      |\n",
            "|    time_elapsed       | 1248       |\n",
            "|    total_timesteps    | 96000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19199      |\n",
            "|    policy_loss        | 0.54       |\n",
            "|    reward             | 0.17520198 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.13       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19300      |\n",
            "|    time_elapsed       | 1254       |\n",
            "|    total_timesteps    | 96500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19299      |\n",
            "|    policy_loss        | -22.5      |\n",
            "|    reward             | 0.23362958 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 4.7        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1261      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 109       |\n",
            "|    reward             | 2.3707383 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 59.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 1270      |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | 83.4      |\n",
            "|    reward             | 1.1657666 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 51.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1278      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 7.87e-06  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 29.4      |\n",
            "|    reward             | 0.8077841 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 13.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19700     |\n",
            "|    time_elapsed       | 1284      |\n",
            "|    total_timesteps    | 98500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19699     |\n",
            "|    policy_loss        | -26       |\n",
            "|    reward             | 0.8895185 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 6.41      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 1291      |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | 12.9      |\n",
            "|    reward             | -7.838016 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 1.57      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1298       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -60.7      |\n",
            "|    reward             | -4.2103376 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 18.7       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 20000    |\n",
            "|    time_elapsed       | 1305     |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | -0.00183 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19999    |\n",
            "|    policy_loss        | -70      |\n",
            "|    reward             | -9.54562 |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 57.9     |\n",
            "------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.995067e+05  9.905746e+05\n",
            "2021-10-05  1.000203e+06  9.996566e+05\n",
            "2021-10-06  1.001075e+06  1.002637e+06\n",
            "2021-10-07  1.002773e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  8.740073e+05  9.854252e+05\n",
            "2023-04-28  8.776574e+05  9.933491e+05\n",
            "2023-05-01  8.715291e+05  9.919956e+05\n",
            "2023-05-02  8.689897e+05  9.812993e+05\n",
            "2023-05-03  8.616237e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -13.84 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -15.6      |\n",
            "|    reward             | 0.14613616 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.66       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.0391     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -6.19      |\n",
            "|    reward             | 0.70283115 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.9        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.372      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -4.61      |\n",
            "|    reward             | -3.2028282 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.15       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 0.147    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 12.9     |\n",
            "|    reward             | 0.908493 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 3.41     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0277     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -23.2      |\n",
            "|    reward             | -0.6327066 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 6.4        |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 1.69         |\n",
            "|    reward             | -0.032330666 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.0257       |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -2.45     |\n",
            "|    reward             | -0.728664 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.274     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -6.13     |\n",
            "|    reward             | 0.1837468 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.913     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -0.358    |\n",
            "|    reward             | 3.0506878 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.34      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -66.1     |\n",
            "|    reward             | 2.5158567 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 58.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 70       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | -0.0639  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 38.7     |\n",
            "|    reward             | 1.942153 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 8.74     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 77          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -5.87       |\n",
            "|    reward             | -0.39355847 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.27        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.00615   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -7.95     |\n",
            "|    reward             | 0.7296263 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.799     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 29.8       |\n",
            "|    reward             | 0.52015084 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 5.22       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0832    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 32.2       |\n",
            "|    reward             | 0.35169607 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 102       |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.0576   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -24.5     |\n",
            "|    reward             | 1.8841437 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 12.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 134       |\n",
            "|    reward             | 5.669671  |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 164       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -19.2      |\n",
            "|    reward             | 0.37034586 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.77       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 120         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -43.2       |\n",
            "|    reward             | 0.028812483 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 10.7        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 127         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 1.01        |\n",
            "|    reward             | -0.20391609 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.766       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -12.9     |\n",
            "|    reward             | 2.3945217 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 4.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 139        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.000314   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 19.1       |\n",
            "|    reward             | -2.5785325 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.32       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 254       |\n",
            "|    reward             | 2.9792356 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 405       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 151        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -1.33      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 27.7       |\n",
            "|    reward             | 0.35599327 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 5.47       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 158        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | -8.58      |\n",
            "|    reward             | 0.54615074 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.05       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2600       |\n",
            "|    time_elapsed       | 164        |\n",
            "|    total_timesteps    | 13000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2599       |\n",
            "|    policy_loss        | 13         |\n",
            "|    reward             | 0.22033012 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.89       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 171         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -6          |\n",
            "|    reward             | -0.73991483 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.647       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 176       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -55.8     |\n",
            "|    reward             | 1.9363843 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 25.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 183       |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 117       |\n",
            "|    reward             | 1.2756809 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 97.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 190        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.448     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | 3.83       |\n",
            "|    reward             | -0.9308777 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.235      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 199         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | -30         |\n",
            "|    reward             | -0.04637022 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 6.18        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 209       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 56.7      |\n",
            "|    reward             | 1.3116301 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 23.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 220         |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | 6.85        |\n",
            "|    reward             | -0.13953233 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.337       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 229        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -6.57e-05  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | -168       |\n",
            "|    reward             | 0.39782393 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 183        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 238       |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 126       |\n",
            "|    reward             | 1.3442206 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 88.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 247       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.0478   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 2.43      |\n",
            "|    reward             | 0.3060995 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.153     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 256         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | 1.98        |\n",
            "|    reward             | -0.69675267 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 1.12        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 71           |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 266          |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 39.3         |\n",
            "|    reward             | -0.055553406 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 13.8         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 275        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | -5.28      |\n",
            "|    reward             | 0.42691964 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.56       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 285        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -60.9      |\n",
            "|    reward             | -4.6961384 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 21.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 294        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 20.7       |\n",
            "|    reward             | -1.4763596 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 5.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 304       |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | -0.943    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 8.29      |\n",
            "|    reward             | -1.074427 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.09      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 313        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | 23.1       |\n",
            "|    reward             | -0.6968878 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 3.43       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 322        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -18.7      |\n",
            "|    reward             | -2.5726395 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 331       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 10.6      |\n",
            "|    reward             | 4.6205444 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.39      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 67         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 340        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 39.7       |\n",
            "|    reward             | -0.7024236 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 14.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 348       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 3.24      |\n",
            "|    reward             | 4.3034406 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 3.92      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 357       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -7.78     |\n",
            "|    reward             | -0.540113 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.3       |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 66           |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 366          |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | 14.9         |\n",
            "|    reward             | -0.004058861 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 1.86         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 66         |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 373        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -35.1      |\n",
            "|    reward             | 0.82896847 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 7.51       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 67          |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 380         |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | 41.2        |\n",
            "|    reward             | -0.84445894 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 10.5        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 386       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0.0355    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | 10.1      |\n",
            "|    reward             | 1.1272993 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.35      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 393       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0.00388   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 14.6      |\n",
            "|    reward             | -3.022536 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.03      |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3689321.12\n",
            "total_reward: 2689321.12\n",
            "total_cost: 6617.98\n",
            "total_trades: 13156\n",
            "Sharpe: 0.790\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 67       |\n",
            "|    iterations         | 5400     |\n",
            "|    time_elapsed       | 401      |\n",
            "|    total_timesteps    | 27000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5399     |\n",
            "|    policy_loss        | -31.9    |\n",
            "|    reward             | -1.16215 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 6.45     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 408       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 24.5      |\n",
            "|    reward             | 0.4506067 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 3.24      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 414       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -10.5     |\n",
            "|    reward             | 0.5364631 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.61      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 421       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | -15       |\n",
            "|    reward             | 1.1536553 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.84      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 427       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 19.4      |\n",
            "|    reward             | 1.7248012 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.84      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 434       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | -58.3     |\n",
            "|    reward             | -1.207483 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 20.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 441       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -42.4     |\n",
            "|    reward             | 0.8101205 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 13.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 447      |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | 9.01     |\n",
            "|    reward             | 0.785428 |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.976    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 454       |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -0.0162   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | -50.7     |\n",
            "|    reward             | -2.774432 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 29.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 461       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | -15.2     |\n",
            "|    reward             | 0.9044022 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.58      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 468      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 47.8     |\n",
            "|    reward             | 2.920685 |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 17.4     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 474         |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | -34.8       |\n",
            "|    reward             | 0.038692124 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 9.61        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 481        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -41.4      |\n",
            "|    reward             | -1.8311133 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 10.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 488       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 7.71      |\n",
            "|    reward             | 1.9535865 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.366     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 494       |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 9.25      |\n",
            "|    reward             | -2.272828 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.9       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 502         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | -13.5       |\n",
            "|    reward             | -0.46893474 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 1.4         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 510       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -1.31     |\n",
            "|    reward             | 1.5932308 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.444     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 517        |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -1.86      |\n",
            "|    reward             | 0.05614266 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.0212     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 524         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 5.31        |\n",
            "|    reward             | -0.51856714 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.215       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 531        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | -5.95      |\n",
            "|    reward             | -0.6254261 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.628      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 539       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -56.1     |\n",
            "|    reward             | 1.8667682 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 26.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 545       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | -0.129    |\n",
            "|    reward             | 1.7179168 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.105     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 552        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 10.2       |\n",
            "|    reward             | 0.21511652 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.36       |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 68             |\n",
            "|    iterations         | 7700           |\n",
            "|    time_elapsed       | 559            |\n",
            "|    total_timesteps    | 38500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -13.6          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7699           |\n",
            "|    policy_loss        | 4.34           |\n",
            "|    reward             | -0.00095042714 |\n",
            "|    std                | 1.1            |\n",
            "|    value_loss         | 0.125          |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 566         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | -0.00529    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | 16.6        |\n",
            "|    reward             | -0.32860425 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 2.01        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 7900       |\n",
            "|    time_elapsed       | 572        |\n",
            "|    total_timesteps    | 39500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7899       |\n",
            "|    policy_loss        | -26.5      |\n",
            "|    reward             | 0.98544765 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 3.67       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 579         |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -6.65       |\n",
            "|    reward             | -0.04725847 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.827       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 586       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -38       |\n",
            "|    reward             | 3.0406618 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 17.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 593       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -318      |\n",
            "|    reward             | -8.019604 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 548       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 600       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | -19.9     |\n",
            "|    reward             | -0.663429 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 3.33      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 8400       |\n",
            "|    time_elapsed       | 607        |\n",
            "|    total_timesteps    | 42000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8399       |\n",
            "|    policy_loss        | -28.9      |\n",
            "|    reward             | 0.14339891 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 4.11       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 613       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -4.7      |\n",
            "|    reward             | 1.5579164 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.889     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 620      |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.7    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | 10.3     |\n",
            "|    reward             | 1.803747 |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 1.31     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 626       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -83.4     |\n",
            "|    reward             | 2.0767379 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 42.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 633        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 86.8       |\n",
            "|    reward             | -3.0260189 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 59.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 640       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -0.649    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 41.4      |\n",
            "|    reward             | 1.6699916 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 8.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 647        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 16.5       |\n",
            "|    reward             | 0.15201852 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 2.11       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 9100       |\n",
            "|    time_elapsed       | 654        |\n",
            "|    total_timesteps    | 45500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9099       |\n",
            "|    policy_loss        | -11.8      |\n",
            "|    reward             | 0.58075225 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 1.07       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 660        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 48.7       |\n",
            "|    reward             | 0.54988086 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 17.2       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 69       |\n",
            "|    iterations         | 9300     |\n",
            "|    time_elapsed       | 667      |\n",
            "|    total_timesteps    | 46500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9299     |\n",
            "|    policy_loss        | 32.2     |\n",
            "|    reward             | 2.66754  |\n",
            "|    std                | 1.13     |\n",
            "|    value_loss         | 5.67     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 674       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 48.9      |\n",
            "|    reward             | 2.0021381 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 37.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 681       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 9.69      |\n",
            "|    reward             | 0.2040837 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 1.1       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 688        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.0669    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 6.95       |\n",
            "|    reward             | -0.7749928 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.796      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 9700      |\n",
            "|    time_elapsed       | 694       |\n",
            "|    total_timesteps    | 48500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9699      |\n",
            "|    policy_loss        | 10.8      |\n",
            "|    reward             | -1.493515 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 1.66      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 9800        |\n",
            "|    time_elapsed       | 701         |\n",
            "|    total_timesteps    | 49000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9799        |\n",
            "|    policy_loss        | -75.3       |\n",
            "|    reward             | -0.22007565 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 34.4        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 708       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | -6.41     |\n",
            "|    reward             | 1.4815398 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 1.43      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 714       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | 36.5      |\n",
            "|    reward             | -6.868332 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 12        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 721       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 0.756     |\n",
            "|    reward             | 1.1199899 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.567     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 729       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 23.5      |\n",
            "|    reward             | 1.1115891 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 3.93      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 736       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -23.3     |\n",
            "|    reward             | 1.0439488 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 3.26      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 744        |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 174        |\n",
            "|    reward             | -1.1971726 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 146        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 751        |\n",
            "|    total_timesteps    | 52500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 58.7       |\n",
            "|    reward             | -5.1316175 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 25.1       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 69           |\n",
            "|    iterations         | 10600        |\n",
            "|    time_elapsed       | 758          |\n",
            "|    total_timesteps    | 53000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10599        |\n",
            "|    policy_loss        | -155         |\n",
            "|    reward             | -0.108676456 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 236          |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 766        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | -2         |\n",
            "|    reward             | 0.33589137 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.0166     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 773         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 11.9        |\n",
            "|    reward             | -0.41256917 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.976       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 779        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | 11.8       |\n",
            "|    reward             | -1.8249611 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 3.37       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 786        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -17.3      |\n",
            "|    reward             | -0.2841091 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 1.98       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 11100      |\n",
            "|    time_elapsed       | 796        |\n",
            "|    total_timesteps    | 55500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11099      |\n",
            "|    policy_loss        | 71.9       |\n",
            "|    reward             | 0.32345724 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 47.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 11200     |\n",
            "|    time_elapsed       | 806       |\n",
            "|    total_timesteps    | 56000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 8.29e-06  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11199     |\n",
            "|    policy_loss        | 17.9      |\n",
            "|    reward             | 1.8253814 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 7.09      |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4889060.12\n",
            "total_reward: 3889060.12\n",
            "total_cost: 5599.72\n",
            "total_trades: 16443\n",
            "Sharpe: 0.903\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 11300      |\n",
            "|    time_elapsed       | 817        |\n",
            "|    total_timesteps    | 56500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11299      |\n",
            "|    policy_loss        | 16.5       |\n",
            "|    reward             | 0.13038892 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 1.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 827       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 2.48      |\n",
            "|    reward             | 1.0161015 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.54      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 11500    |\n",
            "|    time_elapsed       | 834      |\n",
            "|    total_timesteps    | 57500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11499    |\n",
            "|    policy_loss        | 6.53     |\n",
            "|    reward             | 2.657855 |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 1.18     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 11600      |\n",
            "|    time_elapsed       | 842        |\n",
            "|    total_timesteps    | 58000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11599      |\n",
            "|    policy_loss        | -6.72      |\n",
            "|    reward             | 0.23443875 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.577      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 11700     |\n",
            "|    time_elapsed       | 849       |\n",
            "|    total_timesteps    | 58500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0.000867  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11699     |\n",
            "|    policy_loss        | 68.5      |\n",
            "|    reward             | -2.893294 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 18.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 11800      |\n",
            "|    time_elapsed       | 857        |\n",
            "|    total_timesteps    | 59000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11799      |\n",
            "|    policy_loss        | 53.2       |\n",
            "|    reward             | 0.45015058 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 24.3       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 11900       |\n",
            "|    time_elapsed       | 864         |\n",
            "|    total_timesteps    | 59500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11899       |\n",
            "|    policy_loss        | -23         |\n",
            "|    reward             | -0.45700818 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 3.31        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 871        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -22.4      |\n",
            "|    reward             | -2.5678303 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 2.56       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 878       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -4.45     |\n",
            "|    reward             | 0.8016666 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.73      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 885        |\n",
            "|    total_timesteps    | 61000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | -64.1      |\n",
            "|    reward             | 0.47272405 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 24.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 892       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | -61.9     |\n",
            "|    reward             | 3.0845582 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 24.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 899       |\n",
            "|    total_timesteps    | 62000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | 88.8      |\n",
            "|    reward             | 3.5565867 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 47.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 906       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.000256  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -74.1     |\n",
            "|    reward             | 4.7553687 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 30.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 12600       |\n",
            "|    time_elapsed       | 915         |\n",
            "|    total_timesteps    | 63000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12599       |\n",
            "|    policy_loss        | -10.4       |\n",
            "|    reward             | -0.98726857 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.561       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 12700    |\n",
            "|    time_elapsed       | 923      |\n",
            "|    total_timesteps    | 63500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12699    |\n",
            "|    policy_loss        | -67.2    |\n",
            "|    reward             | 0.824499 |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 18       |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 12800       |\n",
            "|    time_elapsed       | 931         |\n",
            "|    total_timesteps    | 64000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12799       |\n",
            "|    policy_loss        | 18          |\n",
            "|    reward             | -0.74919474 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 1.85        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 938       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.000115  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | -15.8     |\n",
            "|    reward             | 2.2824664 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 1.51      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13000     |\n",
            "|    time_elapsed       | 945       |\n",
            "|    total_timesteps    | 65000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0.000783  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12999     |\n",
            "|    policy_loss        | 46.6      |\n",
            "|    reward             | -5.022427 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 15.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 952       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -84.6     |\n",
            "|    reward             | 3.3765974 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 36.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13200     |\n",
            "|    time_elapsed       | 959       |\n",
            "|    total_timesteps    | 66000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13199     |\n",
            "|    policy_loss        | -18.2     |\n",
            "|    reward             | -2.123502 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 1.78      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13300      |\n",
            "|    time_elapsed       | 966        |\n",
            "|    total_timesteps    | 66500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0.000221   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13299      |\n",
            "|    policy_loss        | -49.6      |\n",
            "|    reward             | 0.64588857 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 13.4       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 13400       |\n",
            "|    time_elapsed       | 973         |\n",
            "|    total_timesteps    | 67000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0.000267    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13399       |\n",
            "|    policy_loss        | 21.5        |\n",
            "|    reward             | -0.03450516 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 2.25        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 13500     |\n",
            "|    time_elapsed       | 993       |\n",
            "|    total_timesteps    | 67500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13499     |\n",
            "|    policy_loss        | -0.447    |\n",
            "|    reward             | 0.5185179 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 2.79      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 13600       |\n",
            "|    time_elapsed       | 999         |\n",
            "|    total_timesteps    | 68000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13599       |\n",
            "|    policy_loss        | -34.2       |\n",
            "|    reward             | -0.25895905 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 9.17        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 1006      |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 40        |\n",
            "|    reward             | 1.9029863 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 15.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 1012      |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | 2.2       |\n",
            "|    reward             | 1.7755344 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 0.0596    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 1019       |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -2.38e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | -0.645     |\n",
            "|    reward             | -2.1943002 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 2.24       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 1025        |\n",
            "|    total_timesteps    | 70000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | -0.00703    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | -11.6       |\n",
            "|    reward             | 0.050690584 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 1.27        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14100      |\n",
            "|    time_elapsed       | 1031       |\n",
            "|    total_timesteps    | 70500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14099      |\n",
            "|    policy_loss        | 2.01       |\n",
            "|    reward             | -1.5557706 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 0.367      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 14200       |\n",
            "|    time_elapsed       | 1037        |\n",
            "|    total_timesteps    | 71000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14199       |\n",
            "|    policy_loss        | 3.44        |\n",
            "|    reward             | 0.048864204 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.0655      |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 68       |\n",
            "|    iterations         | 14300    |\n",
            "|    time_elapsed       | 1044     |\n",
            "|    total_timesteps    | 71500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14299    |\n",
            "|    policy_loss        | 17.5     |\n",
            "|    reward             | 0.877344 |\n",
            "|    std                | 1.15     |\n",
            "|    value_loss         | 2.62     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14400      |\n",
            "|    time_elapsed       | 1050       |\n",
            "|    total_timesteps    | 72000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14399      |\n",
            "|    policy_loss        | -59.3      |\n",
            "|    reward             | 0.34195375 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 18.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 14500     |\n",
            "|    time_elapsed       | 1056      |\n",
            "|    total_timesteps    | 72500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14499     |\n",
            "|    policy_loss        | 7.71      |\n",
            "|    reward             | 0.5120153 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 2.9       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 1062       |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 62.7       |\n",
            "|    reward             | -3.6683996 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 26.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 68        |\n",
            "|    iterations         | 14700     |\n",
            "|    time_elapsed       | 1069      |\n",
            "|    total_timesteps    | 73500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14699     |\n",
            "|    policy_loss        | 73.3      |\n",
            "|    reward             | -8.118509 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 30.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 1075       |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | 6.77       |\n",
            "|    reward             | 0.37019396 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 0.275      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 14900      |\n",
            "|    time_elapsed       | 1081       |\n",
            "|    total_timesteps    | 74500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14899      |\n",
            "|    policy_loss        | -40.5      |\n",
            "|    reward             | -0.5144017 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 9.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 68         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 1087       |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -27.1      |\n",
            "|    reward             | -1.4526883 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 3.46       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 15100     |\n",
            "|    time_elapsed       | 1093      |\n",
            "|    total_timesteps    | 75500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -1.97e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15099     |\n",
            "|    policy_loss        | 7.42      |\n",
            "|    reward             | -2.668658 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.828     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 1100      |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | -7.99e-06 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -49.8     |\n",
            "|    reward             | 3.2940996 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 44.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 15300     |\n",
            "|    time_elapsed       | 1106      |\n",
            "|    total_timesteps    | 76500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15299     |\n",
            "|    policy_loss        | -284      |\n",
            "|    reward             | -4.398864 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 484       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 1112        |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 13.2        |\n",
            "|    reward             | -0.02865608 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 1.7         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 1119      |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 31.4      |\n",
            "|    reward             | 0.9279794 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 6.92      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 1125       |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 15.5       |\n",
            "|    reward             | 0.04404817 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 1.49       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 15700      |\n",
            "|    time_elapsed       | 1132       |\n",
            "|    total_timesteps    | 78500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15699      |\n",
            "|    policy_loss        | 14.6       |\n",
            "|    reward             | 0.97432816 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.927      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 1139      |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -10.1     |\n",
            "|    reward             | 1.3137326 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.994     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 69          |\n",
            "|    iterations         | 15900       |\n",
            "|    time_elapsed       | 1145        |\n",
            "|    total_timesteps    | 79500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15899       |\n",
            "|    policy_loss        | 3.97        |\n",
            "|    reward             | -0.68359494 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 9.59        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 1151       |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -3.17      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | 49.1       |\n",
            "|    reward             | -0.9775062 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 17.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 16100      |\n",
            "|    time_elapsed       | 1157       |\n",
            "|    total_timesteps    | 80500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16099      |\n",
            "|    policy_loss        | -6.16      |\n",
            "|    reward             | 0.21688184 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.693      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1163      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -17.4     |\n",
            "|    reward             | 1.0168861 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 1.8       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 16300     |\n",
            "|    time_elapsed       | 1169      |\n",
            "|    total_timesteps    | 81500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16299     |\n",
            "|    policy_loss        | -15.1     |\n",
            "|    reward             | 0.4308158 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 1.84      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 1175      |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | 22.2      |\n",
            "|    reward             | 2.5207412 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 3.45      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1181       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | 39.1       |\n",
            "|    reward             | -1.3470056 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 12.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1187      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -50.1     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 44.3      |\n",
            "|    reward             | 0.3421387 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 9.03      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 69        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1193      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -15.7     |\n",
            "|    reward             | 1.4297084 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 1.43      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1200       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 35.2       |\n",
            "|    reward             | -2.7237258 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 7.51       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1205      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -52       |\n",
            "|    reward             | 1.1639236 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 15        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 17000     |\n",
            "|    time_elapsed       | 1212      |\n",
            "|    total_timesteps    | 85000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16999     |\n",
            "|    policy_loss        | -61.4     |\n",
            "|    reward             | 1.2842448 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 29        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1218      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -142      |\n",
            "|    reward             | 3.2062738 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 109       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3742134.28\n",
            "total_reward: 2742134.28\n",
            "total_cost: 9736.62\n",
            "total_trades: 13184\n",
            "Sharpe: 0.781\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 1224        |\n",
            "|    total_timesteps    | 86000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | -0.379      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | -0.97       |\n",
            "|    reward             | -0.09755459 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.185       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 1230      |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | -9.39     |\n",
            "|    reward             | 0.9060994 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.488     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 17400       |\n",
            "|    time_elapsed       | 1236        |\n",
            "|    total_timesteps    | 87000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17399       |\n",
            "|    policy_loss        | 10.7        |\n",
            "|    reward             | -0.77527905 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.747       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 1242      |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | -17.5     |\n",
            "|    reward             | 1.5566425 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 2.7       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 17600      |\n",
            "|    time_elapsed       | 1248       |\n",
            "|    total_timesteps    | 88000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17599      |\n",
            "|    policy_loss        | 54.8       |\n",
            "|    reward             | -1.2600399 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 14.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1254      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | -37.9     |\n",
            "|    reward             | 3.1565244 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 30.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1260       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0.232      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 3.32       |\n",
            "|    reward             | 0.84326386 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.0774     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1266       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -8.33      |\n",
            "|    reward             | -2.0464528 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.466      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1273       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | -43.2      |\n",
            "|    reward             | -1.6633121 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 15.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1279      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | 4.69      |\n",
            "|    reward             | 1.5952436 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 1.15      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 18200     |\n",
            "|    time_elapsed       | 1285      |\n",
            "|    total_timesteps    | 91000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18199     |\n",
            "|    policy_loss        | 39.8      |\n",
            "|    reward             | 0.2844563 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 11.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 18300       |\n",
            "|    time_elapsed       | 1291        |\n",
            "|    total_timesteps    | 91500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18299       |\n",
            "|    policy_loss        | -135        |\n",
            "|    reward             | -0.03597119 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 105         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 18400      |\n",
            "|    time_elapsed       | 1297       |\n",
            "|    total_timesteps    | 92000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18399      |\n",
            "|    policy_loss        | 7.75       |\n",
            "|    reward             | 0.08972741 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.537      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 70          |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 1303        |\n",
            "|    total_timesteps    | 92500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | 16.8        |\n",
            "|    reward             | -0.04839834 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 2.17        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 18600      |\n",
            "|    time_elapsed       | 1310       |\n",
            "|    total_timesteps    | 93000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18599      |\n",
            "|    policy_loss        | 3.53       |\n",
            "|    reward             | 0.68927467 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.228      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1317      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -15.2     |\n",
            "|    reward             | 2.0324917 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 1.08      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 1323      |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 4.18      |\n",
            "|    reward             | 1.4478412 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 0.698     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 18900     |\n",
            "|    time_elapsed       | 1329      |\n",
            "|    total_timesteps    | 94500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18899     |\n",
            "|    policy_loss        | 49.7      |\n",
            "|    reward             | 0.3854249 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 19.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 19000      |\n",
            "|    time_elapsed       | 1335       |\n",
            "|    total_timesteps    | 95000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18999      |\n",
            "|    policy_loss        | -17.9      |\n",
            "|    reward             | 0.48610866 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 2.09       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1341      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -84.8     |\n",
            "|    reward             | 0.8795285 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 32.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 19200      |\n",
            "|    time_elapsed       | 1347       |\n",
            "|    total_timesteps    | 96000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19199      |\n",
            "|    policy_loss        | 4.3        |\n",
            "|    reward             | -0.9705819 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 0.785      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 19300      |\n",
            "|    time_elapsed       | 1353       |\n",
            "|    total_timesteps    | 96500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 5.66e-06   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19299      |\n",
            "|    policy_loss        | 8.24       |\n",
            "|    reward             | -0.6213399 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 0.528      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1360      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 82.9      |\n",
            "|    reward             | 0.6661652 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 50.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 1366      |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | -2.69     |\n",
            "|    reward             | -2.213037 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 1.12      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1373      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 29.4      |\n",
            "|    reward             | 0.7438088 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 6.5       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 71          |\n",
            "|    iterations         | 19700       |\n",
            "|    time_elapsed       | 1381        |\n",
            "|    total_timesteps    | 98500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.5       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19699       |\n",
            "|    policy_loss        | -34.5       |\n",
            "|    reward             | -0.21314356 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 9.33        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 1389      |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | 14.7      |\n",
            "|    reward             | -7.033688 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 1.17      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1397       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -25.1      |\n",
            "|    reward             | -2.5932095 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 3.36       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 20000      |\n",
            "|    time_elapsed       | 1404       |\n",
            "|    total_timesteps    | 100000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19999      |\n",
            "|    policy_loss        | -18.7      |\n",
            "|    reward             | -5.4319224 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 13.7       |\n",
            "--------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.999349e+05  9.905746e+05\n",
            "2021-10-05  1.000160e+06  9.996566e+05\n",
            "2021-10-06  1.000707e+06  1.002637e+06\n",
            "2021-10-07  1.001310e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  9.444224e+05  9.854252e+05\n",
            "2023-04-28  9.477345e+05  9.933491e+05\n",
            "2023-05-01  9.453852e+05  9.919956e+05\n",
            "2023-05-02  9.389332e+05  9.812993e+05\n",
            "2023-05-03  9.323316e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -6.77 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -5.3      |\n",
            "|    reward             | 0.5508251 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.208     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -0.764     |\n",
            "|    reward             | -0.3433268 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.442      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0597    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -22.3     |\n",
            "|    reward             | 0.2698045 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.46      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0214     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -45.1      |\n",
            "|    reward             | -3.2481399 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 11.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -18.2      |\n",
            "|    reward             | -0.7983892 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.1        |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 79            |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | -1.49         |\n",
            "|    reward             | -0.0013920838 |\n",
            "|    std                | 1.02          |\n",
            "|    value_loss         | 0.0165        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 78             |\n",
            "|    iterations         | 700            |\n",
            "|    time_elapsed       | 44             |\n",
            "|    total_timesteps    | 3500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -13.1          |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 699            |\n",
            "|    policy_loss        | -0.0712        |\n",
            "|    reward             | -0.00033601624 |\n",
            "|    std                | 1.04           |\n",
            "|    value_loss         | 8.55e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.163       |\n",
            "|    reward             | 0.0001691942 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.000248     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.283      |\n",
            "|    reward             | 0.022874022 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.000922    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 78            |\n",
            "|    iterations         | 1000          |\n",
            "|    time_elapsed       | 63            |\n",
            "|    total_timesteps    | 5000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.2         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 999           |\n",
            "|    policy_loss        | -0.173        |\n",
            "|    reward             | -0.0018521395 |\n",
            "|    std                | 1.17          |\n",
            "|    value_loss         | 0.000251      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.514       |\n",
            "|    reward             | 0.002204384 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 0.00234     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 79            |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 75            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.9         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | -0.0717       |\n",
            "|    reward             | -0.0017672371 |\n",
            "|    std                | 1.26          |\n",
            "|    value_loss         | 2.53e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 81       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -0.65    |\n",
            "|    reward             | 0.050223 |\n",
            "|    std                | 1.29     |\n",
            "|    value_loss         | 0.00398  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 3.64       |\n",
            "|    reward             | 0.21913151 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 0.077      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 95        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 17        |\n",
            "|    reward             | 0.6386419 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 2.35      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -9.71       |\n",
            "|    reward             | -0.59008276 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 2.32        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.3     |\n",
            "|    explained_variance | 0.0711    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 55.5      |\n",
            "|    reward             | 0.6384556 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 28.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 114        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -4.41      |\n",
            "|    reward             | 0.11270755 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 0.139      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -17.3     |\n",
            "|    reward             | 0.2477658 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 0.993     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 126         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 14.6        |\n",
            "|    reward             | -0.09291316 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 1.09        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -23.7     |\n",
            "|    reward             | 2.8134434 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 5.58      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 139         |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 2.57        |\n",
            "|    reward             | -0.52313054 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 2.86        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 213       |\n",
            "|    reward             | 2.5780704 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 275       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 151        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 5.71       |\n",
            "|    reward             | 0.13983315 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.149      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 158       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -2.43     |\n",
            "|    reward             | 0.3894767 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 0.0744    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 164      |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.4    |\n",
            "|    explained_variance | -0.196   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 15.4     |\n",
            "|    reward             | 0.669894 |\n",
            "|    std                | 1.34     |\n",
            "|    value_loss         | 2.19     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 171         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.4       |\n",
            "|    explained_variance | -0.0063     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | 0.372       |\n",
            "|    reward             | -0.06602351 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 0.325       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 177      |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.4    |\n",
            "|    explained_variance | -0.00152 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | -55.6    |\n",
            "|    reward             | 0.27864  |\n",
            "|    std                | 1.34     |\n",
            "|    value_loss         | 12.8     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 183        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 74.2       |\n",
            "|    reward             | 0.28468487 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 25.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 189        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | -0.0415    |\n",
            "|    reward             | -0.1655468 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 0.000307   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 195          |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.5        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | -6.86        |\n",
            "|    reward             | -0.005189073 |\n",
            "|    std                | 1.36         |\n",
            "|    value_loss         | 0.421        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 202       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 24.9      |\n",
            "|    reward             | 0.6533705 |\n",
            "|    std                | 1.36      |\n",
            "|    value_loss         | 3.81      |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 79            |\n",
            "|    iterations         | 3300          |\n",
            "|    time_elapsed       | 208           |\n",
            "|    total_timesteps    | 16500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.6         |\n",
            "|    explained_variance | -0.64         |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3299          |\n",
            "|    policy_loss        | 5.4           |\n",
            "|    reward             | -0.0028161972 |\n",
            "|    std                | 1.37          |\n",
            "|    value_loss         | 0.491         |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 215        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.6      |\n",
            "|    explained_variance | -0.0302    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | -115       |\n",
            "|    reward             | 0.87486684 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 79.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 221       |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 70.5      |\n",
            "|    reward             | 1.2468078 |\n",
            "|    std                | 1.37      |\n",
            "|    value_loss         | 29.3      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 227         |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.7       |\n",
            "|    explained_variance | -2.17       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | 10.3        |\n",
            "|    reward             | 0.112302326 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 0.701       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 233         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -1.66       |\n",
            "|    reward             | -0.36298546 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 0.898       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 239        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | -0.0199    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | 48.7       |\n",
            "|    reward             | 0.47061503 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 12.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 246        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | -0.0225    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | 9.25       |\n",
            "|    reward             | 0.20996712 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 1.1        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 251        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -40.4      |\n",
            "|    reward             | -2.8957841 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 7.38       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 258         |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.6       |\n",
            "|    explained_variance | 0.0056      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -19.2       |\n",
            "|    reward             | -0.42583936 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 1.9         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | 9.59       |\n",
            "|    reward             | -0.8414155 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 0.483      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 271         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 29.6        |\n",
            "|    reward             | -0.54148704 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 4.4         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 277        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -25.6      |\n",
            "|    reward             | -2.7633855 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 3.09       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 285       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.7     |\n",
            "|    explained_variance | 0.0001    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 24.7      |\n",
            "|    reward             | 4.0115466 |\n",
            "|    std                | 1.39      |\n",
            "|    value_loss         | 2.51      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 293        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 42.2       |\n",
            "|    reward             | -0.6183014 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 9.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 301       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -4.51     |\n",
            "|    reward             | 0.8488623 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 1.11      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 308       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.8     |\n",
            "|    explained_variance | 0.465     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -3.04     |\n",
            "|    reward             | 0.0491847 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 0.141     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 314         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -28.7       |\n",
            "|    reward             | -0.43617183 |\n",
            "|    std                | 1.39        |\n",
            "|    value_loss         | 3.38        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 321       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -17.7     |\n",
            "|    reward             | 0.7373637 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 1.85      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 327        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 11.6       |\n",
            "|    reward             | 0.19550475 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 1.24       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 333       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | -33.1     |\n",
            "|    reward             | -1.485377 |\n",
            "|    std                | 1.39      |\n",
            "|    value_loss         | 9.19      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 340        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 102        |\n",
            "|    reward             | -2.2399728 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 42.5       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3027161.90\n",
            "total_reward: 2027161.90\n",
            "total_cost: 6819.95\n",
            "total_trades: 8542\n",
            "Sharpe: 0.649\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 346        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.8      |\n",
            "|    explained_variance | -1.13      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -19.9      |\n",
            "|    reward             | -0.9805851 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 1.81       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 353       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 7.14      |\n",
            "|    reward             | 2.1788256 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 1.33      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 359        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.8      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -1.51      |\n",
            "|    reward             | -1.7836831 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 0.438      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 365         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | -7.96       |\n",
            "|    reward             | -0.95514816 |\n",
            "|    std                | 1.4         |\n",
            "|    value_loss         | 2.11        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 372       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 43.4      |\n",
            "|    reward             | 0.9690474 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 7.46      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 378        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | -54.9      |\n",
            "|    reward             | -3.0801373 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 10.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 385        |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | -28.5      |\n",
            "|    reward             | 0.92041856 |\n",
            "|    std                | 1.41       |\n",
            "|    value_loss         | 3.39       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 391        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | -7.73      |\n",
            "|    reward             | 0.95079905 |\n",
            "|    std                | 1.41       |\n",
            "|    value_loss         | 1.02       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 398        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.9      |\n",
            "|    explained_variance | 0.24       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -71.7      |\n",
            "|    reward             | -1.8993726 |\n",
            "|    std                | 1.42       |\n",
            "|    value_loss         | 26.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 404        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16        |\n",
            "|    explained_variance | 0.0338     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | 17.4       |\n",
            "|    reward             | -0.6522173 |\n",
            "|    std                | 1.43       |\n",
            "|    value_loss         | 1.31       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 411       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16       |\n",
            "|    explained_variance | -0.013    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 27.8      |\n",
            "|    reward             | 1.7880363 |\n",
            "|    std                | 1.43      |\n",
            "|    value_loss         | 5.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 417        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | 45.1       |\n",
            "|    reward             | -1.6937517 |\n",
            "|    std                | 1.42       |\n",
            "|    value_loss         | 11.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 424        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -13.6      |\n",
            "|    reward             | -0.4423688 |\n",
            "|    std                | 1.43       |\n",
            "|    value_loss         | 0.547      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6700       |\n",
            "|    time_elapsed       | 430        |\n",
            "|    total_timesteps    | 33500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6699       |\n",
            "|    policy_loss        | 0.524      |\n",
            "|    reward             | 0.52838296 |\n",
            "|    std                | 1.43       |\n",
            "|    value_loss         | 0.0775     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 436        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 12.1       |\n",
            "|    reward             | -1.1138818 |\n",
            "|    std                | 1.43       |\n",
            "|    value_loss         | 1.17       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 6900      |\n",
            "|    time_elapsed       | 443       |\n",
            "|    total_timesteps    | 34500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16       |\n",
            "|    explained_variance | 4.37e-05  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6899      |\n",
            "|    policy_loss        | 15.1      |\n",
            "|    reward             | 1.6587253 |\n",
            "|    std                | 1.44      |\n",
            "|    value_loss         | 1.48      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7000        |\n",
            "|    time_elapsed       | 449         |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16         |\n",
            "|    explained_variance | -0.00183    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6999        |\n",
            "|    policy_loss        | 31          |\n",
            "|    reward             | -0.13993739 |\n",
            "|    std                | 1.44        |\n",
            "|    value_loss         | 5.04        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 456         |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | -1.38       |\n",
            "|    reward             | 0.026655562 |\n",
            "|    std                | 1.43        |\n",
            "|    value_loss         | 0.00908     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 463         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 5.7         |\n",
            "|    reward             | 0.041590106 |\n",
            "|    std                | 1.44        |\n",
            "|    value_loss         | 0.177       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 471         |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 13.7        |\n",
            "|    reward             | -0.09475463 |\n",
            "|    std                | 1.45        |\n",
            "|    value_loss         | 0.972       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 478       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -30.9     |\n",
            "|    reward             | 1.0961204 |\n",
            "|    std                | 1.45      |\n",
            "|    value_loss         | 5.88      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 7500       |\n",
            "|    time_elapsed       | 484        |\n",
            "|    total_timesteps    | 37500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7499       |\n",
            "|    policy_loss        | 1.55       |\n",
            "|    reward             | 0.31193548 |\n",
            "|    std                | 1.45       |\n",
            "|    value_loss         | 0.0452     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 490       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 4.22      |\n",
            "|    reward             | 1.0333965 |\n",
            "|    std                | 1.45      |\n",
            "|    value_loss         | 0.107     |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 77            |\n",
            "|    iterations         | 7700          |\n",
            "|    time_elapsed       | 497           |\n",
            "|    total_timesteps    | 38500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -16.1         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7699          |\n",
            "|    policy_loss        | -2.16         |\n",
            "|    reward             | -0.0010033167 |\n",
            "|    std                | 1.46          |\n",
            "|    value_loss         | 0.0284        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 504         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | 2.75        |\n",
            "|    reward             | 0.024919098 |\n",
            "|    std                | 1.47        |\n",
            "|    value_loss         | 0.0475      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 510       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.2     |\n",
            "|    explained_variance | -0.542    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -11.6     |\n",
            "|    reward             | 0.5508433 |\n",
            "|    std                | 1.47      |\n",
            "|    value_loss         | 0.556     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 517        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | -0.285     |\n",
            "|    reward             | 0.42979422 |\n",
            "|    std                | 1.47       |\n",
            "|    value_loss         | 0.282      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 523      |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -16.2    |\n",
            "|    explained_variance | 0.00502  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | -17.9    |\n",
            "|    reward             | 1.50673  |\n",
            "|    std                | 1.47     |\n",
            "|    value_loss         | 4.85     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 530       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -243      |\n",
            "|    reward             | -4.335672 |\n",
            "|    std                | 1.47      |\n",
            "|    value_loss         | 240       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 8300        |\n",
            "|    time_elapsed       | 536         |\n",
            "|    total_timesteps    | 41500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.2       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8299        |\n",
            "|    policy_loss        | -7.8        |\n",
            "|    reward             | -0.15863031 |\n",
            "|    std                | 1.47        |\n",
            "|    value_loss         | 0.365       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 542         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -20.1       |\n",
            "|    reward             | -0.17977574 |\n",
            "|    std                | 1.48        |\n",
            "|    value_loss         | 1.93        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8500       |\n",
            "|    time_elapsed       | 549        |\n",
            "|    total_timesteps    | 42500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8499       |\n",
            "|    policy_loss        | -3.32      |\n",
            "|    reward             | 0.85043037 |\n",
            "|    std                | 1.48       |\n",
            "|    value_loss         | 0.104      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 555       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.3     |\n",
            "|    explained_variance | -0.455    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | 20.9      |\n",
            "|    reward             | 1.5334105 |\n",
            "|    std                | 1.48      |\n",
            "|    value_loss         | 1.96      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 562       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.3     |\n",
            "|    explained_variance | -0.0815   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -42.4     |\n",
            "|    reward             | 2.5210116 |\n",
            "|    std                | 1.48      |\n",
            "|    value_loss         | 9.62      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 568       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.3     |\n",
            "|    explained_variance | -0.171    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | -13.5     |\n",
            "|    reward             | -8.012542 |\n",
            "|    std                | 1.48      |\n",
            "|    value_loss         | 4.76      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 8900       |\n",
            "|    time_elapsed       | 575        |\n",
            "|    total_timesteps    | 44500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8899       |\n",
            "|    policy_loss        | 5.47       |\n",
            "|    reward             | 0.57918584 |\n",
            "|    std                | 1.49       |\n",
            "|    value_loss         | 0.163      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 582         |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.4       |\n",
            "|    explained_variance | -0.0424     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | 15.6        |\n",
            "|    reward             | -0.09425544 |\n",
            "|    std                | 1.49        |\n",
            "|    value_loss         | 1.05        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9100       |\n",
            "|    time_elapsed       | 588        |\n",
            "|    total_timesteps    | 45500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.4      |\n",
            "|    explained_variance | -0.0864    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9099       |\n",
            "|    policy_loss        | -8.44      |\n",
            "|    reward             | 0.14278121 |\n",
            "|    std                | 1.5        |\n",
            "|    value_loss         | 1.71       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 595        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.4      |\n",
            "|    explained_variance | -0.0505    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | -14        |\n",
            "|    reward             | 0.57684195 |\n",
            "|    std                | 1.5        |\n",
            "|    value_loss         | 2.4        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 601       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 32.9      |\n",
            "|    reward             | 0.2373892 |\n",
            "|    std                | 1.49      |\n",
            "|    value_loss         | 5.17      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 608       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.4     |\n",
            "|    explained_variance | 0.054     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 25.5      |\n",
            "|    reward             | 1.8611103 |\n",
            "|    std                | 1.49      |\n",
            "|    value_loss         | 9.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 614        |\n",
            "|    total_timesteps    | 47500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | 3.18       |\n",
            "|    reward             | 0.19562288 |\n",
            "|    std                | 1.5        |\n",
            "|    value_loss         | 0.0825     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 621        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | -14.5      |\n",
            "|    reward             | -0.6260036 |\n",
            "|    std                | 1.51       |\n",
            "|    value_loss         | 1.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 627        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.5      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 8.68       |\n",
            "|    reward             | -0.5730959 |\n",
            "|    std                | 1.51       |\n",
            "|    value_loss         | 1.11       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 634       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.5     |\n",
            "|    explained_variance | 0.0102    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9799      |\n",
            "|    policy_loss        | -87.1     |\n",
            "|    reward             | 1.4229808 |\n",
            "|    std                | 1.52      |\n",
            "|    value_loss         | 31.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 641         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.5       |\n",
            "|    explained_variance | 0.00263     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 41.8        |\n",
            "|    reward             | -0.38746455 |\n",
            "|    std                | 1.52        |\n",
            "|    value_loss         | 7.44        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 647        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.5      |\n",
            "|    explained_variance | 0.0436     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | -8.04      |\n",
            "|    reward             | -2.6057696 |\n",
            "|    std                | 1.52       |\n",
            "|    value_loss         | 2.13       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10100      |\n",
            "|    time_elapsed       | 654        |\n",
            "|    total_timesteps    | 50500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10099      |\n",
            "|    policy_loss        | -1.84      |\n",
            "|    reward             | 0.50052714 |\n",
            "|    std                | 1.52       |\n",
            "|    value_loss         | 0.0808     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 660       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.5     |\n",
            "|    explained_variance | 0.021     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 10.5      |\n",
            "|    reward             | 0.4411873 |\n",
            "|    std                | 1.52      |\n",
            "|    value_loss         | 0.817     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10300      |\n",
            "|    time_elapsed       | 666        |\n",
            "|    total_timesteps    | 51500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.5      |\n",
            "|    explained_variance | 0.00171    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10299      |\n",
            "|    policy_loss        | -39.7      |\n",
            "|    reward             | 0.75353414 |\n",
            "|    std                | 1.52       |\n",
            "|    value_loss         | 7.95       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 673        |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.5      |\n",
            "|    explained_variance | -0.00217   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 55.2       |\n",
            "|    reward             | -2.1197305 |\n",
            "|    std                | 1.53       |\n",
            "|    value_loss         | 13.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 679        |\n",
            "|    total_timesteps    | 52500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.6      |\n",
            "|    explained_variance | 0.0591     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 54.2       |\n",
            "|    reward             | -2.4715602 |\n",
            "|    std                | 1.53       |\n",
            "|    value_loss         | 9.35       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10600      |\n",
            "|    time_elapsed       | 686        |\n",
            "|    total_timesteps    | 53000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.6      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10599      |\n",
            "|    policy_loss        | -102       |\n",
            "|    reward             | -1.2297539 |\n",
            "|    std                | 1.53       |\n",
            "|    value_loss         | 61.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 692       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | 4.64      |\n",
            "|    reward             | 0.2574355 |\n",
            "|    std                | 1.54      |\n",
            "|    value_loss         | 0.0908    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 698         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.6       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 16.4        |\n",
            "|    reward             | -0.10138466 |\n",
            "|    std                | 1.54        |\n",
            "|    value_loss         | 1.35        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 705        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | -23.6      |\n",
            "|    reward             | -1.5206195 |\n",
            "|    std                | 1.55       |\n",
            "|    value_loss         | 5.17       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 11000    |\n",
            "|    time_elapsed       | 711      |\n",
            "|    total_timesteps    | 55000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -16.7    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10999    |\n",
            "|    policy_loss        | -5.36    |\n",
            "|    reward             | 0.783939 |\n",
            "|    std                | 1.55     |\n",
            "|    value_loss         | 0.331    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 11100     |\n",
            "|    time_elapsed       | 717       |\n",
            "|    total_timesteps    | 55500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.8     |\n",
            "|    explained_variance | 0.00794   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11099     |\n",
            "|    policy_loss        | 110       |\n",
            "|    reward             | 1.7727456 |\n",
            "|    std                | 1.56      |\n",
            "|    value_loss         | 65.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 723        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -19        |\n",
            "|    reward             | -4.2451487 |\n",
            "|    std                | 1.56       |\n",
            "|    value_loss         | 5.58       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4453198.19\n",
            "total_reward: 3453198.19\n",
            "total_cost: 31390.07\n",
            "total_trades: 13092\n",
            "Sharpe: 0.836\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11300      |\n",
            "|    time_elapsed       | 730        |\n",
            "|    total_timesteps    | 56500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -16.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11299      |\n",
            "|    policy_loss        | 3.9        |\n",
            "|    reward             | 0.14271176 |\n",
            "|    std                | 1.58       |\n",
            "|    value_loss         | 0.0632     |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 11400    |\n",
            "|    time_elapsed       | 736      |\n",
            "|    total_timesteps    | 57000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -16.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11399    |\n",
            "|    policy_loss        | 1.08     |\n",
            "|    reward             | 0.252707 |\n",
            "|    std                | 1.59     |\n",
            "|    value_loss         | 0.0461   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 743       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -16.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 1.92      |\n",
            "|    reward             | 1.0538138 |\n",
            "|    std                | 1.59      |\n",
            "|    value_loss         | 0.132     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11600      |\n",
            "|    time_elapsed       | 749        |\n",
            "|    total_timesteps    | 58000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11599      |\n",
            "|    policy_loss        | 3.11       |\n",
            "|    reward             | 0.25030935 |\n",
            "|    std                | 1.6        |\n",
            "|    value_loss         | 0.0613     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 11700       |\n",
            "|    time_elapsed       | 755         |\n",
            "|    total_timesteps    | 58500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17         |\n",
            "|    explained_variance | -0.391      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11699       |\n",
            "|    policy_loss        | 41.6        |\n",
            "|    reward             | -0.39975604 |\n",
            "|    std                | 1.6         |\n",
            "|    value_loss         | 8.37        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 11800    |\n",
            "|    time_elapsed       | 761      |\n",
            "|    total_timesteps    | 59000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -17      |\n",
            "|    explained_variance | -0.101   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11799    |\n",
            "|    policy_loss        | -65      |\n",
            "|    reward             | 3.608613 |\n",
            "|    std                | 1.6      |\n",
            "|    value_loss         | 57.2     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 11900      |\n",
            "|    time_elapsed       | 768        |\n",
            "|    total_timesteps    | 59500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11899      |\n",
            "|    policy_loss        | -16.5      |\n",
            "|    reward             | -0.6426374 |\n",
            "|    std                | 1.6        |\n",
            "|    value_loss         | 1.56       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 774        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -11.6      |\n",
            "|    reward             | -2.1518736 |\n",
            "|    std                | 1.6        |\n",
            "|    value_loss         | 1.38       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 780       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -3.93     |\n",
            "|    reward             | 0.3703959 |\n",
            "|    std                | 1.6       |\n",
            "|    value_loss         | 0.211     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 787        |\n",
            "|    total_timesteps    | 61000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0.0035     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | -109       |\n",
            "|    reward             | 0.24107222 |\n",
            "|    std                | 1.6        |\n",
            "|    value_loss         | 42.4       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 12300    |\n",
            "|    time_elapsed       | 793      |\n",
            "|    total_timesteps    | 61500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -17      |\n",
            "|    explained_variance | 0.000129 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12299    |\n",
            "|    policy_loss        | -74.5    |\n",
            "|    reward             | 2.829708 |\n",
            "|    std                | 1.61     |\n",
            "|    value_loss         | 31.7     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 799       |\n",
            "|    total_timesteps    | 62000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | 157       |\n",
            "|    reward             | 6.9895577 |\n",
            "|    std                | 1.61      |\n",
            "|    value_loss         | 106       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 806       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -48.9     |\n",
            "|    reward             | 3.9531329 |\n",
            "|    std                | 1.61      |\n",
            "|    value_loss         | 8.84      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 812        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | -10.2      |\n",
            "|    reward             | -1.0488048 |\n",
            "|    std                | 1.61       |\n",
            "|    value_loss         | 0.574      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12700     |\n",
            "|    time_elapsed       | 819       |\n",
            "|    total_timesteps    | 63500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12699     |\n",
            "|    policy_loss        | -55.8     |\n",
            "|    reward             | -0.599059 |\n",
            "|    std                | 1.61      |\n",
            "|    value_loss         | 11.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 12800       |\n",
            "|    time_elapsed       | 825         |\n",
            "|    total_timesteps    | 64000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17         |\n",
            "|    explained_variance | 0.00481     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12799       |\n",
            "|    policy_loss        | 2.11        |\n",
            "|    reward             | -0.70493656 |\n",
            "|    std                | 1.61        |\n",
            "|    value_loss         | 0.158       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 12900    |\n",
            "|    time_elapsed       | 831      |\n",
            "|    total_timesteps    | 64500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -17      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12899    |\n",
            "|    policy_loss        | -12.6    |\n",
            "|    reward             | 2.662907 |\n",
            "|    std                | 1.6      |\n",
            "|    value_loss         | 2.25     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13000      |\n",
            "|    time_elapsed       | 838        |\n",
            "|    total_timesteps    | 65000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12999      |\n",
            "|    policy_loss        | 43.2       |\n",
            "|    reward             | -5.8227425 |\n",
            "|    std                | 1.6        |\n",
            "|    value_loss         | 21.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 844       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -95.1     |\n",
            "|    reward             | 3.4898899 |\n",
            "|    std                | 1.61      |\n",
            "|    value_loss         | 31.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 850        |\n",
            "|    total_timesteps    | 66000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.1      |\n",
            "|    explained_variance | -0.0196    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | -31.5      |\n",
            "|    reward             | -1.0765461 |\n",
            "|    std                | 1.62       |\n",
            "|    value_loss         | 3.84       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13300      |\n",
            "|    time_elapsed       | 857        |\n",
            "|    total_timesteps    | 66500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13299      |\n",
            "|    policy_loss        | -41.7      |\n",
            "|    reward             | 0.08331645 |\n",
            "|    std                | 1.61       |\n",
            "|    value_loss         | 8.13       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13400     |\n",
            "|    time_elapsed       | 863       |\n",
            "|    total_timesteps    | 67000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | -0.000595 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13399     |\n",
            "|    policy_loss        | 50.2      |\n",
            "|    reward             | 0.1785299 |\n",
            "|    std                | 1.62      |\n",
            "|    value_loss         | 9.83      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13500     |\n",
            "|    time_elapsed       | 870       |\n",
            "|    total_timesteps    | 67500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 0.0033    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13499     |\n",
            "|    policy_loss        | 30.5      |\n",
            "|    reward             | 0.4348793 |\n",
            "|    std                | 1.62      |\n",
            "|    value_loss         | 7.7       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13600      |\n",
            "|    time_elapsed       | 876        |\n",
            "|    total_timesteps    | 68000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13599      |\n",
            "|    policy_loss        | -34.7      |\n",
            "|    reward             | -1.2239152 |\n",
            "|    std                | 1.61       |\n",
            "|    value_loss         | 12.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 882       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 9.3e-05   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 48        |\n",
            "|    reward             | 1.7474438 |\n",
            "|    std                | 1.63      |\n",
            "|    value_loss         | 13.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 889       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -3.66     |\n",
            "|    reward             | 1.9841018 |\n",
            "|    std                | 1.63      |\n",
            "|    value_loss         | 0.168     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 895        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | -8.41      |\n",
            "|    reward             | -2.1433022 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 1.63       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 902         |\n",
            "|    total_timesteps    | 70000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | -5.33       |\n",
            "|    reward             | -0.12383939 |\n",
            "|    std                | 1.63        |\n",
            "|    value_loss         | 0.13        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14100       |\n",
            "|    time_elapsed       | 908         |\n",
            "|    total_timesteps    | 70500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14099       |\n",
            "|    policy_loss        | -20.7       |\n",
            "|    reward             | -0.14577158 |\n",
            "|    std                | 1.63        |\n",
            "|    value_loss         | 2.3         |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14200       |\n",
            "|    time_elapsed       | 915         |\n",
            "|    total_timesteps    | 71000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14199       |\n",
            "|    policy_loss        | 0.884       |\n",
            "|    reward             | 0.004583108 |\n",
            "|    std                | 1.62        |\n",
            "|    value_loss         | 0.00335     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 921       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 11.3      |\n",
            "|    reward             | 0.8768231 |\n",
            "|    std                | 1.63      |\n",
            "|    value_loss         | 1         |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 14400     |\n",
            "|    time_elapsed       | 927       |\n",
            "|    total_timesteps    | 72000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14399     |\n",
            "|    policy_loss        | -68.4     |\n",
            "|    reward             | 1.0980698 |\n",
            "|    std                | 1.63      |\n",
            "|    value_loss         | 17.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 14500       |\n",
            "|    time_elapsed       | 934         |\n",
            "|    total_timesteps    | 72500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.1       |\n",
            "|    explained_variance | -4.65e-06   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14499       |\n",
            "|    policy_loss        | -80.1       |\n",
            "|    reward             | -0.17966373 |\n",
            "|    std                | 1.63        |\n",
            "|    value_loss         | 20.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 14600     |\n",
            "|    time_elapsed       | 940       |\n",
            "|    total_timesteps    | 73000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14599     |\n",
            "|    policy_loss        | 33.1      |\n",
            "|    reward             | -5.689676 |\n",
            "|    std                | 1.63      |\n",
            "|    value_loss         | 7.32      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 947        |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 47.8       |\n",
            "|    reward             | -3.9415646 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 10         |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 14800        |\n",
            "|    time_elapsed       | 953          |\n",
            "|    total_timesteps    | 74000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 14799        |\n",
            "|    policy_loss        | 1.97         |\n",
            "|    reward             | -0.096191086 |\n",
            "|    std                | 1.63         |\n",
            "|    value_loss         | 0.0183       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 14900      |\n",
            "|    time_elapsed       | 959        |\n",
            "|    total_timesteps    | 74500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.1      |\n",
            "|    explained_variance | 0.00973    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14899      |\n",
            "|    policy_loss        | -51.1      |\n",
            "|    reward             | 0.27810416 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 8.33       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 966        |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | -0.000409  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -39.6      |\n",
            "|    reward             | -1.8546929 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 6.72       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 973        |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 1.33       |\n",
            "|    reward             | -2.9546192 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 0.505      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 979       |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -84.6     |\n",
            "|    reward             | 4.1225257 |\n",
            "|    std                | 1.63      |\n",
            "|    value_loss         | 78.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 985        |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 4.23e-05   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -357       |\n",
            "|    reward             | -7.5593987 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 600        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 992         |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 9.65        |\n",
            "|    reward             | -0.08063635 |\n",
            "|    std                | 1.64        |\n",
            "|    value_loss         | 0.498       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 999       |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 43.7      |\n",
            "|    reward             | 1.3058605 |\n",
            "|    std                | 1.64      |\n",
            "|    value_loss         | 7.79      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 1005       |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 30         |\n",
            "|    reward             | 0.28707922 |\n",
            "|    std                | 1.64       |\n",
            "|    value_loss         | 3.63       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15700      |\n",
            "|    time_elapsed       | 1012       |\n",
            "|    total_timesteps    | 78500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0.000213   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15699      |\n",
            "|    policy_loss        | 2.51       |\n",
            "|    reward             | 0.20739152 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.398      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 1018      |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -29.1     |\n",
            "|    reward             | 1.6081518 |\n",
            "|    std                | 1.64      |\n",
            "|    value_loss         | 3.51      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 15900      |\n",
            "|    time_elapsed       | 1024       |\n",
            "|    total_timesteps    | 79500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15899      |\n",
            "|    policy_loss        | 98.4       |\n",
            "|    reward             | -1.4234226 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 53.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 16000       |\n",
            "|    time_elapsed       | 1031        |\n",
            "|    total_timesteps    | 80000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15999       |\n",
            "|    policy_loss        | -2.38       |\n",
            "|    reward             | -0.77076924 |\n",
            "|    std                | 1.65        |\n",
            "|    value_loss         | 0.695       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 1037      |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -0.364    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 23.8      |\n",
            "|    reward             | 1.1257583 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 4.66      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1044      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -1.9      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -44.2     |\n",
            "|    reward             | 0.5714981 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 8.01      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16300      |\n",
            "|    time_elapsed       | 1050       |\n",
            "|    total_timesteps    | 81500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.3      |\n",
            "|    explained_variance | -91.2      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16299      |\n",
            "|    policy_loss        | -150       |\n",
            "|    reward             | 0.07589647 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 83         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 1056      |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -0.497    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | -11.3     |\n",
            "|    reward             | 1.1117227 |\n",
            "|    std                | 1.66      |\n",
            "|    value_loss         | 5.44      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 16500     |\n",
            "|    time_elapsed       | 1063      |\n",
            "|    total_timesteps    | 82500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | -0.0199   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16499     |\n",
            "|    policy_loss        | -76.8     |\n",
            "|    reward             | 0.9911848 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 39.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16600      |\n",
            "|    time_elapsed       | 1069       |\n",
            "|    total_timesteps    | 83000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16599      |\n",
            "|    policy_loss        | 11.5       |\n",
            "|    reward             | 0.13083261 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.554      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16700      |\n",
            "|    time_elapsed       | 1076       |\n",
            "|    total_timesteps    | 83500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16699      |\n",
            "|    policy_loss        | -42.6      |\n",
            "|    reward             | 0.35368082 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 6.96       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1082       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0.104      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 7.84       |\n",
            "|    reward             | -1.7907326 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 1.26       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 16900    |\n",
            "|    time_elapsed       | 1089     |\n",
            "|    total_timesteps    | 84500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -17.2    |\n",
            "|    explained_variance | -0.0525  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16899    |\n",
            "|    policy_loss        | -35.3    |\n",
            "|    reward             | 1.364092 |\n",
            "|    std                | 1.65     |\n",
            "|    value_loss         | 4.74     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1095       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.3      |\n",
            "|    explained_variance | -0.0129    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -17.4      |\n",
            "|    reward             | -3.0725763 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 3.61       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1101      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -0.0519   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -217      |\n",
            "|    reward             | 4.2963805 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 141       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5591028.00\n",
            "total_reward: 4591028.00\n",
            "total_cost: 62330.25\n",
            "total_trades: 19302\n",
            "Sharpe: 0.943\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17200      |\n",
            "|    time_elapsed       | 1109       |\n",
            "|    total_timesteps    | 86000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17199      |\n",
            "|    policy_loss        | 1.41       |\n",
            "|    reward             | 0.17621139 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.0731     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17300      |\n",
            "|    time_elapsed       | 1115       |\n",
            "|    total_timesteps    | 86500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0.0586     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17299      |\n",
            "|    policy_loss        | -12.1      |\n",
            "|    reward             | 0.64680606 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.631      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17400      |\n",
            "|    time_elapsed       | 1121       |\n",
            "|    total_timesteps    | 87000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.3      |\n",
            "|    explained_variance | -0.00132   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17399      |\n",
            "|    policy_loss        | -14.7      |\n",
            "|    reward             | -2.4931622 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.856      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 1128      |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | -19       |\n",
            "|    reward             | 0.5199047 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 2.38      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17600      |\n",
            "|    time_elapsed       | 1134       |\n",
            "|    total_timesteps    | 88000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17599      |\n",
            "|    policy_loss        | 168        |\n",
            "|    reward             | -0.5670408 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 121        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 17700    |\n",
            "|    time_elapsed       | 1141     |\n",
            "|    total_timesteps    | 88500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -17.2    |\n",
            "|    explained_variance | 5.81e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17699    |\n",
            "|    policy_loss        | 39.8     |\n",
            "|    reward             | 3.965457 |\n",
            "|    std                | 1.65     |\n",
            "|    value_loss         | 9.23     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1147       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 4.89       |\n",
            "|    reward             | 0.83105236 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.114      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1153       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -1.8       |\n",
            "|    reward             | -2.7443361 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 0.0549     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 18000     |\n",
            "|    time_elapsed       | 1160      |\n",
            "|    total_timesteps    | 90000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17999     |\n",
            "|    policy_loss        | 21.7      |\n",
            "|    reward             | 0.3040749 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 2.29      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1166      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | -18.7     |\n",
            "|    reward             | 0.9871412 |\n",
            "|    std                | 1.64      |\n",
            "|    value_loss         | 1.7       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 1172       |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | -0.000412  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | -1.4       |\n",
            "|    reward             | -1.4182849 |\n",
            "|    std                | 1.64       |\n",
            "|    value_loss         | 5.87       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 1179       |\n",
            "|    total_timesteps    | 91500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -302       |\n",
            "|    reward             | -1.6568189 |\n",
            "|    std                | 1.64       |\n",
            "|    value_loss         | 283        |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 18400        |\n",
            "|    time_elapsed       | 1188         |\n",
            "|    total_timesteps    | 92000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.2        |\n",
            "|    explained_variance | 0.00565      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 18399        |\n",
            "|    policy_loss        | 17.2         |\n",
            "|    reward             | -0.073865265 |\n",
            "|    std                | 1.64         |\n",
            "|    value_loss         | 1.41         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 1197        |\n",
            "|    total_timesteps    | 92500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.2       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | -10.3       |\n",
            "|    reward             | -0.55024344 |\n",
            "|    std                | 1.64        |\n",
            "|    value_loss         | 3.87        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 1207      |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.2     |\n",
            "|    explained_variance | -0.0764   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | -7.69     |\n",
            "|    reward             | 0.5959811 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 0.389     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1216      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -25.3     |\n",
            "|    reward             | 3.0681956 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 2.81      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 18800    |\n",
            "|    time_elapsed       | 1223     |\n",
            "|    total_timesteps    | 94000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -17.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18799    |\n",
            "|    policy_loss        | 71.1     |\n",
            "|    reward             | 1.23539  |\n",
            "|    std                | 1.65     |\n",
            "|    value_loss         | 20.9     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1230       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 73.3       |\n",
            "|    reward             | 0.13139597 |\n",
            "|    std                | 1.65       |\n",
            "|    value_loss         | 32.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1237      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | -6.57     |\n",
            "|    reward             | 0.5445162 |\n",
            "|    std                | 1.65      |\n",
            "|    value_loss         | 0.628     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1243      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -0.195    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -94.4     |\n",
            "|    reward             | 1.2133163 |\n",
            "|    std                | 1.66      |\n",
            "|    value_loss         | 29.5      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 19200       |\n",
            "|    time_elapsed       | 1250        |\n",
            "|    total_timesteps    | 96000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19199       |\n",
            "|    policy_loss        | 0.663       |\n",
            "|    reward             | -0.33221725 |\n",
            "|    std                | 1.66        |\n",
            "|    value_loss         | 0.919       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19300      |\n",
            "|    time_elapsed       | 1256       |\n",
            "|    total_timesteps    | 96500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.3      |\n",
            "|    explained_variance | 0.00377    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19299      |\n",
            "|    policy_loss        | 13.9       |\n",
            "|    reward             | 0.21832305 |\n",
            "|    std                | 1.66       |\n",
            "|    value_loss         | 1.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1263      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | 0.0246    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 100       |\n",
            "|    reward             | 1.3533738 |\n",
            "|    std                | 1.66      |\n",
            "|    value_loss         | 54.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19500      |\n",
            "|    time_elapsed       | 1269       |\n",
            "|    total_timesteps    | 97500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.3      |\n",
            "|    explained_variance | 0.00223    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19499      |\n",
            "|    policy_loss        | 27.4       |\n",
            "|    reward             | -1.4532268 |\n",
            "|    std                | 1.66       |\n",
            "|    value_loss         | 4.79       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1276      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.3     |\n",
            "|    explained_variance | -0.0931   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 29.1      |\n",
            "|    reward             | 0.8529325 |\n",
            "|    std                | 1.67      |\n",
            "|    value_loss         | 6.23      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19700      |\n",
            "|    time_elapsed       | 1283       |\n",
            "|    total_timesteps    | 98500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.4      |\n",
            "|    explained_variance | -0.128     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19699      |\n",
            "|    policy_loss        | -44.1      |\n",
            "|    reward             | 0.39799857 |\n",
            "|    std                | 1.67       |\n",
            "|    value_loss         | 9.21       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 1289      |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -17.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | 24.1      |\n",
            "|    reward             | -7.309108 |\n",
            "|    std                | 1.67      |\n",
            "|    value_loss         | 2.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1296       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.4      |\n",
            "|    explained_variance | -0.247     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -42.8      |\n",
            "|    reward             | -2.7979202 |\n",
            "|    std                | 1.67       |\n",
            "|    value_loss         | 6.75       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 20000      |\n",
            "|    time_elapsed       | 1302       |\n",
            "|    total_timesteps    | 100000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -17.4      |\n",
            "|    explained_variance | -0.0191    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19999      |\n",
            "|    policy_loss        | -28.6      |\n",
            "|    reward             | -5.1131434 |\n",
            "|    std                | 1.68       |\n",
            "|    value_loss         | 9.75       |\n",
            "--------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.999031e+05  9.905746e+05\n",
            "2021-10-05  1.000117e+06  9.996566e+05\n",
            "2021-10-06  1.000483e+06  1.002637e+06\n",
            "2021-10-07  1.001131e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  8.950822e+05  9.854252e+05\n",
            "2023-04-28  8.971657e+05  9.933491e+05\n",
            "2023-05-01  8.940644e+05  9.919956e+05\n",
            "2023-05-02  8.860837e+05  9.812993e+05\n",
            "2023-05-03  8.805903e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -11.94 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 74            |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 6             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.6         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0239       |\n",
            "|    reward             | -0.0004280027 |\n",
            "|    std                | 1.1           |\n",
            "|    value_loss         | 4.07e-06      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -4.84       |\n",
            "|    reward             | 0.124171816 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.313       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | -0.209     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -0.649     |\n",
            "|    reward             | -1.2698591 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 1.18       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -18.5      |\n",
            "|    reward             | 0.46781105 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 1.96       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14        |\n",
            "|    explained_variance | 0.0129     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -22.7      |\n",
            "|    reward             | -1.1845229 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 3.45       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 78            |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.1         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | -1.72         |\n",
            "|    reward             | -0.0033372298 |\n",
            "|    std                | 1.15          |\n",
            "|    value_loss         | 0.0213        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 3.96        |\n",
            "|    reward             | -0.35966882 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.154       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | -1.23       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 25.9        |\n",
            "|    reward             | -0.25102866 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 4.88        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0.209     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -18.8     |\n",
            "|    reward             | 1.7598027 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 2.31      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | -0.0315     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -61.1       |\n",
            "|    reward             | -0.48312512 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 34.9        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.1        |\n",
            "|    explained_variance | -0.0146      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -1.18        |\n",
            "|    reward             | -0.022055056 |\n",
            "|    std                | 1.16         |\n",
            "|    value_loss         | 0.618        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 77         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -8.17      |\n",
            "|    reward             | -0.6616551 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.543      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 82         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0.391      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -15.1      |\n",
            "|    reward             | 0.73310435 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 1.64       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 24.4       |\n",
            "|    reward             | 0.84521806 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 4.85       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 95         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 8.73       |\n",
            "|    reward             | -1.9718854 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 2.63       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 37.7        |\n",
            "|    reward             | -0.13830118 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 18.2        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 249        |\n",
            "|    reward             | 13.5746355 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 406        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -28.2     |\n",
            "|    reward             | 0.4087457 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 5.03      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -40.4     |\n",
            "|    reward             | 0.6155334 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 10        |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 125         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 9.35        |\n",
            "|    reward             | -0.40538633 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 1.11        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 132       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0.0138    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -23       |\n",
            "|    reward             | 3.0675204 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 5.97      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 139         |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 16.6        |\n",
            "|    reward             | -0.28939936 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 1.83        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 145      |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.1    |\n",
            "|    explained_variance | 0.00765  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 141      |\n",
            "|    reward             | 3.52389  |\n",
            "|    std                | 1.16     |\n",
            "|    value_loss         | 135      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 151        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -0.0256    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 26.9       |\n",
            "|    reward             | 0.19122519 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 3.99       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 158       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -11.7     |\n",
            "|    reward             | 1.0560255 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 1.3       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 164       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0.0347    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 8.48      |\n",
            "|    reward             | 0.5525642 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 1.74      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 171        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -1.2       |\n",
            "|    reward             | -0.9295722 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.394      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 178         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | -40.2       |\n",
            "|    reward             | 0.102830715 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 9.59        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 185         |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 54.8        |\n",
            "|    reward             | -0.21288449 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 46.1        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 191         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 9.02        |\n",
            "|    reward             | -0.79171103 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.562       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 198       |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -33.7     |\n",
            "|    reward             | 0.6175297 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 9         |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 204       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.1     |\n",
            "|    explained_variance | -0.00245  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 62.7      |\n",
            "|    reward             | 1.0270114 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 24        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 210        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 7.57       |\n",
            "|    reward             | -0.9360845 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.714      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 217         |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | -75.8       |\n",
            "|    reward             | -0.21637663 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 136         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 223        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | 102        |\n",
            "|    reward             | -2.8919108 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 105        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 229        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | -0.776     |\n",
            "|    reward             | 0.75260663 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.085      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 236        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 2.78       |\n",
            "|    reward             | -0.4976081 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.31       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 244          |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 18.2         |\n",
            "|    reward             | -0.091386266 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 8.21         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 250       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | -0.0262   |\n",
            "|    reward             | 0.7873215 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.535     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 256        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -80.5      |\n",
            "|    reward             | -7.1096506 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 41.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 262       |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | -78.5     |\n",
            "|    reward             | 3.1965835 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 43.8      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 268         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | -0.0451     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -12.5       |\n",
            "|    reward             | -0.96575963 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 1.81        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 274         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 0.0113      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 20          |\n",
            "|    reward             | -0.23238339 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 1.89        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 281        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -26.1      |\n",
            "|    reward             | -2.5912998 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 3.35       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 288       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | -1.03     |\n",
            "|    reward             | 3.5192642 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 0.111     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 294         |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | 49.3        |\n",
            "|    reward             | 0.025348142 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 14          |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 300        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 71.4       |\n",
            "|    reward             | 0.76692224 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 26.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 306       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -8.34     |\n",
            "|    reward             | -1.046716 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 4.9       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 312         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 24.3        |\n",
            "|    reward             | -0.43470135 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 5.43        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 319        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -17.2      |\n",
            "|    reward             | 0.22668648 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 2.03       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 325         |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | 42.8        |\n",
            "|    reward             | 0.017834654 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 11.4        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 330         |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | 11.8        |\n",
            "|    reward             | -0.22215775 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.986       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 337       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 61.5      |\n",
            "|    reward             | -4.579333 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 20.2      |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3467069.68\n",
            "total_reward: 2467069.68\n",
            "total_cost: 10230.02\n",
            "total_trades: 15294\n",
            "Sharpe: 0.632\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 343         |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | -37.4       |\n",
            "|    reward             | -0.74574286 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 7.9         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 349        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 22.9       |\n",
            "|    reward             | 0.10782968 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 2.82       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 355       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | -0.00261  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -37       |\n",
            "|    reward             | 0.2663486 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 11.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 362       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | -12.7     |\n",
            "|    reward             | 1.1704011 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 2.12      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 368      |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.3    |\n",
            "|    explained_variance | -0.0383  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | 64.3     |\n",
            "|    reward             | 1.138196 |\n",
            "|    std                | 1.19     |\n",
            "|    value_loss         | 27.2     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 374         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.3       |\n",
            "|    explained_variance | 0.0517      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -2.92       |\n",
            "|    reward             | 0.040135995 |\n",
            "|    std                | 1.19        |\n",
            "|    value_loss         | 2.24        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 380       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -54       |\n",
            "|    reward             | 0.4125928 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 15        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 387        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 9.7        |\n",
            "|    reward             | 0.14563952 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.885      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 393        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.4      |\n",
            "|    explained_variance | -0.218     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | 13.5       |\n",
            "|    reward             | -2.3571439 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 31.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 399       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | -0.0426   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | 15.9      |\n",
            "|    reward             | 1.1982734 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 1.64      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 406       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 14.1      |\n",
            "|    reward             | 2.4257765 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 5.47      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 412       |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | -53       |\n",
            "|    reward             | 1.5760953 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 13.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 418        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -56.5      |\n",
            "|    reward             | -2.1070158 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 14.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 425       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 1.33      |\n",
            "|    reward             | 1.2448928 |\n",
            "|    std                | 1.21      |\n",
            "|    value_loss         | 0.298     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 431        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 53.8       |\n",
            "|    reward             | -1.4042519 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 13.2       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 438         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | -3.66       |\n",
            "|    reward             | -0.56102335 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 0.399       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 444        |\n",
            "|    total_timesteps    | 35000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6999       |\n",
            "|    policy_loss        | 25         |\n",
            "|    reward             | -1.7346843 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 4.85       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 78            |\n",
            "|    iterations         | 7100          |\n",
            "|    time_elapsed       | 450           |\n",
            "|    total_timesteps    | 35500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7099          |\n",
            "|    policy_loss        | -1.28         |\n",
            "|    reward             | -0.0041438304 |\n",
            "|    std                | 1.22          |\n",
            "|    value_loss         | 0.00888       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 78           |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 456          |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.5        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | -14.5        |\n",
            "|    reward             | -0.052881613 |\n",
            "|    std                | 1.22         |\n",
            "|    value_loss         | 1.05         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 462        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | -15.3      |\n",
            "|    reward             | 0.21467263 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 1.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 468       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -3.71     |\n",
            "|    reward             | 0.3514923 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 0.469     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 475       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 13.8      |\n",
            "|    reward             | 0.1294618 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 2.93      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 481       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0.000112  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 26.9      |\n",
            "|    reward             | 1.5671091 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 4.58      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 488        |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | 2.86       |\n",
            "|    reward             | 0.07891019 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.0926     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 494        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | 2.58       |\n",
            "|    reward             | -2.4715466 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.324      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 500       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -38.7     |\n",
            "|    reward             | 1.0922914 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 8.31      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 506         |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -12.8       |\n",
            "|    reward             | -0.04981475 |\n",
            "|    std                | 1.23        |\n",
            "|    value_loss         | 6.49        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 512       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -49.8     |\n",
            "|    reward             | 3.1209254 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 17.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 518        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.6      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -234       |\n",
            "|    reward             | -4.8634973 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 301        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 524       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | -34.5     |\n",
            "|    reward             | -2.346108 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 7.74      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 530       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | -0.117    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | -53.8     |\n",
            "|    reward             | 0.6764775 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 17.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 537       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 9.63      |\n",
            "|    reward             | 1.5618892 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 1.16      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 543       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | -47.9     |\n",
            "|    reward             | 2.3160877 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 11.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 549       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -10.9     |\n",
            "|    reward             | 1.2744728 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 2.03      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 555       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | 145       |\n",
            "|    reward             | -2.535293 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 103       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 561      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.7    |\n",
            "|    explained_variance | 0.166    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | 35.6     |\n",
            "|    reward             | 2.841805 |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 7.47     |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 79           |\n",
            "|    iterations         | 9000         |\n",
            "|    time_elapsed       | 567          |\n",
            "|    total_timesteps    | 45000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8999         |\n",
            "|    policy_loss        | 35.9         |\n",
            "|    reward             | -0.007879069 |\n",
            "|    std                | 1.25         |\n",
            "|    value_loss         | 7.74         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 574       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | 25.6      |\n",
            "|    reward             | 1.0033793 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 2.76      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 580        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.7      |\n",
            "|    explained_variance | -7.15e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 17.1       |\n",
            "|    reward             | 0.42526075 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 3.48       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 586        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.7      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | -3.38      |\n",
            "|    reward             | 0.35522687 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 0.628      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 592        |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | 24.7       |\n",
            "|    reward             | -0.8164774 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 8.34       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 598       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 15.3      |\n",
            "|    reward             | 1.0274758 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 1.83      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 605        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 1.32       |\n",
            "|    reward             | -1.7517363 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 2.34       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 611         |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.7       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9699        |\n",
            "|    policy_loss        | 8.02        |\n",
            "|    reward             | -0.58093137 |\n",
            "|    std                | 1.25        |\n",
            "|    value_loss         | 1.42        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 618        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -28.7      |\n",
            "|    reward             | -1.0367563 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 8.3        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 624        |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | -27.8      |\n",
            "|    reward             | 0.52580637 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 4.63       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 630       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | -23.7     |\n",
            "|    reward             | -4.295985 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 3.48      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 636       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.8     |\n",
            "|    explained_variance | -0.0107   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 10.3      |\n",
            "|    reward             | 1.5756103 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 1.49      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 642       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.8     |\n",
            "|    explained_variance | 0.038     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 24.8      |\n",
            "|    reward             | 0.9945461 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 4.35      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 648       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.8     |\n",
            "|    explained_variance | 0.116     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -4.48     |\n",
            "|    reward             | 1.5776736 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 0.268     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 655        |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 0.145      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 78.5       |\n",
            "|    reward             | -0.3049693 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 26.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 662       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 59.4      |\n",
            "|    reward             | -5.584084 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 25.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10600      |\n",
            "|    time_elapsed       | 677        |\n",
            "|    total_timesteps    | 53000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10599      |\n",
            "|    policy_loss        | -68.6      |\n",
            "|    reward             | -2.0650651 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 42.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 684        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | 15.8       |\n",
            "|    reward             | 0.26789764 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 2.1        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 10800      |\n",
            "|    time_elapsed       | 690        |\n",
            "|    total_timesteps    | 54000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10799      |\n",
            "|    policy_loss        | 21.1       |\n",
            "|    reward             | -0.5015444 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 2.76       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 10900       |\n",
            "|    time_elapsed       | 696         |\n",
            "|    total_timesteps    | 54500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10899       |\n",
            "|    policy_loss        | 32          |\n",
            "|    reward             | -0.51052946 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 5.59        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 703        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -17.8      |\n",
            "|    reward             | 0.29974097 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 2.58       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11100      |\n",
            "|    time_elapsed       | 709        |\n",
            "|    total_timesteps    | 55500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11099      |\n",
            "|    policy_loss        | 89.9       |\n",
            "|    reward             | -0.2684931 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 39.9       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 11200    |\n",
            "|    time_elapsed       | 715      |\n",
            "|    total_timesteps    | 56000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11199    |\n",
            "|    policy_loss        | 3.64     |\n",
            "|    reward             | 1.499363 |\n",
            "|    std                | 1.28     |\n",
            "|    value_loss         | 0.316    |\n",
            "------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2158986.51\n",
            "total_reward: 1158986.51\n",
            "total_cost: 7903.24\n",
            "total_trades: 15881\n",
            "Sharpe: 0.424\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11300      |\n",
            "|    time_elapsed       | 722        |\n",
            "|    total_timesteps    | 56500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11299      |\n",
            "|    policy_loss        | 21.3       |\n",
            "|    reward             | -0.5862637 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 2.65       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 728       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 15.1      |\n",
            "|    reward             | 0.5827514 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 1.39      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 735       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15       |\n",
            "|    explained_variance | -0.238    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 17.7      |\n",
            "|    reward             | 2.4541488 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 3.67      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 11600     |\n",
            "|    time_elapsed       | 741       |\n",
            "|    total_timesteps    | 58000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -14.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11599     |\n",
            "|    policy_loss        | 12.2      |\n",
            "|    reward             | 0.5773469 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 1.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11700      |\n",
            "|    time_elapsed       | 747        |\n",
            "|    total_timesteps    | 58500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11699      |\n",
            "|    policy_loss        | 45.4       |\n",
            "|    reward             | 0.19572847 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 14.5       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 11800    |\n",
            "|    time_elapsed       | 753      |\n",
            "|    total_timesteps    | 59000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -14.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11799    |\n",
            "|    policy_loss        | -129     |\n",
            "|    reward             | 5.302461 |\n",
            "|    std                | 1.28     |\n",
            "|    value_loss         | 156      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 11900      |\n",
            "|    time_elapsed       | 760        |\n",
            "|    total_timesteps    | 59500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -14.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11899      |\n",
            "|    policy_loss        | -21.2      |\n",
            "|    reward             | -0.6927757 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 3.02       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 766        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -22.4      |\n",
            "|    reward             | -2.3743513 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 2.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 772       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15       |\n",
            "|    explained_variance | 0.0642    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -3.36     |\n",
            "|    reward             | 0.7759596 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 0.267     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 780        |\n",
            "|    total_timesteps    | 61000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | -62.5      |\n",
            "|    reward             | 0.80058914 |\n",
            "|    std                | 1.29       |\n",
            "|    value_loss         | 18         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 788       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | -72       |\n",
            "|    reward             | 3.2497547 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 28.1      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 796      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15      |\n",
            "|    explained_variance | 0.0249   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | 69.6     |\n",
            "|    reward             | 4.846509 |\n",
            "|    std                | 1.29     |\n",
            "|    value_loss         | 25.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 805       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -84       |\n",
            "|    reward             | 4.864147  |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 33        |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 12600       |\n",
            "|    time_elapsed       | 812         |\n",
            "|    total_timesteps    | 63000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12599       |\n",
            "|    policy_loss        | 0.841       |\n",
            "|    reward             | -0.92203456 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.112       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 12700      |\n",
            "|    time_elapsed       | 822        |\n",
            "|    total_timesteps    | 63500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12699      |\n",
            "|    policy_loss        | -104       |\n",
            "|    reward             | 0.55787635 |\n",
            "|    std                | 1.29       |\n",
            "|    value_loss         | 48.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 12800       |\n",
            "|    time_elapsed       | 832         |\n",
            "|    total_timesteps    | 64000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12799       |\n",
            "|    policy_loss        | 33.8        |\n",
            "|    reward             | -0.33901286 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 5.81        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 12900    |\n",
            "|    time_elapsed       | 843      |\n",
            "|    total_timesteps    | 64500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12899    |\n",
            "|    policy_loss        | -24.8    |\n",
            "|    reward             | 2.502713 |\n",
            "|    std                | 1.3      |\n",
            "|    value_loss         | 3.99     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 13000      |\n",
            "|    time_elapsed       | 852        |\n",
            "|    total_timesteps    | 65000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12999      |\n",
            "|    policy_loss        | 52.3       |\n",
            "|    reward             | -3.0829644 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 22.3       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 13100    |\n",
            "|    time_elapsed       | 858      |\n",
            "|    total_timesteps    | 65500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.2    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13099    |\n",
            "|    policy_loss        | -88.9    |\n",
            "|    reward             | 3.456311 |\n",
            "|    std                | 1.31     |\n",
            "|    value_loss         | 40.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 13200     |\n",
            "|    time_elapsed       | 865       |\n",
            "|    total_timesteps    | 66000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13199     |\n",
            "|    policy_loss        | -26.6     |\n",
            "|    reward             | -1.521807 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 3.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 872       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | -64.9     |\n",
            "|    reward             | 1.2022648 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 25.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 13400     |\n",
            "|    time_elapsed       | 879       |\n",
            "|    total_timesteps    | 67000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13399     |\n",
            "|    policy_loss        | -4.14     |\n",
            "|    reward             | 0.2718218 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 0.3       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 13500      |\n",
            "|    time_elapsed       | 885        |\n",
            "|    total_timesteps    | 67500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13499      |\n",
            "|    policy_loss        | -11.7      |\n",
            "|    reward             | 0.28065258 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 3.56       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 13600       |\n",
            "|    time_elapsed       | 892         |\n",
            "|    total_timesteps    | 68000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13599       |\n",
            "|    policy_loss        | -83.7       |\n",
            "|    reward             | -0.03539462 |\n",
            "|    std                | 1.31        |\n",
            "|    value_loss         | 26.7        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 899       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 41        |\n",
            "|    reward             | 1.7835933 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 14.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 13800    |\n",
            "|    time_elapsed       | 906      |\n",
            "|    total_timesteps    | 69000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13799    |\n",
            "|    policy_loss        | 5.82     |\n",
            "|    reward             | 1.790539 |\n",
            "|    std                | 1.31     |\n",
            "|    value_loss         | 0.276    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 913        |\n",
            "|    total_timesteps    | 69500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 8.92       |\n",
            "|    reward             | -1.8507254 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 2.58       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 919         |\n",
            "|    total_timesteps    | 70000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | -10.6       |\n",
            "|    reward             | 0.014144327 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 1.87        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 14100      |\n",
            "|    time_elapsed       | 926        |\n",
            "|    total_timesteps    | 70500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14099      |\n",
            "|    policy_loss        | 12.1       |\n",
            "|    reward             | -1.3080163 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 1.84       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 14200      |\n",
            "|    time_elapsed       | 933        |\n",
            "|    total_timesteps    | 71000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14199      |\n",
            "|    policy_loss        | 7.34       |\n",
            "|    reward             | 0.08762555 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.269      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 940       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 8.78      |\n",
            "|    reward             | 0.8483519 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 0.737     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 14400     |\n",
            "|    time_elapsed       | 947       |\n",
            "|    total_timesteps    | 72000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14399     |\n",
            "|    policy_loss        | -56.4     |\n",
            "|    reward             | 0.9089527 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 15.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14500      |\n",
            "|    time_elapsed       | 954        |\n",
            "|    total_timesteps    | 72500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14499      |\n",
            "|    policy_loss        | -42.4      |\n",
            "|    reward             | 0.15782969 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 9.79       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 961        |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 50.8       |\n",
            "|    reward             | -4.5169754 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 15.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 14700     |\n",
            "|    time_elapsed       | 968       |\n",
            "|    total_timesteps    | 73500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14699     |\n",
            "|    policy_loss        | 91.7      |\n",
            "|    reward             | -8.672087 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 46.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 975        |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | 8.11       |\n",
            "|    reward             | 0.43025112 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.478      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 14900       |\n",
            "|    time_elapsed       | 982         |\n",
            "|    total_timesteps    | 74500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14899       |\n",
            "|    policy_loss        | -46         |\n",
            "|    reward             | -0.43224162 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 10.2        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15000      |\n",
            "|    time_elapsed       | 989        |\n",
            "|    total_timesteps    | 75000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14999      |\n",
            "|    policy_loss        | -27.7      |\n",
            "|    reward             | -1.5331348 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 4.51       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15100      |\n",
            "|    time_elapsed       | 995        |\n",
            "|    total_timesteps    | 75500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | -0.436     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15099      |\n",
            "|    policy_loss        | 9.52       |\n",
            "|    reward             | -2.3635125 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 1.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 1002      |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -30.7     |\n",
            "|    reward             | 3.3084078 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 40.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 1009       |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -262       |\n",
            "|    reward             | -11.807244 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 610        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 1016        |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 34          |\n",
            "|    reward             | -0.33238956 |\n",
            "|    std                | 1.31        |\n",
            "|    value_loss         | 7.18        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 1023      |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 30.5      |\n",
            "|    reward             | 1.5437198 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 7.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 1030       |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 26.7       |\n",
            "|    reward             | 0.98816395 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 2.6        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 1036      |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | -4.62     |\n",
            "|    reward             | 0.4156059 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 0.383     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15800      |\n",
            "|    time_elapsed       | 1044       |\n",
            "|    total_timesteps    | 79000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15799      |\n",
            "|    policy_loss        | -52.1      |\n",
            "|    reward             | 0.48175147 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 11.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 1051      |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 64.4      |\n",
            "|    reward             | 0.9567955 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 36.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16000     |\n",
            "|    time_elapsed       | 1058      |\n",
            "|    total_timesteps    | 80000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15999     |\n",
            "|    policy_loss        | 0.925     |\n",
            "|    reward             | -1.654354 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 2.87      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 1065      |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 26.4      |\n",
            "|    reward             | 1.3760337 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 4.15      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 16200        |\n",
            "|    time_elapsed       | 1072         |\n",
            "|    total_timesteps    | 81000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 16199        |\n",
            "|    policy_loss        | -30.6        |\n",
            "|    reward             | -0.041509453 |\n",
            "|    std                | 1.3          |\n",
            "|    value_loss         | 5.14         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16300     |\n",
            "|    time_elapsed       | 1079      |\n",
            "|    total_timesteps    | 81500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16299     |\n",
            "|    policy_loss        | -33.8     |\n",
            "|    reward             | -0.255074 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 5.52      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 16400      |\n",
            "|    time_elapsed       | 1086       |\n",
            "|    total_timesteps    | 82000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16399      |\n",
            "|    policy_loss        | 4.48       |\n",
            "|    reward             | 0.60632455 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 3.11       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1092       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | -10.1      |\n",
            "|    reward             | -2.3904588 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 3.64       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1099      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 5.39      |\n",
            "|    reward             | 0.7025749 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 0.266     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1106      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -39.9     |\n",
            "|    reward             | 0.8959386 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 6.97      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 16800       |\n",
            "|    time_elapsed       | 1112        |\n",
            "|    total_timesteps    | 84000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16799       |\n",
            "|    policy_loss        | -0.0942     |\n",
            "|    reward             | 0.033515535 |\n",
            "|    std                | 1.31        |\n",
            "|    value_loss         | 1.5         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1119      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | 17.6      |\n",
            "|    reward             | 1.4564531 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 2.77      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1125       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -30.3      |\n",
            "|    reward             | -2.0076416 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 4.45       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 17100    |\n",
            "|    time_elapsed       | 1132     |\n",
            "|    total_timesteps    | 85500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.2    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17099    |\n",
            "|    policy_loss        | -166     |\n",
            "|    reward             | 2.112033 |\n",
            "|    std                | 1.32     |\n",
            "|    value_loss         | 120      |\n",
            "------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3699159.91\n",
            "total_reward: 2699159.91\n",
            "total_cost: 2319.65\n",
            "total_trades: 20284\n",
            "Sharpe: 0.666\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 1140        |\n",
            "|    total_timesteps    | 86000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | 0.768       |\n",
            "|    reward             | 0.019608336 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 0.0998      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17300      |\n",
            "|    time_elapsed       | 1149       |\n",
            "|    total_timesteps    | 86500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17299      |\n",
            "|    policy_loss        | -7.62      |\n",
            "|    reward             | 0.77060056 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 0.466      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 17400       |\n",
            "|    time_elapsed       | 1159        |\n",
            "|    total_timesteps    | 87000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17399       |\n",
            "|    policy_loss        | -32.3       |\n",
            "|    reward             | -0.77816486 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 6.75        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 17500    |\n",
            "|    time_elapsed       | 1167     |\n",
            "|    total_timesteps    | 87500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17499    |\n",
            "|    policy_loss        | 3.1      |\n",
            "|    reward             | 1.025098 |\n",
            "|    std                | 1.32     |\n",
            "|    value_loss         | 0.556    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 17600      |\n",
            "|    time_elapsed       | 1176       |\n",
            "|    total_timesteps    | 88000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17599      |\n",
            "|    policy_loss        | 97.6       |\n",
            "|    reward             | -1.7626301 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 40.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 1185      |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | 2.65      |\n",
            "|    reward             | 2.7397733 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 5.37      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1194       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 8.48       |\n",
            "|    reward             | 0.93649834 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.688      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1203       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -7         |\n",
            "|    reward             | -2.7993865 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.27       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 18000       |\n",
            "|    time_elapsed       | 1210        |\n",
            "|    total_timesteps    | 90000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17999       |\n",
            "|    policy_loss        | 7.78        |\n",
            "|    reward             | 0.083120786 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 1.19        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1216      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | 7.53      |\n",
            "|    reward             | 1.4048469 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 0.541     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 1223       |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | 52.5       |\n",
            "|    reward             | 0.15735304 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 15.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 1229       |\n",
            "|    total_timesteps    | 91500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -189       |\n",
            "|    reward             | -0.9610189 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 153        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18400      |\n",
            "|    time_elapsed       | 1236       |\n",
            "|    total_timesteps    | 92000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | -0.00594   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18399      |\n",
            "|    policy_loss        | 25.4       |\n",
            "|    reward             | 0.48147658 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 3.4        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18500      |\n",
            "|    time_elapsed       | 1242       |\n",
            "|    total_timesteps    | 92500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18499      |\n",
            "|    policy_loss        | -9.87      |\n",
            "|    reward             | -0.5430056 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 3.46       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18600      |\n",
            "|    time_elapsed       | 1249       |\n",
            "|    total_timesteps    | 93000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18599      |\n",
            "|    policy_loss        | 14.2       |\n",
            "|    reward             | 0.62194467 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 1.61       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1255      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -2.76     |\n",
            "|    reward             | 1.6892238 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 0.227     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18800      |\n",
            "|    time_elapsed       | 1262       |\n",
            "|    total_timesteps    | 94000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18799      |\n",
            "|    policy_loss        | 25         |\n",
            "|    reward             | -1.5170918 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 7.52       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1271       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 69.9       |\n",
            "|    reward             | -1.8819128 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 48.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1279      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.4     |\n",
            "|    explained_variance | -0.118    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | 0.105     |\n",
            "|    reward             | 1.1646295 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 0.847     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1286      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -82.8     |\n",
            "|    reward             | 0.6983247 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 27.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19200      |\n",
            "|    time_elapsed       | 1292       |\n",
            "|    total_timesteps    | 96000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19199      |\n",
            "|    policy_loss        | -3.35      |\n",
            "|    reward             | 0.14221503 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 1.8        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19300     |\n",
            "|    time_elapsed       | 1299      |\n",
            "|    total_timesteps    | 96500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19299     |\n",
            "|    policy_loss        | 17.6      |\n",
            "|    reward             | 0.5309412 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 2.07      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19400      |\n",
            "|    time_elapsed       | 1305       |\n",
            "|    total_timesteps    | 97000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.4      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19399      |\n",
            "|    policy_loss        | 98         |\n",
            "|    reward             | 0.35146558 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 58.3       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 19500       |\n",
            "|    time_elapsed       | 1312        |\n",
            "|    total_timesteps    | 97500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19499       |\n",
            "|    policy_loss        | -43.6       |\n",
            "|    reward             | -0.60376465 |\n",
            "|    std                | 1.35        |\n",
            "|    value_loss         | 9.76        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19600      |\n",
            "|    time_elapsed       | 1319       |\n",
            "|    total_timesteps    | 98000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19599      |\n",
            "|    policy_loss        | 27.8       |\n",
            "|    reward             | 0.46069837 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 10.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19700      |\n",
            "|    time_elapsed       | 1325       |\n",
            "|    total_timesteps    | 98500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19699      |\n",
            "|    policy_loss        | -29.5      |\n",
            "|    reward             | 0.22014448 |\n",
            "|    std                | 1.36       |\n",
            "|    value_loss         | 5.44       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 1331      |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -15.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | 14.4      |\n",
            "|    reward             | -8.134867 |\n",
            "|    std                | 1.36      |\n",
            "|    value_loss         | 2.32      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19900      |\n",
            "|    time_elapsed       | 1338       |\n",
            "|    total_timesteps    | 99500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -15.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19899      |\n",
            "|    policy_loss        | -65.7      |\n",
            "|    reward             | -4.0289216 |\n",
            "|    std                | 1.36       |\n",
            "|    value_loss         | 20         |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 20000    |\n",
            "|    time_elapsed       | 1345     |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -15.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19999    |\n",
            "|    policy_loss        | -48.7    |\n",
            "|    reward             | -9.44571 |\n",
            "|    std                | 1.36     |\n",
            "|    value_loss         | 38.9     |\n",
            "------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  9.993397e+05  9.905746e+05\n",
            "2021-10-05  1.000279e+06  9.996566e+05\n",
            "2021-10-06  1.000468e+06  1.002637e+06\n",
            "2021-10-07  1.002327e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  9.910390e+05  9.854252e+05\n",
            "2023-04-28  1.001134e+06  9.933491e+05\n",
            "2023-05-01  1.003372e+06  9.919956e+05\n",
            "2023-05-02  9.944668e+05  9.812993e+05\n",
            "2023-05-03  9.882666e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -1.17 %\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.148     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -17.3      |\n",
            "|    reward             | 0.17835833 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.45       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -9.25      |\n",
            "|    reward             | 0.65365165 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.38       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.0029    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -0.42      |\n",
            "|    reward             | -2.8279433 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.71       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -18.4      |\n",
            "|    reward             | 0.55964494 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.65       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -13.5      |\n",
            "|    reward             | -1.6807865 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.49       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 78           |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.9        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 1.16         |\n",
            "|    reward             | -0.047850378 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.0132       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -0.0786     |\n",
            "|    reward             | -0.44496915 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.132       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 77           |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.9        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 5.83         |\n",
            "|    reward             | -0.002448144 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.988        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 9.63      |\n",
            "|    reward             | 2.6546683 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.53      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 64       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 0.00373  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -81.8    |\n",
            "|    reward             | 3.134792 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 85.1     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 28.2      |\n",
            "|    reward             | 1.7921615 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 16.4      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 76          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -4.02       |\n",
            "|    reward             | -0.31310192 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.154       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 83         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -3.99      |\n",
            "|    reward             | 0.55065763 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.382      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 45.1      |\n",
            "|    reward             | 0.8451964 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 12.1      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 96       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 15.2     |\n",
            "|    reward             | 0.628908 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 3.51     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 77          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 103         |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -9.44       |\n",
            "|    reward             | 0.110440195 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 7.37        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.00305  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 156       |\n",
            "|    reward             | 10.191394 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 175       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 115       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -31.7     |\n",
            "|    reward             | 0.4674367 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 5.66      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 122        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.00871    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -35.1      |\n",
            "|    reward             | 0.21113789 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 10         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 128        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 8.34       |\n",
            "|    reward             | -0.6039442 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.65       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 134       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.00477   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -19.4     |\n",
            "|    reward             | 2.9252992 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 5.36      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 140        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 26.2       |\n",
            "|    reward             | 0.72922665 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 9.64       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 91.1      |\n",
            "|    reward             | 1.3821725 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 43.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 153        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.00389    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 24.1       |\n",
            "|    reward             | 0.51452446 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 4          |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 159       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -1.56     |\n",
            "|    reward             | 0.4437944 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.381     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 166       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 6.61      |\n",
            "|    reward             | 0.8220122 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.27      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 172        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -17        |\n",
            "|    reward             | -3.3723636 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.11       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 179       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -19.4     |\n",
            "|    reward             | 0.9047835 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2.78      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 185      |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 9.39     |\n",
            "|    reward             | -0.79612 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 2.21     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 191         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 5.23        |\n",
            "|    reward             | -0.66088676 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.32        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 197         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -0.00772    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | -22.3       |\n",
            "|    reward             | -0.18359677 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 6.06        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 203       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 77.4      |\n",
            "|    reward             | 3.6777368 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 49.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 209        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 18.6       |\n",
            "|    reward             | -0.2551886 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.43       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 216        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | -97.7      |\n",
            "|    reward             | -1.4922369 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 84.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 222        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | 109        |\n",
            "|    reward             | -2.4677448 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 75.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 228        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | 2.06       |\n",
            "|    reward             | 0.25871524 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.157      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 78          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 234         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -6.11       |\n",
            "|    reward             | -0.11128267 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 1.46        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 240        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -18.8      |\n",
            "|    reward             | 0.68819636 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 9.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 246        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | -2.7       |\n",
            "|    reward             | 0.51707107 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.755      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 253        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -97.9      |\n",
            "|    reward             | -3.7948813 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 64.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 259        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 2.64       |\n",
            "|    reward             | -1.7098079 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.09       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 266       |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.00649  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 3.7       |\n",
            "|    reward             | -1.351443 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.695     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 272        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | 34.6       |\n",
            "|    reward             | 0.16361433 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 7.87       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 280        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -15.1      |\n",
            "|    reward             | -4.9420505 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.72       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 287       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 18.6      |\n",
            "|    reward             | 1.9311651 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2.56      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 293        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 47.3       |\n",
            "|    reward             | -1.1085228 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 23.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 300        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 15.2       |\n",
            "|    reward             | -5.4862313 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.72       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 308        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -2.17      |\n",
            "|    reward             | -0.3766184 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.494      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 316       |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | -8.34     |\n",
            "|    reward             | 0.7230292 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 322       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -81.4     |\n",
            "|    reward             | 1.1364601 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 47.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 332       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 27.5      |\n",
            "|    reward             | 0.6966848 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 5.75      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 341        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -101       |\n",
            "|    reward             | -0.7544602 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 97.6       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 350        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 121        |\n",
            "|    reward             | -2.2487419 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 89.1       |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4865416.15\n",
            "total_reward: 3865416.15\n",
            "total_cost: 4694.76\n",
            "total_trades: 16352\n",
            "Sharpe: 0.938\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 360        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -34.1      |\n",
            "|    reward             | -1.0090861 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 6.47       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 368         |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0.00841     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | 35.3        |\n",
            "|    reward             | -0.07310295 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 7.2         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 375       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0.00144   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -8.73     |\n",
            "|    reward             | 1.3201561 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 9.31      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 382        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | 19.3       |\n",
            "|    reward             | 0.29544935 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 5.22       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 388      |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | 55.8     |\n",
            "|    reward             | 1.190103 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 30.2     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 395         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -21.1       |\n",
            "|    reward             | -0.29723716 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 7.58        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 401        |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | -46.4      |\n",
            "|    reward             | 0.74340713 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 14.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 408        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 11.4       |\n",
            "|    reward             | 0.45115253 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.68       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 414        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -59.8      |\n",
            "|    reward             | -2.7108145 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 44.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 421        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | -0.732     |\n",
            "|    reward             | 0.43160573 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 427      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 48.2     |\n",
            "|    reward             | 4.243213 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 23.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 434       |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | -33.1     |\n",
            "|    reward             | 1.3060828 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 6.89      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 6600     |\n",
            "|    time_elapsed       | 442      |\n",
            "|    total_timesteps    | 33000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6599     |\n",
            "|    policy_loss        | -40.1    |\n",
            "|    reward             | -2.14988 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 10.6     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 449       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -4.41     |\n",
            "|    reward             | 2.1400647 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.247     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 455        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 41         |\n",
            "|    reward             | -2.8358533 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 12.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 462        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -29.8      |\n",
            "|    reward             | -1.4136045 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 6.07       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 468       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -17.3     |\n",
            "|    reward             | 2.2441366 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.23      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 474        |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -2.76      |\n",
            "|    reward             | 0.03861217 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0439     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 481         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 14.9        |\n",
            "|    reward             | -0.77290493 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 1.37        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 487         |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | -2.41       |\n",
            "|    reward             | -0.65200746 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.324       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 494       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0.171     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -58.5     |\n",
            "|    reward             | 2.3035362 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 25.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 500       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 3.32      |\n",
            "|    reward             | 2.5259256 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.209     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 507       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 15        |\n",
            "|    reward             | 5.3716917 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.72      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 513         |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 0.936       |\n",
            "|    reward             | 0.008950207 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.00556     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 520         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | 18.7        |\n",
            "|    reward             | -0.79180753 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 2.78        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 7900       |\n",
            "|    time_elapsed       | 527        |\n",
            "|    total_timesteps    | 39500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7899       |\n",
            "|    policy_loss        | -47.3      |\n",
            "|    reward             | 0.47786552 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 17.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 533       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | -31.4     |\n",
            "|    reward             | -0.361529 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 5.36      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 541       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -109      |\n",
            "|    reward             | 5.3837843 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 63.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 547       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -380      |\n",
            "|    reward             | -13.454   |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 950       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 8300        |\n",
            "|    time_elapsed       | 554         |\n",
            "|    total_timesteps    | 41500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8299        |\n",
            "|    policy_loss        | -8.25       |\n",
            "|    reward             | -0.36566442 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.665       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 561       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | -21.8     |\n",
            "|    reward             | 0.2808855 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 4         |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 567       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -3.77     |\n",
            "|    reward             | 1.7743202 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.12      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 574       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | -6.13     |\n",
            "|    reward             | 2.0659664 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 2.68      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 580       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -56.5     |\n",
            "|    reward             | 1.9044526 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 23.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 587        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 136        |\n",
            "|    reward             | -1.1592999 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 105        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 593       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 26.4      |\n",
            "|    reward             | 1.3368783 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 4.37      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 600        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 22         |\n",
            "|    reward             | 0.15289262 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 3.66       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 606       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | -11       |\n",
            "|    reward             | 0.3271814 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.83      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 613       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 66.8      |\n",
            "|    reward             | 0.4996196 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 22.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 619       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 29.8      |\n",
            "|    reward             | 3.0424955 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.15      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 626       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 56.1      |\n",
            "|    reward             | 2.4077864 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 45.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 633        |\n",
            "|    total_timesteps    | 47500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | 11.6       |\n",
            "|    reward             | 0.09068316 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.52       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 640        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 0.932      |\n",
            "|    reward             | -1.2759455 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.591      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 9700      |\n",
            "|    time_elapsed       | 646       |\n",
            "|    total_timesteps    | 48500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9699      |\n",
            "|    policy_loss        | 1.98      |\n",
            "|    reward             | -1.631402 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.761     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 653        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -89.5      |\n",
            "|    reward             | -0.5957554 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 50.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 659       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | -28.1     |\n",
            "|    reward             | 1.0325257 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 5.42      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 665        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | 19.4       |\n",
            "|    reward             | -6.7544637 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 6.78       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 10100    |\n",
            "|    time_elapsed       | 672      |\n",
            "|    total_timesteps    | 50500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.4    |\n",
            "|    explained_variance | 0.0014   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10099    |\n",
            "|    policy_loss        | 5.49     |\n",
            "|    reward             | 1.392214 |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.875    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 679       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 22.6      |\n",
            "|    reward             | 1.4003271 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.39      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 685       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | 2.29      |\n",
            "|    reward             | 1.1391785 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.106     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 692         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 82.8        |\n",
            "|    reward             | 0.075981796 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 50.6        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 698       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 82.5      |\n",
            "|    reward             | -6.007247 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 54.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 705         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | -197        |\n",
            "|    reward             | -0.86156356 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 286         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 711       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.4     |\n",
            "|    explained_variance | 0.0012    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | 8.74      |\n",
            "|    reward             | 0.4551893 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.499     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 10800      |\n",
            "|    time_elapsed       | 717        |\n",
            "|    total_timesteps    | 54000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10799      |\n",
            "|    policy_loss        | 15.4       |\n",
            "|    reward             | -0.5346719 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.35       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 725        |\n",
            "|    total_timesteps    | 54500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | -3.86      |\n",
            "|    reward             | -1.4344094 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 2.76       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 731        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -7.58      |\n",
            "|    reward             | 0.39848432 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.437      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 11100      |\n",
            "|    time_elapsed       | 738        |\n",
            "|    total_timesteps    | 55500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11099      |\n",
            "|    policy_loss        | 117        |\n",
            "|    reward             | -0.5378518 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 95.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 11200      |\n",
            "|    time_elapsed       | 744        |\n",
            "|    total_timesteps    | 56000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11199      |\n",
            "|    policy_loss        | -10.5      |\n",
            "|    reward             | -4.2980466 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 4.2        |\n",
            "--------------------------------------\n",
            "day: 2956, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4453426.51\n",
            "total_reward: 3453426.51\n",
            "total_cost: 1926.12\n",
            "total_trades: 21098\n",
            "Sharpe: 0.813\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 11300       |\n",
            "|    time_elapsed       | 751         |\n",
            "|    total_timesteps    | 56500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.4       |\n",
            "|    explained_variance | 7.45e-06    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11299       |\n",
            "|    policy_loss        | 17.7        |\n",
            "|    reward             | -0.29626203 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 1.87        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 758       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 8.4       |\n",
            "|    reward             | 0.5552362 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.7       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 764       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 15.4      |\n",
            "|    reward             | 2.7236836 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.7       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 11600       |\n",
            "|    time_elapsed       | 771         |\n",
            "|    total_timesteps    | 58000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11599       |\n",
            "|    policy_loss        | 1.95        |\n",
            "|    reward             | -0.06929372 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.501       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 11700       |\n",
            "|    time_elapsed       | 777         |\n",
            "|    total_timesteps    | 58500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11699       |\n",
            "|    policy_loss        | 33.9        |\n",
            "|    reward             | -0.26536673 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 11.3        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 784       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | -29.3     |\n",
            "|    reward             | 3.5981824 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 34.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 11900      |\n",
            "|    time_elapsed       | 790        |\n",
            "|    total_timesteps    | 59500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11899      |\n",
            "|    policy_loss        | -25.1      |\n",
            "|    reward             | -0.3710058 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 4.31       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 12000      |\n",
            "|    time_elapsed       | 797        |\n",
            "|    total_timesteps    | 60000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 11999      |\n",
            "|    policy_loss        | -17.9      |\n",
            "|    reward             | -2.4172251 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 2.74       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 803       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -7        |\n",
            "|    reward             | 0.4572472 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.365     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 810        |\n",
            "|    total_timesteps    | 61000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | -65.6      |\n",
            "|    reward             | 0.31697387 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 22.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 817       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | -54.8     |\n",
            "|    reward             | 2.5798378 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 23.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 823       |\n",
            "|    total_timesteps    | 62000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | 59.9      |\n",
            "|    reward             | 6.1602807 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 21.3      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 12500    |\n",
            "|    time_elapsed       | 830      |\n",
            "|    total_timesteps    | 62500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.5    |\n",
            "|    explained_variance | 0.115    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12499    |\n",
            "|    policy_loss        | -82.6    |\n",
            "|    reward             | 5.068011 |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 35.3     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 836        |\n",
            "|    total_timesteps    | 63000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | -13.9      |\n",
            "|    reward             | -0.9394108 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.5        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 12700       |\n",
            "|    time_elapsed       | 843         |\n",
            "|    total_timesteps    | 63500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12699       |\n",
            "|    policy_loss        | -57.4       |\n",
            "|    reward             | -0.35280785 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 18.7        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 12800       |\n",
            "|    time_elapsed       | 849         |\n",
            "|    total_timesteps    | 64000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12799       |\n",
            "|    policy_loss        | 20.6        |\n",
            "|    reward             | -0.14532632 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 2.7         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 856       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | 8.65      |\n",
            "|    reward             | 2.3120215 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 2.74      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 13000      |\n",
            "|    time_elapsed       | 862        |\n",
            "|    total_timesteps    | 65000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12999      |\n",
            "|    policy_loss        | 29.6       |\n",
            "|    reward             | -4.5739636 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 7.68       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 13100    |\n",
            "|    time_elapsed       | 869      |\n",
            "|    total_timesteps    | 65500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13099    |\n",
            "|    policy_loss        | -74.9    |\n",
            "|    reward             | 3.93786  |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 47       |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 875        |\n",
            "|    total_timesteps    | 66000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | -17.6      |\n",
            "|    reward             | -1.8518786 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 2.3        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 882       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | -56.9     |\n",
            "|    reward             | 1.0482538 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 21.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 13400       |\n",
            "|    time_elapsed       | 888         |\n",
            "|    total_timesteps    | 67000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13399       |\n",
            "|    policy_loss        | -6.71       |\n",
            "|    reward             | -0.15165272 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.341       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 13500      |\n",
            "|    time_elapsed       | 894        |\n",
            "|    total_timesteps    | 67500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -0.0106    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13499      |\n",
            "|    policy_loss        | -6.96      |\n",
            "|    reward             | 0.14547814 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.1        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 13600       |\n",
            "|    time_elapsed       | 901         |\n",
            "|    total_timesteps    | 68000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13599       |\n",
            "|    policy_loss        | -37.6       |\n",
            "|    reward             | -0.21959102 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 8.97        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 13700    |\n",
            "|    time_elapsed       | 907      |\n",
            "|    total_timesteps    | 68500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13699    |\n",
            "|    policy_loss        | 42.1     |\n",
            "|    reward             | 2.12279  |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 19.8     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 13800    |\n",
            "|    time_elapsed       | 914      |\n",
            "|    total_timesteps    | 69000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13799    |\n",
            "|    policy_loss        | -5.63    |\n",
            "|    reward             | 1.714163 |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.26     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 13900    |\n",
            "|    time_elapsed       | 920      |\n",
            "|    total_timesteps    | 69500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13899    |\n",
            "|    policy_loss        | 19.2     |\n",
            "|    reward             | -2.62371 |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 3.09     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 927         |\n",
            "|    total_timesteps    | 70000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | 0.243       |\n",
            "|    reward             | -0.36102247 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 1.14        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 14100       |\n",
            "|    time_elapsed       | 933         |\n",
            "|    total_timesteps    | 70500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0.022       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14099       |\n",
            "|    policy_loss        | -5.54       |\n",
            "|    reward             | -0.18522067 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.536       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14200      |\n",
            "|    time_elapsed       | 941        |\n",
            "|    total_timesteps    | 71000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14199      |\n",
            "|    policy_loss        | 8.05       |\n",
            "|    reward             | 0.13690664 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.506      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14300      |\n",
            "|    time_elapsed       | 947        |\n",
            "|    total_timesteps    | 71500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -0.348     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14299      |\n",
            "|    policy_loss        | 23.5       |\n",
            "|    reward             | 0.98072356 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 4.24       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 14400       |\n",
            "|    time_elapsed       | 954         |\n",
            "|    total_timesteps    | 72000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14399       |\n",
            "|    policy_loss        | -71.5       |\n",
            "|    reward             | -0.07804944 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 26.8        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14500      |\n",
            "|    time_elapsed       | 960        |\n",
            "|    total_timesteps    | 72500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14499      |\n",
            "|    policy_loss        | 12         |\n",
            "|    reward             | 0.32799113 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 3.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14600      |\n",
            "|    time_elapsed       | 969        |\n",
            "|    total_timesteps    | 73000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14599      |\n",
            "|    policy_loss        | 54.8       |\n",
            "|    reward             | -2.2028806 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 19.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 975        |\n",
            "|    total_timesteps    | 73500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 26.8       |\n",
            "|    reward             | -5.3721743 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 4.89       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 982        |\n",
            "|    total_timesteps    | 74000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -3.85      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | -0.809     |\n",
            "|    reward             | 0.65317327 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.788      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 14900       |\n",
            "|    time_elapsed       | 990         |\n",
            "|    total_timesteps    | 74500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14899       |\n",
            "|    policy_loss        | -40.3       |\n",
            "|    reward             | -0.44423518 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 9.6         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15000     |\n",
            "|    time_elapsed       | 997       |\n",
            "|    total_timesteps    | 75000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14999     |\n",
            "|    policy_loss        | -18.4     |\n",
            "|    reward             | -1.829605 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 3.85      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15100     |\n",
            "|    time_elapsed       | 1004      |\n",
            "|    total_timesteps    | 75500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15099     |\n",
            "|    policy_loss        | 15.1      |\n",
            "|    reward             | -2.150047 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.17      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 1010      |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -0.0592   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | -2.14     |\n",
            "|    reward             | 3.5862842 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 22        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 1017       |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -221       |\n",
            "|    reward             | -10.189993 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 412        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 1024        |\n",
            "|    total_timesteps    | 77000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | 27.4        |\n",
            "|    reward             | -0.31053022 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 6.97        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 15500    |\n",
            "|    time_elapsed       | 1031     |\n",
            "|    total_timesteps    | 77500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15499    |\n",
            "|    policy_loss        | 30.3     |\n",
            "|    reward             | 1.384501 |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 7.59     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15600     |\n",
            "|    time_elapsed       | 1037      |\n",
            "|    total_timesteps    | 78000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15599     |\n",
            "|    policy_loss        | 20.9      |\n",
            "|    reward             | 0.7176497 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 3.1       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 15700      |\n",
            "|    time_elapsed       | 1044       |\n",
            "|    total_timesteps    | 78500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15699      |\n",
            "|    policy_loss        | 1.35       |\n",
            "|    reward             | 0.51001257 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.352      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 1050      |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -22.5     |\n",
            "|    reward             | 1.1986238 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 4.25      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 1057      |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 60.8      |\n",
            "|    reward             | 1.4585453 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 51.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 1063       |\n",
            "|    total_timesteps    | 80000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | -0.413     |\n",
            "|    reward             | -1.7496392 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 2.72       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 1070      |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 16.3      |\n",
            "|    reward             | 1.1171426 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 2.76      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 1077      |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -34.1     |\n",
            "|    reward             | 0.7201815 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 7.28      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 16300       |\n",
            "|    time_elapsed       | 1084        |\n",
            "|    total_timesteps    | 81500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16299       |\n",
            "|    policy_loss        | -31.2       |\n",
            "|    reward             | -0.26345733 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 5.57        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 1093      |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | -3.04     |\n",
            "|    reward             | 0.8196118 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 2.58      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 1099       |\n",
            "|    total_timesteps    | 82500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | -13        |\n",
            "|    reward             | -1.7427164 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 6.34       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 1106      |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 5.01      |\n",
            "|    reward             | 0.6675537 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.259     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 1113      |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -39.9     |\n",
            "|    reward             | 0.7396375 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 8.91      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 16800      |\n",
            "|    time_elapsed       | 1120       |\n",
            "|    total_timesteps    | 84000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16799      |\n",
            "|    policy_loss        | 6.94       |\n",
            "|    reward             | -0.4554804 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 2.18       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 1126      |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | 10.6      |\n",
            "|    reward             | 1.1922157 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 1.99      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17000      |\n",
            "|    time_elapsed       | 1132       |\n",
            "|    total_timesteps    | 85000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16999      |\n",
            "|    policy_loss        | -6.99      |\n",
            "|    reward             | -3.1591902 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.812      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 1139      |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -129      |\n",
            "|    reward             | 2.6539097 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 122       |\n",
            "-------------------------------------\n",
            "day: 2956, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4427554.51\n",
            "total_reward: 3427554.51\n",
            "total_cost: 1116.83\n",
            "total_trades: 18094\n",
            "Sharpe: 0.796\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 17200        |\n",
            "|    time_elapsed       | 1146         |\n",
            "|    total_timesteps    | 86000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.7        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17199        |\n",
            "|    policy_loss        | -0.238       |\n",
            "|    reward             | -0.119771995 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 0.0985       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17300      |\n",
            "|    time_elapsed       | 1152       |\n",
            "|    total_timesteps    | 86500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17299      |\n",
            "|    policy_loss        | -9.13      |\n",
            "|    reward             | 0.63992286 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.607      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17400      |\n",
            "|    time_elapsed       | 1159       |\n",
            "|    total_timesteps    | 87000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17399      |\n",
            "|    policy_loss        | -33        |\n",
            "|    reward             | -1.2483675 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 8.77       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 17500    |\n",
            "|    time_elapsed       | 1166     |\n",
            "|    total_timesteps    | 87500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17499    |\n",
            "|    policy_loss        | -8.78    |\n",
            "|    reward             | 0.921597 |\n",
            "|    std                | 1.13     |\n",
            "|    value_loss         | 0.884    |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 17600       |\n",
            "|    time_elapsed       | 1172        |\n",
            "|    total_timesteps    | 88000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 17599       |\n",
            "|    policy_loss        | 131         |\n",
            "|    reward             | -0.90752035 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 70.1        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 17700    |\n",
            "|    time_elapsed       | 1179     |\n",
            "|    total_timesteps    | 88500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17699    |\n",
            "|    policy_loss        | 13       |\n",
            "|    reward             | 2.806864 |\n",
            "|    std                | 1.13     |\n",
            "|    value_loss         | 6.6      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17800      |\n",
            "|    time_elapsed       | 1186       |\n",
            "|    total_timesteps    | 89000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17799      |\n",
            "|    policy_loss        | 9.81       |\n",
            "|    reward             | 0.97956467 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.823      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 17900      |\n",
            "|    time_elapsed       | 1192       |\n",
            "|    total_timesteps    | 89500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17899      |\n",
            "|    policy_loss        | -4.44      |\n",
            "|    reward             | -2.8474073 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.144      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 1198       |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | 7.25       |\n",
            "|    reward             | 0.24080354 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.995      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 1205      |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | -7.57     |\n",
            "|    reward             | 1.0263813 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.365     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 18200       |\n",
            "|    time_elapsed       | 1212        |\n",
            "|    total_timesteps    | 91000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18199       |\n",
            "|    policy_loss        | 28.3        |\n",
            "|    reward             | -0.39990723 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 11.8        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 18300       |\n",
            "|    time_elapsed       | 1218        |\n",
            "|    total_timesteps    | 91500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18299       |\n",
            "|    policy_loss        | -185        |\n",
            "|    reward             | -0.34050182 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 169         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 1225      |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | 22.1      |\n",
            "|    reward             | 0.5670685 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 4.39      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18500      |\n",
            "|    time_elapsed       | 1234       |\n",
            "|    total_timesteps    | 92500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | -0.0339    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18499      |\n",
            "|    policy_loss        | -20.8      |\n",
            "|    reward             | -0.6370385 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 6.64       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 1243      |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | 12.2      |\n",
            "|    reward             | 0.6000591 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 1.44      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 1249      |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | -8.97     |\n",
            "|    reward             | 1.9178764 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.629     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 18800        |\n",
            "|    time_elapsed       | 1256         |\n",
            "|    total_timesteps    | 94000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.8        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 18799        |\n",
            "|    policy_loss        | 49.7         |\n",
            "|    reward             | -0.017805155 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 19.1         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 1262       |\n",
            "|    total_timesteps    | 94500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 9.54e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | 42.1       |\n",
            "|    reward             | -1.5560933 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 20.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 1270      |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | 7.33      |\n",
            "|    reward             | 1.3479965 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 1.51      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 1276      |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -71.6     |\n",
            "|    reward             | 0.7374248 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 25.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19200      |\n",
            "|    time_elapsed       | 1282       |\n",
            "|    total_timesteps    | 96000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19199      |\n",
            "|    policy_loss        | -4.3       |\n",
            "|    reward             | 0.48632985 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 1.23       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 19300      |\n",
            "|    time_elapsed       | 1289       |\n",
            "|    total_timesteps    | 96500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19299      |\n",
            "|    policy_loss        | -15.4      |\n",
            "|    reward             | 0.77520114 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 1.71       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 1295      |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 87.7      |\n",
            "|    reward             | 2.0837374 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 45.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 1302      |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | 28.1      |\n",
            "|    reward             | 2.1795113 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 4.76      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 1308      |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -0.388    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 21.7      |\n",
            "|    reward             | 0.6980586 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 7.77      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19700     |\n",
            "|    time_elapsed       | 1316      |\n",
            "|    total_timesteps    | 98500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19699     |\n",
            "|    policy_loss        | -29.5     |\n",
            "|    reward             | 0.4637024 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 5.34      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 1323      |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | 12.7      |\n",
            "|    reward             | -7.061779 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 2.06      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 19900     |\n",
            "|    time_elapsed       | 1330      |\n",
            "|    total_timesteps    | 99500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -1.29e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19899     |\n",
            "|    policy_loss        | -56.2     |\n",
            "|    reward             | -3.830493 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 21.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 20000     |\n",
            "|    time_elapsed       | 1336      |\n",
            "|    total_timesteps    | 100000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.8     |\n",
            "|    explained_variance | -0.021    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19999     |\n",
            "|    policy_loss        | -37.9     |\n",
            "|    reward             | -9.756426 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 38        |\n",
            "-------------------------------------\n",
            "hit end!\n",
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (400, 8)\n",
            "Annual return         -0.022145\n",
            "Cumulative returns    -0.034921\n",
            "Annual volatility      0.176822\n",
            "Sharpe ratio          -0.038668\n",
            "Calmar ratio          -0.100930\n",
            "Stability              0.215672\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            0.993578\n",
            "Sortino ratio         -0.053987\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.003436\n",
            "Daily value at risk   -0.022305\n",
            "dtype: float64\n",
            "result:                       a2c           dji\n",
            "date                                  \n",
            "2021-10-01  1.000000e+06  1.000000e+06\n",
            "2021-10-04  1.000009e+06  9.905746e+05\n",
            "2021-10-05  1.000215e+06  9.996566e+05\n",
            "2021-10-06  1.000570e+06  1.002637e+06\n",
            "2021-10-07  1.000685e+06  1.012483e+06\n",
            "...                  ...           ...\n",
            "2023-04-27  8.251508e+05  9.854252e+05\n",
            "2023-04-28  8.276208e+05  9.933491e+05\n",
            "2023-05-01  8.203070e+05  9.919956e+05\n",
            "2023-05-02  8.208110e+05  9.812993e+05\n",
            "2023-05-03  8.146760e+05  9.734251e+05\n",
            "\n",
            "[399 rows x 2 columns]\n",
            "A2C로 얻은 투자 수익률>> -18.53 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  stats = pd.Series()\n"
          ]
        }
      ],
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}\n",
        "\n",
        "\n",
        "Earn_list =[]\n",
        "\n",
        "for i in range(10):\n",
        "  e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
        "\n",
        "  env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "\n",
        "\n",
        "  if_using_a2c = True ##a2c만 사용해보자\n",
        "\n",
        "  agent = DRLAgent(env = env_train)\n",
        "  model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "  if if_using_a2c:\n",
        "    # set up logger\n",
        "    tmp_path = RESULTS_DIR + '/a2c'\n",
        "    new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "    # Set new logger\n",
        "    model_a2c.set_logger(new_logger_a2c)\n",
        "    \n",
        "  trained_a2c = agent.train_model(model=model_a2c, \n",
        "                              tb_log_name='a2c',\n",
        "                              total_timesteps=100000) if if_using_a2c else None\n",
        "\n",
        "  data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
        "  insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
        "\n",
        "  e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
        "  # env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "  trained_model = trained_a2c\n",
        "  df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
        "      model=trained_model, \n",
        "      environment = e_trade_gym)\n",
        "\n",
        "  df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
        "  df_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n",
        "  #baseline stats\n",
        "  print(\"==============Get Baseline Stats===========\")\n",
        "  df_dji_ = get_baseline(\n",
        "          ticker=\"^DJI\", \n",
        "          start = TRADE_START_DATE,\n",
        "          end = TRADE_END_DATE)\n",
        "  stats = backtest_stats(df_dji_, value_col_name = 'close')\n",
        "  df_dji = pd.DataFrame()\n",
        "  df_dji['date'] = df_account_value_a2c['date']\n",
        "  df_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "  df_dji.to_csv(\"df_dji.csv\")\n",
        "  df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "  df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "  result = pd.DataFrame(df_result_a2c)\n",
        "\n",
        "\n",
        "  result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "  result.columns = ['a2c','dji']\n",
        "\n",
        "  print(\"result: \", result)\n",
        "  result.to_csv(\"result.csv\")\n",
        "\n",
        "\n",
        "  print('A2C로 얻은 투자 수익률>>', round((df_result_a2c.iloc[-1,0]/df_result_a2c.iloc[0,0]-1)*100,2),'%')\n",
        "  Earn = round((df_result_a2c.iloc[-1,0]/df_result_a2c.iloc[0,0]-1)*100,2)\n",
        "  \n",
        "  Earn_list.append(Earn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "poU5GsZkclIn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "평균 수익률>> -7.15 %\n",
            "표준편차>> 6.95 %\n"
          ]
        }
      ],
      "source": [
        "print('평균 수익률>>', round(np.mean(Earn_list),2),'%')\n",
        "print('표준편차>>', round(np.std(Earn_list),2),'%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>수익률</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-13.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-13.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-6.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-11.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-18.53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     수익률\n",
              "0 -13.42\n",
              "1   0.10\n",
              "2   4.20\n",
              "3  -8.26\n",
              "4  -1.83\n",
              "5 -13.84\n",
              "6  -6.77\n",
              "7 -11.94\n",
              "8  -1.17\n",
              "9 -18.53"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(Earn_list, columns=['수익률'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.791000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.341687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-18.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-4.415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.345000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>35.820000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0\n",
              "count  10.000000\n",
              "mean    3.791000\n",
              "std    17.341687\n",
              "min   -18.600000\n",
              "25%    -4.415000\n",
              "50%     1.500000\n",
              "75%     9.345000\n",
              "max    35.820000"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv('Earn_list.csv').drop('Unnamed: 0',axis=1).describe()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPnZnB1zLmn9CbiX7aDoIq8",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
