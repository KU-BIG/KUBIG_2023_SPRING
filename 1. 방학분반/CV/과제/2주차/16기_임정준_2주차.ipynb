{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 과제\n",
        "## 1. 기본 코드(cifar10 dataset) 돌리면서 코드 파악\n",
        "\n",
        "## 2. 원하는 dataset 선택\n",
        "- dataset에 따른 imgsize & class 개수 등 조절 필요\n",
        "\n",
        "## 3. Parameter 바꿔가면서 성능 변화 확인하기\n",
        "  - image 크기(resize)\n",
        "  - learning rate\n",
        "  - optimizer\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "학습시간이 너무 오래 걸리면 epoch수를 줄이고, 다양한 시도를 해보면 좋을 것!!\n",
        "\n",
        "참고 데이터셋\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
        "- 그 외 원하는 이미지 데이터셋 자유롭게 사용 가능"
      ],
      "metadata": {
        "id": "JYWuOh6tva5L"
      }
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "G14yjsROmGxn"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tensorflow\n",
        "device_name = tensorflow.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "bFHrnvzLjgfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cc2586-d68a-481e-fc6c-32f631d44eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "47uahMnwmGxo"
      },
      "cell_type": "markdown",
      "source": [
        "## ResNet 구현\n",
        "### 1. identity block을 생성하는 함수인 identity_block() 생성. \n",
        "* input_tensor : 입력 tensor\n",
        "\n",
        "* kernel_size : kernel 크기\n",
        "  - identity block 내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임 (3x3 커널이 아니라 5x5 kernel도 지정할 수 있게 구성)\n",
        "* filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음\n",
        "  * 첫번째 : 첫번째 1x1 filter 개수 (tensor의 channel 차원을 1/4로 축소)\n",
        "  * 두번째 : 3x3 filter 개수\n",
        "  * 세번째 : 마지막 1x1 filter 개수 (tensor의 차원 복구)\n",
        "* stage: identity block들을 구별하기 위해서 설정 & 동일한 filter수를 가지는 identity block들은 동일한 stage로 설정\n",
        "* block: 동일 stage내에서 identity block을 구별하기 위한 구분자 (a,b,c)\n",
        "\n",
        "![](https://raw.githubusercontent.com/chulminkw/CNN_PG/main/utils/images/residual_block_small.png)\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Pdxw4_nVmGxp"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import add, Add\n",
        "\n",
        "# identity block은 shortcut 단에 conv layer가 없는 block 영역\n",
        "def identity_block(input_tensor, middle_kernel_size, filters, stage, block):\n",
        "    '''\n",
        "    함수 입력 인자 설명\n",
        "    input_tensor : 입력 tensor\n",
        "\n",
        "    middle_kernel_size : 중간에 위치하는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. \n",
        "    (3x3 커널이 이외에도 5x5 kernel도 지정할 수 있게 구성)\n",
        "\n",
        "    filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, 세번째는 마지막 1x1 filter 개수\n",
        "\n",
        "    stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n",
        "\n",
        "    block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n",
        "    ''' \n",
        "    \n",
        "    # filters : filter 개수를 각각 filter1, filter2, filter3 list 형태로 할당. \n",
        "    # filter은 첫번째 1x1 filter 개수\n",
        "    # filter2는 3x3 filter 개수\n",
        "    # filter3는 마지막 1x1 filter 개수\n",
        "    filter1, filter2, filter3 = filters\n",
        "    \n",
        "    # conv layer와 Batch normalization layer각각에 고유한 이름을 부여하기 위해 설정\n",
        "    # 입력받은 stage와 block에 기반하여 이름 부여\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # 이전 layer에 입력 받은 input_tensor를 기반으로 첫번째 1x1 Conv->Batch Norm->Relu 수행. \n",
        "    # 첫번째 1x1 Conv에서 Channel Dimension Reduction(1/4) 수행\n",
        "    x = Conv2D(filters=filter1, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # 두번째 3x3 Conv->Batch Norm->ReLU 수행\n",
        "    # 3x3이 아닌 다른 kernel size도 구성 가능할 수 있도록 identity_block() 인자로 입력받은 middle_kernel_size를 이용\n",
        "    # Conv 수행 출력 사이즈가 변하지 않도록 padding='same'으로 설정\n",
        "    # filter 개수는 이전의 1x1 filter개수와 동일\n",
        "    x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n",
        "    x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # 마지막 1x1 Conv->Batch Norm 수행\n",
        "    # ReLU를 수행 X (input tensor 더한 이후에 ReLU 적용)\n",
        "    # filter 크기는 input_tensor channel 차원 개수로 복구\n",
        "    x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)\n",
        "    x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)\n",
        "\n",
        "    # Residual Block 수행 결과 & input_tensor를 합 (Skip Connection)\n",
        "    x = Add()([input_tensor, x])\n",
        "\n",
        "    # 최종 ReLU 적용\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mnPHdMIImGxq"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. 위에서 생성한 identity_block()을 호출하여 어떻게 identity block이 구성되어 있는지 확인"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "j-V8Yqy1mGxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4808b4b1-d87d-4f5c-dcd1-b6fff79f917f"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# input_tensor로 임의의 Feature Map size를 생성. \n",
        "input_tensor = Input(shape=(56, 56, 256), name='test_input')\n",
        "\n",
        "# input_tensor의 channel수는 256개\n",
        "# filters는 256의 1/4 filter수로 차원 축소후 다시 마지막 1x1 Conv에서 256으로 복원\n",
        "filters = [64, 64, 256]\n",
        "\n",
        "# 중간 Conv 커널 크기 : 3x3\n",
        "kernel_size = (3, 3)\n",
        "stage = 2\n",
        "block = 'a'\n",
        "\n",
        "# identity_block 호출 & layer들이 어떻게 구성되어 있는지 확인하기 위해서 model로 구성하고 summary()호출 \n",
        "output = identity_block(input_tensor, kernel_size, filters, stage, block)\n",
        "identity_layers = Model(inputs=input_tensor, outputs=output)\n",
        "identity_layers.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " test_input (InputLayer)        [(None, 56, 56, 256  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['test_input[0][0]']             \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 56, 56, 64)   0           ['bn2a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 56, 56, 64)   0           ['bn2a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 56, 56, 256)  0           ['test_input[0][0]',             \n",
            "                                                                  'bn2a_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 56, 56, 256)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 71,552\n",
            "Trainable params: 70,784\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DwwWqDhGmGxq"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. identity block을 연속으로 이어서 하나의 Stage 구성.\n",
        "* 아래는 input tensor의 크기가 feature map 생성시 절반으로 줄지 않음\n",
        "* input tensor의 크기가 절반으로 줄수 있도록 구성\n",
        "* 동일한 Stage 내에서 feature map의 크기는 그대로 & block내에서 filter 개수는 변화"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoavj1qVmGxr",
        "outputId": "b80c53dc-7475-48c3-9e17-d116d669433a"
      },
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(56, 56, 256), name='test_input')\n",
        "\n",
        "x = identity_block(input_tensor, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='a')\n",
        "x = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='b')\n",
        "\n",
        "output = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='c')\n",
        "\n",
        "identity_layers = Model(inputs=input_tensor, outputs=output)\n",
        "identity_layers.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " test_input (InputLayer)        [(None, 56, 56, 256  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['test_input[0][0]']             \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 56, 56, 64)   0           ['bn2a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 56, 56, 64)   0           ['bn2a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 56, 56, 256)  0           ['test_input[0][0]',             \n",
            "                                                                  'bn2a_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 56, 56, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " res2b_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " bn2b_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 56, 56, 64)   0           ['bn2b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " bn2b_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 56, 56, 64)   0           ['bn2b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " bn2b_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 56, 56, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'bn2b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 56, 56, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " res2c_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " bn2c_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 56, 56, 64)   0           ['bn2c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " bn2c_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 56, 56, 64)   0           ['bn2c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 56, 56, 256)  0           ['activation_8[0][0]',           \n",
            "                                                                  'bn2c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 56, 56, 256)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 214,656\n",
            "Trainable params: 212,352\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fBGZg0qFmGxr"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. 각 stage내의 첫번째 identity block에서 입력 feature map의 크기를 절반으로 줄이는 conv_block() 만들기\n",
        "* conv_block() 함수는 앞에서 구현한 identity_block()함수과 거의 유사\n",
        "* 입력 feature map의 크기를 절반으로 줄이고 shortcut 전달시 1x1 conv & stride 2 적용\n",
        "* 첫번째 Stage의 첫번째 block에서는 이미 입력 feature map이 max pool로 절반이 줄어있는 상태이므로 다시 줄이지 않음"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TKuxKe_TmGxs"
      },
      "cell_type": "code",
      "source": [
        "def conv_block(input_tensor, middle_kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    '''\n",
        "    함수 입력 인자 설명\n",
        "    input_tensor: 입력 tensor\n",
        "\n",
        "    middle_kernel_size: 중간에 위치하는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. \n",
        "                        3x3 커널 이외에도 5x5 kernel도 지정할 수 있게 구성. \n",
        "\n",
        "    filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, \n",
        "             세번째는 마지막 1x1 filter 개수\n",
        "\n",
        "    stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n",
        "\n",
        "    block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n",
        "\n",
        "    strides: 입력 feature map의 크기를 절반으로 줄이기 위해서 사용. Default는 2이지만, \n",
        "             첫번째 Stage의 첫번째 block에서는 이미 입력 feature map이 max pool로 절반이 줄어있는 상태이므로 다시 줄이지 않기 위해 1을 호출해야함 \n",
        "    ''' \n",
        "    \n",
        "    # filters : filter 개수를 각각 filter1, filter2, filter3 list 형태로 할당. \n",
        "    # filter은 첫번째 1x1 filter 개수\n",
        "    # filter2는 3x3 filter 개수\n",
        "    # filter3는 마지막 1x1 filter 개수\n",
        "    filter1, filter2, filter3 = filters\n",
        "\n",
        "    # conv layer와 Batch normalization layer각각에 고유한 이름을 부여하기 위해 설정. 입력받은 stage와 block에 기반하여 이름 부여\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # 이전 layer에 입력 받은 input_tensor를 기반으로 첫번째 1x1 Conv->Batch Norm->Relu 수행. \n",
        "    # 입력 feature map 사이즈를 1/2로 줄이기 위해 strides 입력  \n",
        "    x = Conv2D(filters=filter1, kernel_size=(1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)\n",
        "    \n",
        "    # Batch Norm 적용\n",
        "    # 입력 데이터는 batch 사이즈까지 포함하여 4차원 : (batch_size, height, width, channel depth)\n",
        "    # Batch Norm의 axis는 channel depth에 해당하는 axis index인 3을 입력 (무조건 channel이 마지막 차원의 값으로 입력된다고 가정)\n",
        "    x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)\n",
        "    # ReLU Activation 적용\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # 두번째 3x3 Conv->Batch Norm->ReLU 수행\n",
        "    # 3x3이 아닌 다른 kernel size도 구성 가능할 수 있도록 identity_block() 인자로 입력받은 middle_kernel_size를 이용. \n",
        "    # Conv 수행 출력 사이즈가 변하지 않도록 padding='same'으로 설정. filter 개수는 이전의 1x1 filter개수와 동일.  \n",
        "    x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n",
        "    x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # 마지막 1x1 Conv->Batch Norm 수행\n",
        "    # ReLU를 수행 X (input tensor 더한 이후에 ReLU 적용)\n",
        "    # filter 크기는 input_tensor channel 차원 개수로 복구\n",
        "    x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)\n",
        "    x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)\n",
        "    \n",
        "    # shortcut을 1x1 conv 수행, filter3가 입력 feature map의 filter 개수\n",
        "    shortcut = Conv2D(filter3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'1')(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(shortcut)\n",
        "    \n",
        "    # Residual Block 수행 결과 & 1x1 conv가 적용된 shortcut을 합 \n",
        "    x = add([x, shortcut])\n",
        "    \n",
        "    # 최종 ReLU 적용\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PePSmhJ9mGxs"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. conv_block()과 identity_block()을 호출하여 stage 구성."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0znd7clmGxs",
        "outputId": "65ae6af4-77d2-493e-a5a2-48719538881e"
      },
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(56, 56, 256), name='test_input')\n",
        "\n",
        "# conv_block() 호출 시 strides를 2로 설정하여 입력 feature map의 크기를 절반으로 줄임 / strides=1이면 크기를 그대로 유지\n",
        "x = conv_block(input_tensor, middle_kernel_size=3, filters=[64, 64, 256], strides=2, stage=2, block='a')\n",
        "x = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='b')\n",
        "\n",
        "output = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='c')\n",
        "\n",
        "identity_layers = Model(inputs=input_tensor, outputs=output)\n",
        "identity_layers.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " test_input (InputLayer)        [(None, 56, 56, 256  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)        (None, 28, 28, 64)   16448       ['test_input[0][0]']             \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormalizat  (None, 28, 28, 64)  256         ['res2a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 28, 28, 64)   0           ['bn2a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)        (None, 28, 28, 64)   36928       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormalizat  (None, 28, 28, 64)  256         ['res2a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 28, 28, 64)   0           ['bn2a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)        (None, 28, 28, 256)  16640       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch1 (Conv2D)         (None, 28, 28, 256)  65792       ['test_input[0][0]']             \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormalizat  (None, 28, 28, 256)  1024       ['res2a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn2a_branch1 (BatchNormalizati  (None, 28, 28, 256)  1024       ['res2a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 28, 28, 256)  0           ['bn2a_branch2c[0][0]',          \n",
            "                                                                  'bn2a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 28, 28, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " res2b_branch2a (Conv2D)        (None, 28, 28, 64)   16448       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2a (BatchNormalizat  (None, 28, 28, 64)  256         ['res2b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 28, 28, 64)   0           ['bn2b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2b (Conv2D)        (None, 28, 28, 64)   36928       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2b (BatchNormalizat  (None, 28, 28, 64)  256         ['res2b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 28, 28, 64)   0           ['bn2b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2c (Conv2D)        (None, 28, 28, 256)  16640       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2c (BatchNormalizat  (None, 28, 28, 256)  1024       ['res2b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 28, 28, 256)  0           ['activation_14[0][0]',          \n",
            "                                                                  'bn2b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 28, 28, 256)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " res2c_branch2a (Conv2D)        (None, 28, 28, 64)   16448       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2a (BatchNormalizat  (None, 28, 28, 64)  256         ['res2c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 28, 28, 64)   0           ['bn2c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2b (Conv2D)        (None, 28, 28, 64)   36928       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2b (BatchNormalizat  (None, 28, 28, 64)  256         ['res2c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 28, 28, 64)   0           ['bn2c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2c (Conv2D)        (None, 28, 28, 256)  16640       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2c (BatchNormalizat  (None, 28, 28, 256)  1024       ['res2c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 28, 28, 256)  0           ['activation_17[0][0]',          \n",
            "                                                                  'bn2c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 28, 28, 256)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 281,472\n",
            "Trainable params: 278,656\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HG40II7lmGxs"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. input image를 7x7 Conv 변환하고 Max Pooling 적용 로직을 별도 함수로 구현.\n",
        "* O = (I - F + 2P)/S + 1, I는 Input size, F는 filter의 kernel 크기, P는 padding, S는 Stride\n",
        "* (224 - 7)/2 + 1 = 109.5 = 109가 됨. 따라서 112x112 로 출력하기 위해 ZeroPadding2D(3, 3)수행\n",
        "* 112x112로 MaxPooling 을 (3, 3) pool size로 stride 2로 수행하므로 56x56으로 출력하기 위해 ZeroPadding2D(1,1) 수행"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC4yuaf9mGxs",
        "outputId": "4744ceaa-b8c1-4de2-cb18-36c85494b7a3"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import ZeroPadding2D, MaxPooling2D\n",
        "\n",
        "def do_first_conv(input_tensor):\n",
        "    # 7x7 Conv 연산 수행하여 feature map 생성, input_tensor 크기를 절반으로 생성\n",
        "    # filter 개수 : 64개 \n",
        "    # 224x224 를 input -> 7x7 conv, strides=2 -> 112x112 출력 (Zero padding 적용)\n",
        "    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(input_tensor)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal', name='conv')(x)\n",
        "    x = BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 다시 feature map 크기를 MaxPooling으로 절반으로 만듬 -> 56x56으로 출력 (zero padding 적용)\n",
        "    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "output = do_first_conv(input_tensor)\n",
        "model = Model(inputs=input_tensor, outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)       0         \n",
            "                                                                 \n",
            " conv (Conv2D)               (None, 112, 112, 64)      9472      \n",
            "                                                                 \n",
            " bn_conv1 (BatchNormalizatio  (None, 112, 112, 64)     256       \n",
            " n)                                                              \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 56, 56, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,728\n",
            "Trainable params: 9,600\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BIPGKFf8mGxt"
      },
      "cell_type": "markdown",
      "source": [
        "### 7. ResNet 50 모델 생성.\n",
        "* 앞에서 생성한 conv_block()과 identity_block()을 호출하여 ResNet 50 모델 생성. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pfGN0j-7mGxt"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "def create_resnet(in_shape=(224, 224, 3), n_classes=10):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "    \n",
        "    # 첫번째 7x7 Conv와 Max Pooling 적용.  \n",
        "    x = do_first_conv(input_tensor)\n",
        "    \n",
        "    # stage 2의 conv_block과 identity block 생성\n",
        "    # stage2의 첫번째 conv_block은 strides를 1로 하여 크기를 줄이지 않음. \n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "    \n",
        "    # stage 3의 conv_block과 identity block 생성\n",
        "    # stage3의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임 \n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # stage 4의 conv_block과 identity block 생성\n",
        "    # stage4의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # stage 5의 conv_block과 identity block 생성\n",
        "    # stage5의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    \n",
        "    # classification dense layer와 연결 전 GlobalAveragePooling 수행 \n",
        "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(200, activation='relu', name='fc_01')(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "   \n",
        "    # 마지막 fully connected layer & Softmax 함수를 이용해 확률 반환\n",
        "    output = Dense(n_classes, activation='softmax', name='fc_final')(x) \n",
        "    \n",
        "    # model 구성\n",
        "    model = Model(inputs=input_tensor, outputs=output, name='resnet50')\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UldtROIAmGxt",
        "outputId": "b3bc1790-bbe4-458a-997d-16b2920a44dd"
      },
      "cell_type": "code",
      "source": [
        "model =  create_resnet(in_shape=(224,224,3), n_classes=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv (Conv2D)                  (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_conv1 (BatchNormalization)  (None, 112, 112, 64  256         ['conv[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 112, 112, 64  0           ['bn_conv1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['activation_22[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)  0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)        (None, 56, 56, 64)   4160        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 56, 56, 64)   0           ['bn2a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 56, 56, 64)   0           ['bn2a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch1 (Conv2D)         (None, 56, 56, 256)  16640       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn2a_branch1 (BatchNormalizati  (None, 56, 56, 256)  1024       ['res2a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 56, 56, 256)  0           ['bn2a_branch2c[0][0]',          \n",
            "                                                                  'bn2a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 56, 56, 256)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " res2b_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 56, 56, 64)   0           ['bn2b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 56, 56, 64)   0           ['bn2b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 56, 56, 256)  0           ['activation_25[0][0]',          \n",
            "                                                                  'bn2b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 56, 56, 256)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " res2c_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 56, 56, 64)   0           ['bn2c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 56, 56, 64)   0           ['bn2c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 56, 56, 256)  0           ['activation_28[0][0]',          \n",
            "                                                                  'bn2c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 56, 56, 256)  0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " res3a_branch2a (Conv2D)        (None, 28, 28, 128)  32896       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " bn3a_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 28, 28, 128)  0           ['bn3a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3a_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " bn3a_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 28, 28, 128)  0           ['bn3a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3a_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " res3a_branch1 (Conv2D)         (None, 28, 28, 512)  131584      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " bn3a_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn3a_branch1 (BatchNormalizati  (None, 28, 28, 512)  2048       ['res3a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 28, 28, 512)  0           ['bn3a_branch2c[0][0]',          \n",
            "                                                                  'bn3a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 28, 28, 512)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " res3b_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " bn3b_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 28, 28, 128)  0           ['bn3b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3b_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " bn3b_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 28, 28, 128)  0           ['bn3b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3b_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " bn3b_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 28, 28, 512)  0           ['activation_34[0][0]',          \n",
            "                                                                  'bn3b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 28, 28, 512)  0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " res3c_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " bn3c_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 28, 28, 128)  0           ['bn3c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3c_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " bn3c_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 28, 28, 128)  0           ['bn3c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3c_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " bn3c_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 28, 28, 512)  0           ['activation_37[0][0]',          \n",
            "                                                                  'bn3c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 28, 28, 512)  0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " res3d_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " bn3d_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3d_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 28, 28, 128)  0           ['bn3d_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3d_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " bn3d_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3d_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 28, 28, 128)  0           ['bn3d_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3d_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " bn3d_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3d_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 28, 28, 512)  0           ['activation_40[0][0]',          \n",
            "                                                                  'bn3d_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 28, 28, 512)  0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " res4a_branch2a (Conv2D)        (None, 14, 14, 256)  131328      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " bn4a_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 14, 14, 256)  0           ['bn4a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4a_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " bn4a_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 14, 14, 256)  0           ['bn4a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4a_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_45[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res4a_branch1 (Conv2D)         (None, 14, 14, 1024  525312      ['activation_43[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn4a_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4a_branch2c[0][0]']         \n",
            " ion)                           )                                                                 \n",
            "                                                                                                  \n",
            " bn4a_branch1 (BatchNormalizati  (None, 14, 14, 1024  4096       ['res4a_branch1[0][0]']          \n",
            " on)                            )                                                                 \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 14, 14, 1024  0           ['bn4a_branch2c[0][0]',          \n",
            "                                )                                 'bn4a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 14, 14, 1024  0           ['add_14[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res4b_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " bn4b_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 14, 14, 256)  0           ['bn4b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4b_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " bn4b_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 14, 14, 256)  0           ['bn4b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4b_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_48[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn4b_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4b_branch2c[0][0]']         \n",
            " ion)                           )                                                                 \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 14, 14, 1024  0           ['activation_46[0][0]',          \n",
            "                                )                                 'bn4b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 14, 14, 1024  0           ['add_15[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res4c_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " bn4c_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 14, 14, 256)  0           ['bn4c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4c_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " bn4c_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 14, 14, 256)  0           ['bn4c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4c_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_51[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn4c_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4c_branch2c[0][0]']         \n",
            " ion)                           )                                                                 \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 14, 14, 1024  0           ['activation_49[0][0]',          \n",
            "                                )                                 'bn4c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 14, 14, 1024  0           ['add_16[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res4d_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " bn4d_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4d_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 14, 14, 256)  0           ['bn4d_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4d_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " bn4d_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4d_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 14, 14, 256)  0           ['bn4d_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4d_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_54[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn4d_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4d_branch2c[0][0]']         \n",
            " ion)                           )                                                                 \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 14, 14, 1024  0           ['activation_52[0][0]',          \n",
            "                                )                                 'bn4d_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 14, 14, 1024  0           ['add_17[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res4e_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " bn4e_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4e_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 14, 14, 256)  0           ['bn4e_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4e_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " bn4e_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4e_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 14, 14, 256)  0           ['bn4e_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4e_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_57[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn4e_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4e_branch2c[0][0]']         \n",
            " ion)                           )                                                                 \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 14, 14, 1024  0           ['activation_55[0][0]',          \n",
            "                                )                                 'bn4e_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 14, 14, 1024  0           ['add_18[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res4f_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " bn4f_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4f_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 14, 14, 256)  0           ['bn4f_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4f_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " bn4f_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4f_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 14, 14, 256)  0           ['bn4f_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4f_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_60[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn4f_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4f_branch2c[0][0]']         \n",
            " ion)                           )                                                                 \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 14, 14, 1024  0           ['activation_58[0][0]',          \n",
            "                                )                                 'bn4f_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 14, 14, 1024  0           ['add_19[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " res5a_branch2a (Conv2D)        (None, 7, 7, 512)    524800      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " bn5a_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 512)    0           ['bn5a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res5a_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " bn5a_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 512)    0           ['bn5a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res5a_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_63[0][0]']          \n",
            "                                                                                                  \n",
            " res5a_branch1 (Conv2D)         (None, 7, 7, 2048)   2099200     ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " bn5a_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn5a_branch1 (BatchNormalizati  (None, 7, 7, 2048)  8192        ['res5a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 7, 7, 2048)   0           ['bn5a_branch2c[0][0]',          \n",
            "                                                                  'bn5a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 2048)   0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " res5b_branch2a (Conv2D)        (None, 7, 7, 512)    1049088     ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " bn5b_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 512)    0           ['bn5b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res5b_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " bn5b_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 512)    0           ['bn5b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res5b_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " bn5b_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 7, 7, 2048)   0           ['activation_64[0][0]',          \n",
            "                                                                  'bn5b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 2048)   0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " res5c_branch2a (Conv2D)        (None, 7, 7, 512)    1049088     ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " bn5c_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 512)    0           ['bn5c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res5c_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_68[0][0]']          \n",
            "                                                                                                  \n",
            " bn5c_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 512)    0           ['bn5c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res5c_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " bn5c_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 7, 7, 2048)   0           ['activation_67[0][0]',          \n",
            "                                                                  'bn5c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 7, 7, 2048)   0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['activation_70[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " fc_01 (Dense)                  (None, 200)          409800      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 200)          0           ['fc_01[0][0]']                  \n",
            "                                                                                                  \n",
            " fc_final (Dense)               (None, 10)           2010        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,999,522\n",
            "Trainable params: 23,946,402\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9QYNl6apmGxt"
      },
      "cell_type": "markdown",
      "source": [
        "## CIFAR10 데이터 세트로 ResNet 모델 학습 및 성능 테스트"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1TjsWZQMmGxt"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vtG_X3h7mGxt"
      },
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리/인코딩/스케일링 함수 및 CIFAR_Dataset 선언"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-8Sym9UMmGxu"
      },
      "cell_type": "code",
      "source": [
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import cv2\n",
        "import sklearn\n",
        "\n",
        "def zero_one_scaler(image):\n",
        "    return image/255.0\n",
        "\n",
        "# One Hot Encoding(OHE)\n",
        "def get_preprocessed_ohe(images, labels, pre_func=None):\n",
        "    # preprocessing 함수가 입력되면 이를 이용하여 image array를 scaling 적용.\n",
        "    if pre_func is not None:\n",
        "        images = pre_func(images)\n",
        "    # OHE 적용    \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=42):\n",
        "\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경\n",
        "    # Label에 대해서는 OHE 적용\n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # train valid split\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels )\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import cv2\n",
        "import sklearn\n",
        "\n",
        "# 입력 인자 images_array labels는 모두 numpy array로 들어옴 (images_array는 32x32)\n",
        "class CIFAR_Dataset(Sequence):\n",
        "    def __init__(self, images_array, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "\n",
        "        images_array : 원본 32x32 만큼의 image 배열값. \n",
        "\n",
        "        labels : 해당 image의 label\n",
        "\n",
        "        batch_size : __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "\n",
        "        augmentor : albumentations 객체\n",
        "\n",
        "        shuffle : 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        # 인자로 입력되는 images_array는 전체 32x32 image array임.\n",
        "        self.images_array = images_array\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환 후 반환\n",
        "    # index(몇번째 배치이지) -> 해당 순서에 해당하는 batch_size 만큼의 데이터를 가공하여 반환\n",
        "    # batch_size 개수만큼 image_array와 label_array 반환\n",
        "    def __getitem__(self, index):\n",
        "        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size : (index+1)*self.batch_size 만큼 가져옴\n",
        "        # 32x32 image array를 self.batch_size만큼 가져옴. \n",
        "        images_fetch = self.images_array[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # albumentation으로 만든 augmentor가 주어진다면 augmentor를 이용\n",
        "        # albumentations : image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행 \n",
        "        # 변환된 image 배열값을 담을 image_batch 선언 & image_batch 배열은 float32 로 설정 \n",
        "        image_batch = np.zeros((images_fetch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환\n",
        "        # augmentor가 not None일 경우 -> image_batch에 담음\n",
        "        for image_index in range(images_fetch.shape[0]):\n",
        "            #image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # 원본 image를 IMAGE_SIZE x IMAGE_SIZE 크기로 변환\n",
        "            image = cv2.resize(images_fetch[image_index], (IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "            # 만약 augmentor가 주어졌다면 이를 적용. \n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "                \n",
        "            # 만약 scaling 함수가 입력되었다면 이를 적용하여 scaling 수행. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "            \n",
        "            # image_batch에 순차적으로 변환된 image를 담음.               \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 원본 image배열과 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.images_array, self.labels = sklearn.utils.shuffle(self.images_array, self.labels)\n",
        "        else:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIEIzahUmGxu"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 원-핫 인코딩, 학습/검증/테스트 데이터 세트 분할\n",
        "* scaling은 원본 채널별 pixel값 - [103.939, 116.779, 123.68] 적용.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2fpuivimGxu",
        "outputId": "c3608c6c-9aa5-4bca-dbad-c003fc396caa"
      },
      "cell_type": "code",
      "source": [
        "# CIFAR10 데이터 재 로딩 및 OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
        "\n",
        "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.2, random_state=2021)\n",
        "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 13s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "(40000, 32, 32, 3) (40000, 100) (10000, 32, 32, 3) (10000, 100) (10000, 32, 32, 3) (10000, 100)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bZBrrIJmmGxu"
      },
      "cell_type": "markdown",
      "source": [
        "### 학습, 검증용 CIFAR_Dataset 생성"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxHU_GitmGxu",
        "outputId": "20f19f59-f25b-4630-cbb2-12b9596e681c"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "\n",
        "tr_ds = CIFAR_Dataset(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=resnet_preprocess)\n",
        "val_ds = CIFAR_Dataset(val_images, val_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n",
        "\n",
        "print(next(iter(tr_ds))[0].shape, next(iter(val_ds))[0].shape)\n",
        "print(next(iter(tr_ds))[1].shape, next(iter(val_ds))[1].shape)\n",
        "# 채널별 값 - [103.939, 116.779, 123.68]\n",
        "print(next(iter(tr_ds))[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 128, 3) (64, 128, 128, 3)\n",
            "(64, 100) (64, 100)\n",
            "[[[118.061     128.22101   128.32     ]\n",
            "  [118.061     128.22101   128.32     ]\n",
            "  [116.061     127.221     127.32     ]\n",
            "  ...\n",
            "  [139.061     130.22101   118.32     ]\n",
            "  [139.061     130.22101   118.32     ]\n",
            "  [139.061     130.22101   118.32     ]]\n",
            "\n",
            " [[118.061     128.22101   128.32     ]\n",
            "  [118.061     128.22101   128.32     ]\n",
            "  [116.061     126.221     127.32     ]\n",
            "  ...\n",
            "  [139.061     130.22101   118.32     ]\n",
            "  [139.061     130.22101   118.32     ]\n",
            "  [139.061     130.22101   118.32     ]]\n",
            "\n",
            " [[117.061     127.221     127.32     ]\n",
            "  [117.061     127.221     127.32     ]\n",
            "  [115.061     125.221     126.32     ]\n",
            "  ...\n",
            "  [139.061     130.22101   118.32     ]\n",
            "  [139.061     130.22101   118.32     ]\n",
            "  [139.061     130.22101   118.32     ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-23.939003  -49.779     -66.68     ]\n",
            "  [-23.939003  -49.779     -66.68     ]\n",
            "  [-24.939003  -50.779     -67.68     ]\n",
            "  ...\n",
            "  [-21.939003    9.221001   51.32     ]\n",
            "  [-29.939003    3.2210007  48.32     ]\n",
            "  [-29.939003    3.2210007  48.32     ]]\n",
            "\n",
            " [[-23.939003  -49.779     -66.68     ]\n",
            "  [-23.939003  -49.779     -66.68     ]\n",
            "  [-24.939003  -49.779     -66.68     ]\n",
            "  ...\n",
            "  [-21.939003    9.221001   51.32     ]\n",
            "  [-29.939003    3.2210007  48.32     ]\n",
            "  [-29.939003    3.2210007  48.32     ]]\n",
            "\n",
            " [[-23.939003  -49.779     -66.68     ]\n",
            "  [-23.939003  -49.779     -66.68     ]\n",
            "  [-23.939003  -49.779     -66.68     ]\n",
            "  ...\n",
            "  [-21.939003    9.221001   51.32     ]\n",
            "  [-29.939003    3.2210007  48.32     ]\n",
            "  [-29.939003    3.2210007  48.32     ]]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zuB0gFGTmGxu"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) ResNet50 (모델 생성) 후 학습/평가\n",
        "* 초기 learning_rate 0.001\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5vPi0HfmGxu",
        "outputId": "3ab869fa-6ee6-4377-dd99-ff895330c9df"
      },
      "cell_type": "code",
      "source": [
        "resnet_model = create_resnet(in_shape=(128, 128, 3), n_classes=100)\n",
        "\n",
        "resnet_model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "\n",
        "history = resnet_model.fit(tr_ds, epochs=10, \n",
        "                    #steps_per_epoch=int(np.ceil(tr_images.shape[0]/BATCH_SIZE)),\n",
        "                    validation_data=val_ds, \n",
        "                    #validation_steps=int(np.ceil(val_images.shape[0]/BATCH_SIZE)), \n",
        "                    callbacks=[rlr_cb, ely_cb]\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 134, 134, 3)  0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv (Conv2D)                  (None, 64, 64, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " bn_conv1 (BatchNormalization)  (None, 64, 64, 64)   256         ['conv[0][0]']                   \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 64, 64, 64)   0           ['bn_conv1[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['activation_71[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " res2a_branch2a (Conv2D)        (None, 32, 32, 64)   4160        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " bn2a_branch2a (BatchNormalizat  (None, 32, 32, 64)  256         ['res2a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 32, 32, 64)   0           ['bn2a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2b (Conv2D)        (None, 32, 32, 64)   36928       ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " bn2a_branch2b (BatchNormalizat  (None, 32, 32, 64)  256         ['res2a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 32, 32, 64)   0           ['bn2a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch2c (Conv2D)        (None, 32, 32, 256)  16640       ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " res2a_branch1 (Conv2D)         (None, 32, 32, 256)  16640       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " bn2a_branch2c (BatchNormalizat  (None, 32, 32, 256)  1024       ['res2a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn2a_branch1 (BatchNormalizati  (None, 32, 32, 256)  1024       ['res2a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 32, 32, 256)  0           ['bn2a_branch2c[0][0]',          \n",
            "                                                                  'bn2a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 32, 32, 256)  0           ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " res2b_branch2a (Conv2D)        (None, 32, 32, 64)   16448       ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2a (BatchNormalizat  (None, 32, 32, 64)  256         ['res2b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 32, 32, 64)   0           ['bn2b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2b (Conv2D)        (None, 32, 32, 64)   36928       ['activation_75[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2b (BatchNormalizat  (None, 32, 32, 64)  256         ['res2b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 32, 32, 64)   0           ['bn2b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2b_branch2c (Conv2D)        (None, 32, 32, 256)  16640       ['activation_76[0][0]']          \n",
            "                                                                                                  \n",
            " bn2b_branch2c (BatchNormalizat  (None, 32, 32, 256)  1024       ['res2b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 32, 32, 256)  0           ['activation_74[0][0]',          \n",
            "                                                                  'bn2b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 32, 32, 256)  0           ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " res2c_branch2a (Conv2D)        (None, 32, 32, 64)   16448       ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2a (BatchNormalizat  (None, 32, 32, 64)  256         ['res2c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 32, 32, 64)   0           ['bn2c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2b (Conv2D)        (None, 32, 32, 64)   36928       ['activation_78[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2b (BatchNormalizat  (None, 32, 32, 64)  256         ['res2c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 32, 32, 64)   0           ['bn2c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res2c_branch2c (Conv2D)        (None, 32, 32, 256)  16640       ['activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " bn2c_branch2c (BatchNormalizat  (None, 32, 32, 256)  1024       ['res2c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 32, 32, 256)  0           ['activation_77[0][0]',          \n",
            "                                                                  'bn2c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 32, 32, 256)  0           ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " res3a_branch2a (Conv2D)        (None, 16, 16, 128)  32896       ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " bn3a_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 16, 16, 128)  0           ['bn3a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3a_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " bn3a_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 16, 16, 128)  0           ['bn3a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3a_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_82[0][0]']          \n",
            "                                                                                                  \n",
            " res3a_branch1 (Conv2D)         (None, 16, 16, 512)  131584      ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " bn3a_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn3a_branch1 (BatchNormalizati  (None, 16, 16, 512)  2048       ['res3a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 16, 16, 512)  0           ['bn3a_branch2c[0][0]',          \n",
            "                                                                  'bn3a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 16, 16, 512)  0           ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " res3b_branch2a (Conv2D)        (None, 16, 16, 128)  65664       ['activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " bn3b_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 16, 16, 128)  0           ['bn3b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3b_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " bn3b_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 16, 16, 128)  0           ['bn3b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3b_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_85[0][0]']          \n",
            "                                                                                                  \n",
            " bn3b_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 16, 16, 512)  0           ['activation_83[0][0]',          \n",
            "                                                                  'bn3b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 16, 16, 512)  0           ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " res3c_branch2a (Conv2D)        (None, 16, 16, 128)  65664       ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " bn3c_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 16, 16, 128)  0           ['bn3c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3c_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_87[0][0]']          \n",
            "                                                                                                  \n",
            " bn3c_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 16, 16, 128)  0           ['bn3c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3c_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " bn3c_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 16, 16, 512)  0           ['activation_86[0][0]',          \n",
            "                                                                  'bn3c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 16, 16, 512)  0           ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " res3d_branch2a (Conv2D)        (None, 16, 16, 128)  65664       ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " bn3d_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3d_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 16, 16, 128)  0           ['bn3d_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res3d_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " bn3d_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3d_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 16, 16, 128)  0           ['bn3d_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res3d_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_91[0][0]']          \n",
            "                                                                                                  \n",
            " bn3d_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3d_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 16, 16, 512)  0           ['activation_89[0][0]',          \n",
            "                                                                  'bn3d_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 16, 16, 512)  0           ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " res4a_branch2a (Conv2D)        (None, 8, 8, 256)    131328      ['activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " bn4a_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 256)    0           ['bn4a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4a_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " bn4a_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 8, 8, 256)    0           ['bn4a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4a_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_94[0][0]']          \n",
            "                                                                                                  \n",
            " res4a_branch1 (Conv2D)         (None, 8, 8, 1024)   525312      ['activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " bn4a_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn4a_branch1 (BatchNormalizati  (None, 8, 8, 1024)  4096        ['res4a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 8, 8, 1024)   0           ['bn4a_branch2c[0][0]',          \n",
            "                                                                  'bn4a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 8, 8, 1024)   0           ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " res4b_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_95[0][0]']          \n",
            "                                                                                                  \n",
            " bn4b_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 8, 8, 256)    0           ['bn4b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4b_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " bn4b_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 8, 8, 256)    0           ['bn4b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4b_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " bn4b_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 8, 8, 1024)   0           ['activation_95[0][0]',          \n",
            "                                                                  'bn4b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 8, 8, 1024)   0           ['add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " res4c_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " bn4c_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 8, 8, 256)    0           ['bn4c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4c_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_99[0][0]']          \n",
            "                                                                                                  \n",
            " bn4c_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 8, 8, 256)    0           ['bn4c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4c_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " bn4c_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 8, 8, 1024)   0           ['activation_98[0][0]',          \n",
            "                                                                  'bn4c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 8, 8, 1024)   0           ['add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " res4d_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_101[0][0]']         \n",
            "                                                                                                  \n",
            " bn4d_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4d_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 8, 8, 256)    0           ['bn4d_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4d_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " bn4d_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4d_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 8, 8, 256)    0           ['bn4d_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4d_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " bn4d_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4d_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 8, 8, 1024)   0           ['activation_101[0][0]',         \n",
            "                                                                  'bn4d_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 8, 8, 1024)   0           ['add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " res4e_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_104[0][0]']         \n",
            "                                                                                                  \n",
            " bn4e_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4e_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 8, 8, 256)    0           ['bn4e_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4e_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " bn4e_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4e_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 8, 8, 256)    0           ['bn4e_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4e_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_106[0][0]']         \n",
            "                                                                                                  \n",
            " bn4e_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4e_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_34 (Add)                   (None, 8, 8, 1024)   0           ['activation_104[0][0]',         \n",
            "                                                                  'bn4e_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 8, 8, 1024)   0           ['add_34[0][0]']                 \n",
            "                                                                                                  \n",
            " res4f_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " bn4f_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4f_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 8, 8, 256)    0           ['bn4f_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res4f_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_108[0][0]']         \n",
            "                                                                                                  \n",
            " bn4f_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4f_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 8, 8, 256)    0           ['bn4f_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res4f_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " bn4f_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4f_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_35 (Add)                   (None, 8, 8, 1024)   0           ['activation_107[0][0]',         \n",
            "                                                                  'bn4f_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 8, 8, 1024)   0           ['add_35[0][0]']                 \n",
            "                                                                                                  \n",
            " res5a_branch2a (Conv2D)        (None, 4, 4, 512)    524800      ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " bn5a_branch2a (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5a_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 4, 4, 512)    0           ['bn5a_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res5a_branch2b (Conv2D)        (None, 4, 4, 512)    2359808     ['activation_111[0][0]']         \n",
            "                                                                                                  \n",
            " bn5a_branch2b (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5a_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 4, 4, 512)    0           ['bn5a_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res5a_branch2c (Conv2D)        (None, 4, 4, 2048)   1050624     ['activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " res5a_branch1 (Conv2D)         (None, 4, 4, 2048)   2099200     ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " bn5a_branch2c (BatchNormalizat  (None, 4, 4, 2048)  8192        ['res5a_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " bn5a_branch1 (BatchNormalizati  (None, 4, 4, 2048)  8192        ['res5a_branch1[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add_36 (Add)                   (None, 4, 4, 2048)   0           ['bn5a_branch2c[0][0]',          \n",
            "                                                                  'bn5a_branch1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 4, 4, 2048)   0           ['add_36[0][0]']                 \n",
            "                                                                                                  \n",
            " res5b_branch2a (Conv2D)        (None, 4, 4, 512)    1049088     ['activation_113[0][0]']         \n",
            "                                                                                                  \n",
            " bn5b_branch2a (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5b_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 4, 4, 512)    0           ['bn5b_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res5b_branch2b (Conv2D)        (None, 4, 4, 512)    2359808     ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " bn5b_branch2b (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5b_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 4, 4, 512)    0           ['bn5b_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res5b_branch2c (Conv2D)        (None, 4, 4, 2048)   1050624     ['activation_115[0][0]']         \n",
            "                                                                                                  \n",
            " bn5b_branch2c (BatchNormalizat  (None, 4, 4, 2048)  8192        ['res5b_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_37 (Add)                   (None, 4, 4, 2048)   0           ['activation_113[0][0]',         \n",
            "                                                                  'bn5b_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 4, 4, 2048)   0           ['add_37[0][0]']                 \n",
            "                                                                                                  \n",
            " res5c_branch2a (Conv2D)        (None, 4, 4, 512)    1049088     ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " bn5c_branch2a (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5c_branch2a[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 4, 4, 512)    0           ['bn5c_branch2a[0][0]']          \n",
            "                                                                                                  \n",
            " res5c_branch2b (Conv2D)        (None, 4, 4, 512)    2359808     ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " bn5c_branch2b (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5c_branch2b[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 4, 4, 512)    0           ['bn5c_branch2b[0][0]']          \n",
            "                                                                                                  \n",
            " res5c_branch2c (Conv2D)        (None, 4, 4, 2048)   1050624     ['activation_118[0][0]']         \n",
            "                                                                                                  \n",
            " bn5c_branch2c (BatchNormalizat  (None, 4, 4, 2048)  8192        ['res5c_branch2c[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " add_38 (Add)                   (None, 4, 4, 2048)   0           ['activation_116[0][0]',         \n",
            "                                                                  'bn5c_branch2c[0][0]']          \n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 4, 4, 2048)   0           ['add_38[0][0]']                 \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['activation_119[0][0]']         \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " fc_01 (Dense)                  (None, 200)          409800      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 200)          0           ['fc_01[0][0]']                  \n",
            "                                                                                                  \n",
            " fc_final (Dense)               (None, 100)          20100       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,017,612\n",
            "Trainable params: 23,964,492\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 160s 247ms/step - loss: 4.7057 - accuracy: 0.0104 - val_loss: 4.6096 - val_accuracy: 0.0071 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6088 - accuracy: 0.0089 - val_loss: 4.6109 - val_accuracy: 0.0077 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6091 - accuracy: 0.0102 - val_loss: 4.6100 - val_accuracy: 0.0100 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6090 - accuracy: 0.0094 - val_loss: 4.6095 - val_accuracy: 0.0074 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6088 - accuracy: 0.0102 - val_loss: 4.6105 - val_accuracy: 0.0090 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6090 - accuracy: 0.0102 - val_loss: 4.6113 - val_accuracy: 0.0074 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 4.6088 - accuracy: 0.0093\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6088 - accuracy: 0.0093 - val_loss: 4.6101 - val_accuracy: 0.0104 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 153s 244ms/step - loss: 4.6068 - accuracy: 0.0094 - val_loss: 4.6083 - val_accuracy: 0.0104 - lr: 0.0020\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6060 - accuracy: 0.0088 - val_loss: 4.6084 - val_accuracy: 0.0082 - lr: 0.0020\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 4.6059 - accuracy: 0.0099 - val_loss: 4.6085 - val_accuracy: 0.0074 - lr: 0.0020\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gImZ32Z0mGxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc4b0ef-8751-42bc-a23a-6d0d8ac6e87c"
      },
      "cell_type": "code",
      "source": [
        "test_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n",
        "resnet_model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 12s 73ms/step - loss: 4.6056 - accuracy: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.605584144592285, 0.009999999776482582]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "oq2rHrXsmGxv"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) ResNet50 (Pretrained 모델)로 학습/평가"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ivQzaa25mGxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01fb90e-b1c7-4adf-f150-5f71c68629d7"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "input_tensor = Input(shape=(128, 128, 3))\n",
        "base_model = ResNet50(include_top=False, weights=None, input_tensor=input_tensor)\n",
        "bm_output = base_model.output\n",
        "\n",
        "# classification dense layer와 연결 전 GlobalAveragePooling 수행 \n",
        "x = GlobalAveragePooling2D(name='avg_pool')(bm_output)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "x = Dense(200, activation='relu', name='fc_01')(x)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "output = Dense(100, activation='softmax', name='fc_final')(x)\n",
        "\n",
        "pr_model = Model(inputs=input_tensor, outputs=output, name='resnet50')\n",
        "pr_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 134, 134, 3)  0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 64, 64, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 64, 64, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 64, 64, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 32, 32, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 32, 32, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 32, 32, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 32, 32, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 32, 32, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 32, 32, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 32, 32, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 32, 32, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 16, 16, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 16, 16, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 16, 16, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 16, 16, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 16, 16, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 16, 16, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 8, 8, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 8, 8, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 4, 4, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 4, 4, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 4, 4, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 4, 4, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " fc_01 (Dense)                  (None, 200)          409800      ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 200)          0           ['fc_01[0][0]']                  \n",
            "                                                                                                  \n",
            " fc_final (Dense)               (None, 100)          20100       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,017,612\n",
            "Trainable params: 23,964,492\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "f5Rb-lCSmGxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac8be47-0bdd-4aa5-d0fb-398876b74f44"
      },
      "cell_type": "code",
      "source": [
        "pr_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = pr_model.fit(tr_ds, epochs=40, \n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[rlr_cb, ely_cb]\n",
        "                   )\n",
        "\n",
        "test_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n",
        "pr_model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "625/625 [==============================] - 163s 253ms/step - loss: 3.0745 - accuracy: 0.2450 - val_loss: 2.8890 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 2.9071 - accuracy: 0.2743 - val_loss: 2.7830 - val_accuracy: 0.3066 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 2.7631 - accuracy: 0.3007 - val_loss: 2.7235 - val_accuracy: 0.3255 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 2.5685 - accuracy: 0.3397 - val_loss: 2.6092 - val_accuracy: 0.3416 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 2.3776 - accuracy: 0.3742 - val_loss: 2.6513 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 2.2249 - accuracy: 0.4089 - val_loss: 2.5796 - val_accuracy: 0.3614 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 1.9740 - accuracy: 0.4657 - val_loss: 2.7036 - val_accuracy: 0.3401 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 1.7446 - accuracy: 0.5182 - val_loss: 2.6064 - val_accuracy: 0.3834 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 1.5962 - accuracy: 0.5526\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 1.5962 - accuracy: 0.5526 - val_loss: 2.6634 - val_accuracy: 0.3829 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 1.0426 - accuracy: 0.6884 - val_loss: 2.6142 - val_accuracy: 0.4283 - lr: 2.0000e-05\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 0.8130 - accuracy: 0.7500 - val_loss: 2.8256 - val_accuracy: 0.4268 - lr: 2.0000e-05\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.7893\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 0.6643 - accuracy: 0.7893 - val_loss: 3.1391 - val_accuracy: 0.4181 - lr: 2.0000e-05\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 0.5292 - accuracy: 0.8280 - val_loss: 3.1750 - val_accuracy: 0.4232 - lr: 4.0000e-06\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 0.4755 - accuracy: 0.8433 - val_loss: 3.2412 - val_accuracy: 0.4244 - lr: 4.0000e-06\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8521\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 0.4461 - accuracy: 0.8521 - val_loss: 3.3093 - val_accuracy: 0.4237 - lr: 4.0000e-06\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 157s 251ms/step - loss: 0.4182 - accuracy: 0.8615 - val_loss: 3.3108 - val_accuracy: 0.4244 - lr: 8.0000e-07\n",
            "Epoch 16: early stopping\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 3.2143 - accuracy: 0.4342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.214346408843994, 0.4341999888420105]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Image Classification\n",
        "\n",
        "* tensorflow로 구현된 내용을 필자가 자주 활용하는 pytorch로 변환하여 과제 수행\n",
        "* 전체 Resnet을 구현하지는 않고, torchvision에서 이미 구현된 resnet을 활용하여 과제 수행\n",
        "* 나머지 사항들은 각주로서 설명"
      ],
      "metadata": {
        "id": "uuXGbpXj-nit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms \n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device='cuda'\n",
        "else:\n",
        "  device='cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap5spZtn70OV",
        "outputId": "27e334af-f442-4538-ff80-43e7c00f842d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Pytorch identity_block/conv_block/first_conv 구현\n",
        "     \n",
        "     *사실 Pytorch 특성상 이렇게 구현하면 안되는데..(pytorch는 클래스 중심으로 구현) tensorflow의 block들을 직관적으로 구현하고 이해하고자 부득이하게 단일 메소드로 구현.. "
      ],
      "metadata": {
        "id": "k6ZTnbtCEBTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "def identity_block(input_tensor, middle_kernel_size, filters):\n",
        "\n",
        "  #def __init__():\n",
        "  #self.input_tensor=input_tensor\n",
        "  #self.middle_kernel_size=middle_kernel_size\n",
        "  #self.filters=filters\n",
        "\n",
        "  #def _make_layers(input_tensor, middle_kernel_size, filters):\n",
        "  filter1, filter2, filter3=filters\n",
        "  relu=nn.ReLU()\n",
        "  conv1=nn.Conv2d(input_tensor.shape[1], filter1, kernel_size=(1,1))\n",
        "  bnorm1=nn.BatchNorm2d(filter1)\n",
        "\n",
        "  conv2=nn.Conv2d(filter1, filter2, kernel_size=middle_kernel_size)\n",
        "  bnorm2=nn.BatchNorm2d(filter2)\n",
        "\n",
        "  conv3=nn.Conv2d(filter2, filter3, kernel_size=(1,1))\n",
        "  bnorm3=nn.BatchNorm2d(filter3)\n",
        "\n",
        "  #def forward():\n",
        "  x=conv1(input_tensor)\n",
        "  x=bnorm1(x)\n",
        "  x=relu(x)\n",
        "  x=conv2(x)\n",
        "  x=bnorm2(x)\n",
        "  x=relu(x)\n",
        "  x=conv3(x)\n",
        "  x=bnorm3(x)\n",
        "  \n",
        "  x=torch.add(input_tensor, x)\n",
        "  x=relu(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "UFvLGrCQ74Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(input_tensor, middle_kernel_size, filters, strides=(2,2)):\n",
        "\n",
        "\n",
        "  #def _make_layers(input_tensor, middle_kernel_size, filters, strides):\n",
        "  filter1, filter2, filter3=filter1\n",
        "\n",
        "  relu=nn.ReLU()\n",
        "\n",
        "  conv1=nn.Conv2d(input_tensor.shape[1], filter1, kernel_size=(1,1), stride=2)\n",
        "  bnorm1=nn.BatchNorm2d(filter1)\n",
        "\n",
        "  conv2=nn.Conv2d(filter1, filter2, kernel_size=middle_kernel_size, padding=1)\n",
        "  bnorm2=nn.BatchNorm2d(filter2)\n",
        "\n",
        "  conv3=nn.Conv2d(filter2, filter3, kernel_size=(1,1))\n",
        "  bnorm3=nn.BatchNorm2d(filter3)\n",
        "\n",
        "  shortcut1=nn.Conv2d(filter3, filter3, kernel_size=(1,1), stride=strides)\n",
        "  shortcut2=nn.BatchNorm2d(filter3)\n",
        "\n",
        "  #def forward():\n",
        "  x=conv1(input_tensor)\n",
        "  x=bnorm1(x)\n",
        "  x=relu(x)\n",
        "  x=conv2(x)\n",
        "  x=bnorm2(x)\n",
        "  x=relu(x)\n",
        "  x=conv3(x)\n",
        "  x=bnorm3(x)\n",
        "  \n",
        "  shortcut=shortcut1(input_tensor)\n",
        "  shortcut=shortcut2(shortcut)\n",
        "\n",
        "  x=torch.add(x, shortcut)\n",
        "  x=relu(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "TPYu0Fyo75H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def first_conv(input_tensor):\n",
        "\n",
        "  #def _make_layers(input_tensor):\n",
        "  pad1=nn.ZeroPad2d((3,3))\n",
        "  conv1=nn.Conv2d(64, (7,7),strides=(2,2))\n",
        "  bnorm1=nn.BatchNorm2d(64)\n",
        "  relu=nn.ReLU()\n",
        "\n",
        "  pad2=nn.ZeroPad2d((1,1))\n",
        "  maxpool=nn.MaxPool2d((3,3),strides=(2,2))\n",
        "\n",
        "  #def forward():\n",
        "  x=pad1(input_tensor)\n",
        "  x=conv1(x)\n",
        "  x=bnorm1(x)\n",
        "  x=relu(x)\n",
        "\n",
        "  x=pad2(x)\n",
        "  x=maxpool(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "hIYDgwyj77He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Resnet"
      ],
      "metadata": {
        "id": "cOJ2H2jQFHkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data=datasets.CIFAR100(root='data',\n",
        "                          train=True,\n",
        "                          download=True,\n",
        "                          )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5gsHtwFgHRi",
        "outputId": "752448b0-6a2a-4dd6-e75d-0bf3a3ef715a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Image Normalization\n",
        "x = np.concatenate([np.asarray(tr_data[i][0]) for i in range(len(tr_data))])\n",
        "\n",
        "mean = np.mean(x, axis=(0, 1))/255\n",
        "std = np.std(x, axis=(0, 1))/255\n",
        "\n",
        "mean=mean.tolist()\n",
        "std=std.tolist()"
      ],
      "metadata": {
        "id": "KwvZaL1If1Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data=datasets.CIFAR100(root='data',\n",
        "                          train=True,\n",
        "                          download=True,\n",
        "                          transform=transforms.Compose([ #Simple Augmentation 적용\n",
        "                              transforms.Resize(224), #원래 224*224 이미지에 적합한 모델이므로 Resize\n",
        "                              transforms.RandomCrop(224, padding=4,padding_mode='reflect'), #224*224 image에서 image RandomCrop(*image augmentation)\n",
        "                              transforms.RandomHorizontalFlip(), #horizontal 방향으로 사진 뒤집기\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize(mean=mean,\n",
        "                                     std=std,inplace=True)\n",
        "                          ]))\n",
        "\n",
        "test_data=datasets.CIFAR100(root='data',\n",
        "                          train=False,\n",
        "                          download=True,\n",
        "                          transform=transforms.Compose([\n",
        "                              transforms.Resize(224),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize(mean=mean,\n",
        "                                     std=std)\n",
        "                          ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYinODQV78qj",
        "outputId": "2bf16505-c718-4f59-e63b-235dc2ecc045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 32\n",
        "\n",
        "train_db=DataLoader(tr_data, batch_size=batch_size,shuffle=True,pin_memory=True)\n",
        "test_db=DataLoader(test_data, batch_size=batch_size,shuffle=False,pin_memory=True)"
      ],
      "metadata": {
        "id": "2izxV92V7-bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False) #Resnet 호출 \n",
        "model.to(device) #cuda 올리기\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=5e-3,weight_decay=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MvrtoZC8BRL",
        "outputId": "c2f26230-a969-4ef8-9e13-f1294c70f133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary #model summary check\n",
        "\n",
        "summary(model, (3,224,224), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXn_Ctd9hqlq",
        "outputId": "17d8d213-96be-499a-f8e3-52185479768c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [32, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [32, 64, 112, 112]             128\n",
            "              ReLU-3         [32, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [32, 64, 56, 56]               0\n",
            "            Conv2d-5           [32, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [32, 64, 56, 56]             128\n",
            "              ReLU-7           [32, 64, 56, 56]               0\n",
            "            Conv2d-8           [32, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [32, 64, 56, 56]             128\n",
            "             ReLU-10           [32, 64, 56, 56]               0\n",
            "           Conv2d-11          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [32, 256, 56, 56]             512\n",
            "           Conv2d-13          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [32, 256, 56, 56]             512\n",
            "             ReLU-15          [32, 256, 56, 56]               0\n",
            "       Bottleneck-16          [32, 256, 56, 56]               0\n",
            "           Conv2d-17           [32, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [32, 64, 56, 56]             128\n",
            "             ReLU-19           [32, 64, 56, 56]               0\n",
            "           Conv2d-20           [32, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [32, 64, 56, 56]             128\n",
            "             ReLU-22           [32, 64, 56, 56]               0\n",
            "           Conv2d-23          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [32, 256, 56, 56]             512\n",
            "             ReLU-25          [32, 256, 56, 56]               0\n",
            "       Bottleneck-26          [32, 256, 56, 56]               0\n",
            "           Conv2d-27           [32, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [32, 64, 56, 56]             128\n",
            "             ReLU-29           [32, 64, 56, 56]               0\n",
            "           Conv2d-30           [32, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [32, 64, 56, 56]             128\n",
            "             ReLU-32           [32, 64, 56, 56]               0\n",
            "           Conv2d-33          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [32, 256, 56, 56]             512\n",
            "             ReLU-35          [32, 256, 56, 56]               0\n",
            "       Bottleneck-36          [32, 256, 56, 56]               0\n",
            "           Conv2d-37          [32, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [32, 128, 56, 56]             256\n",
            "             ReLU-39          [32, 128, 56, 56]               0\n",
            "           Conv2d-40          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [32, 128, 28, 28]             256\n",
            "             ReLU-42          [32, 128, 28, 28]               0\n",
            "           Conv2d-43          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [32, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [32, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [32, 512, 28, 28]           1,024\n",
            "             ReLU-47          [32, 512, 28, 28]               0\n",
            "       Bottleneck-48          [32, 512, 28, 28]               0\n",
            "           Conv2d-49          [32, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [32, 128, 28, 28]             256\n",
            "             ReLU-51          [32, 128, 28, 28]               0\n",
            "           Conv2d-52          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [32, 128, 28, 28]             256\n",
            "             ReLU-54          [32, 128, 28, 28]               0\n",
            "           Conv2d-55          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [32, 512, 28, 28]           1,024\n",
            "             ReLU-57          [32, 512, 28, 28]               0\n",
            "       Bottleneck-58          [32, 512, 28, 28]               0\n",
            "           Conv2d-59          [32, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [32, 128, 28, 28]             256\n",
            "             ReLU-61          [32, 128, 28, 28]               0\n",
            "           Conv2d-62          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [32, 128, 28, 28]             256\n",
            "             ReLU-64          [32, 128, 28, 28]               0\n",
            "           Conv2d-65          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [32, 512, 28, 28]           1,024\n",
            "             ReLU-67          [32, 512, 28, 28]               0\n",
            "       Bottleneck-68          [32, 512, 28, 28]               0\n",
            "           Conv2d-69          [32, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [32, 128, 28, 28]             256\n",
            "             ReLU-71          [32, 128, 28, 28]               0\n",
            "           Conv2d-72          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [32, 128, 28, 28]             256\n",
            "             ReLU-74          [32, 128, 28, 28]               0\n",
            "           Conv2d-75          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [32, 512, 28, 28]           1,024\n",
            "             ReLU-77          [32, 512, 28, 28]               0\n",
            "       Bottleneck-78          [32, 512, 28, 28]               0\n",
            "           Conv2d-79          [32, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [32, 256, 28, 28]             512\n",
            "             ReLU-81          [32, 256, 28, 28]               0\n",
            "           Conv2d-82          [32, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [32, 256, 14, 14]             512\n",
            "             ReLU-84          [32, 256, 14, 14]               0\n",
            "           Conv2d-85         [32, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [32, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [32, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [32, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [32, 1024, 14, 14]               0\n",
            "           Conv2d-91          [32, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [32, 256, 14, 14]             512\n",
            "             ReLU-93          [32, 256, 14, 14]               0\n",
            "           Conv2d-94          [32, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [32, 256, 14, 14]             512\n",
            "             ReLU-96          [32, 256, 14, 14]               0\n",
            "           Conv2d-97         [32, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [32, 1024, 14, 14]               0\n",
            "          Conv2d-101          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [32, 256, 14, 14]             512\n",
            "            ReLU-103          [32, 256, 14, 14]               0\n",
            "          Conv2d-104          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [32, 256, 14, 14]             512\n",
            "            ReLU-106          [32, 256, 14, 14]               0\n",
            "          Conv2d-107         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [32, 1024, 14, 14]               0\n",
            "          Conv2d-111          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [32, 256, 14, 14]             512\n",
            "            ReLU-113          [32, 256, 14, 14]               0\n",
            "          Conv2d-114          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [32, 256, 14, 14]             512\n",
            "            ReLU-116          [32, 256, 14, 14]               0\n",
            "          Conv2d-117         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [32, 1024, 14, 14]               0\n",
            "          Conv2d-121          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [32, 256, 14, 14]             512\n",
            "            ReLU-123          [32, 256, 14, 14]               0\n",
            "          Conv2d-124          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [32, 256, 14, 14]             512\n",
            "            ReLU-126          [32, 256, 14, 14]               0\n",
            "          Conv2d-127         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [32, 1024, 14, 14]               0\n",
            "          Conv2d-131          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [32, 256, 14, 14]             512\n",
            "            ReLU-133          [32, 256, 14, 14]               0\n",
            "          Conv2d-134          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [32, 256, 14, 14]             512\n",
            "            ReLU-136          [32, 256, 14, 14]               0\n",
            "          Conv2d-137         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [32, 1024, 14, 14]               0\n",
            "          Conv2d-141          [32, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [32, 512, 14, 14]           1,024\n",
            "            ReLU-143          [32, 512, 14, 14]               0\n",
            "          Conv2d-144            [32, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [32, 512, 7, 7]           1,024\n",
            "            ReLU-146            [32, 512, 7, 7]               0\n",
            "          Conv2d-147           [32, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [32, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [32, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [32, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [32, 2048, 7, 7]               0\n",
            "          Conv2d-153            [32, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [32, 512, 7, 7]           1,024\n",
            "            ReLU-155            [32, 512, 7, 7]               0\n",
            "          Conv2d-156            [32, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [32, 512, 7, 7]           1,024\n",
            "            ReLU-158            [32, 512, 7, 7]               0\n",
            "          Conv2d-159           [32, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [32, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [32, 2048, 7, 7]               0\n",
            "          Conv2d-163            [32, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [32, 512, 7, 7]           1,024\n",
            "            ReLU-165            [32, 512, 7, 7]               0\n",
            "          Conv2d-166            [32, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [32, 512, 7, 7]           1,024\n",
            "            ReLU-168            [32, 512, 7, 7]               0\n",
            "          Conv2d-169           [32, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [32, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [32, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [32, 2048, 1, 1]               0\n",
            "          Linear-174                  [32, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 23,712,932\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 18.38\n",
            "Forward/backward pass size (MB): 9169.65\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 9278.48\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#마지막 Linear layer의 softmax가 1000-d로 구성되어 있음 _ ImageNet Classification에 적합한 모델\n",
        "#Cifar-100은 100개의 label이기 때문에 100-d로 linear layer 수정\n",
        "for name, child in model.named_children():\n",
        "    if isinstance(child, nn.Linear):\n",
        "        model._modules[name]=nn.Linear(2048, 100).to(device) #instance 변경 후 device에 올리기\n",
        "    elif isinstance(child, nn.Sequential): #sequential 안에 있으면 거기에서 변환\n",
        "        for sname, schild in child.named_children():\n",
        "            if isinstance(schild, nn.Linear):\n",
        "                print(name,sname)\n",
        "                model._modules[name]._modules[sname]=nn.Linear(2048, 100).to(device)"
      ],
      "metadata": {
        "id": "hU7maA9_4Lgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3,224,224), batch_size=32) #100-d로 변환 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU9zHCno4Zmt",
        "outputId": "737684e5-f004-440a-fa5e-c338559a4cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [32, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [32, 64, 112, 112]             128\n",
            "              ReLU-3         [32, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [32, 64, 56, 56]               0\n",
            "            Conv2d-5           [32, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [32, 64, 56, 56]             128\n",
            "              ReLU-7           [32, 64, 56, 56]               0\n",
            "            Conv2d-8           [32, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [32, 64, 56, 56]             128\n",
            "             ReLU-10           [32, 64, 56, 56]               0\n",
            "           Conv2d-11          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [32, 256, 56, 56]             512\n",
            "           Conv2d-13          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [32, 256, 56, 56]             512\n",
            "             ReLU-15          [32, 256, 56, 56]               0\n",
            "       Bottleneck-16          [32, 256, 56, 56]               0\n",
            "           Conv2d-17           [32, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [32, 64, 56, 56]             128\n",
            "             ReLU-19           [32, 64, 56, 56]               0\n",
            "           Conv2d-20           [32, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [32, 64, 56, 56]             128\n",
            "             ReLU-22           [32, 64, 56, 56]               0\n",
            "           Conv2d-23          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [32, 256, 56, 56]             512\n",
            "             ReLU-25          [32, 256, 56, 56]               0\n",
            "       Bottleneck-26          [32, 256, 56, 56]               0\n",
            "           Conv2d-27           [32, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [32, 64, 56, 56]             128\n",
            "             ReLU-29           [32, 64, 56, 56]               0\n",
            "           Conv2d-30           [32, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [32, 64, 56, 56]             128\n",
            "             ReLU-32           [32, 64, 56, 56]               0\n",
            "           Conv2d-33          [32, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [32, 256, 56, 56]             512\n",
            "             ReLU-35          [32, 256, 56, 56]               0\n",
            "       Bottleneck-36          [32, 256, 56, 56]               0\n",
            "           Conv2d-37          [32, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [32, 128, 56, 56]             256\n",
            "             ReLU-39          [32, 128, 56, 56]               0\n",
            "           Conv2d-40          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [32, 128, 28, 28]             256\n",
            "             ReLU-42          [32, 128, 28, 28]               0\n",
            "           Conv2d-43          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [32, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [32, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [32, 512, 28, 28]           1,024\n",
            "             ReLU-47          [32, 512, 28, 28]               0\n",
            "       Bottleneck-48          [32, 512, 28, 28]               0\n",
            "           Conv2d-49          [32, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [32, 128, 28, 28]             256\n",
            "             ReLU-51          [32, 128, 28, 28]               0\n",
            "           Conv2d-52          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [32, 128, 28, 28]             256\n",
            "             ReLU-54          [32, 128, 28, 28]               0\n",
            "           Conv2d-55          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [32, 512, 28, 28]           1,024\n",
            "             ReLU-57          [32, 512, 28, 28]               0\n",
            "       Bottleneck-58          [32, 512, 28, 28]               0\n",
            "           Conv2d-59          [32, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [32, 128, 28, 28]             256\n",
            "             ReLU-61          [32, 128, 28, 28]               0\n",
            "           Conv2d-62          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [32, 128, 28, 28]             256\n",
            "             ReLU-64          [32, 128, 28, 28]               0\n",
            "           Conv2d-65          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [32, 512, 28, 28]           1,024\n",
            "             ReLU-67          [32, 512, 28, 28]               0\n",
            "       Bottleneck-68          [32, 512, 28, 28]               0\n",
            "           Conv2d-69          [32, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [32, 128, 28, 28]             256\n",
            "             ReLU-71          [32, 128, 28, 28]               0\n",
            "           Conv2d-72          [32, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [32, 128, 28, 28]             256\n",
            "             ReLU-74          [32, 128, 28, 28]               0\n",
            "           Conv2d-75          [32, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [32, 512, 28, 28]           1,024\n",
            "             ReLU-77          [32, 512, 28, 28]               0\n",
            "       Bottleneck-78          [32, 512, 28, 28]               0\n",
            "           Conv2d-79          [32, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [32, 256, 28, 28]             512\n",
            "             ReLU-81          [32, 256, 28, 28]               0\n",
            "           Conv2d-82          [32, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [32, 256, 14, 14]             512\n",
            "             ReLU-84          [32, 256, 14, 14]               0\n",
            "           Conv2d-85         [32, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [32, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [32, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [32, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [32, 1024, 14, 14]               0\n",
            "           Conv2d-91          [32, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [32, 256, 14, 14]             512\n",
            "             ReLU-93          [32, 256, 14, 14]               0\n",
            "           Conv2d-94          [32, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [32, 256, 14, 14]             512\n",
            "             ReLU-96          [32, 256, 14, 14]               0\n",
            "           Conv2d-97         [32, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [32, 1024, 14, 14]               0\n",
            "          Conv2d-101          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [32, 256, 14, 14]             512\n",
            "            ReLU-103          [32, 256, 14, 14]               0\n",
            "          Conv2d-104          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [32, 256, 14, 14]             512\n",
            "            ReLU-106          [32, 256, 14, 14]               0\n",
            "          Conv2d-107         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [32, 1024, 14, 14]               0\n",
            "          Conv2d-111          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [32, 256, 14, 14]             512\n",
            "            ReLU-113          [32, 256, 14, 14]               0\n",
            "          Conv2d-114          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [32, 256, 14, 14]             512\n",
            "            ReLU-116          [32, 256, 14, 14]               0\n",
            "          Conv2d-117         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [32, 1024, 14, 14]               0\n",
            "          Conv2d-121          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [32, 256, 14, 14]             512\n",
            "            ReLU-123          [32, 256, 14, 14]               0\n",
            "          Conv2d-124          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [32, 256, 14, 14]             512\n",
            "            ReLU-126          [32, 256, 14, 14]               0\n",
            "          Conv2d-127         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [32, 1024, 14, 14]               0\n",
            "          Conv2d-131          [32, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [32, 256, 14, 14]             512\n",
            "            ReLU-133          [32, 256, 14, 14]               0\n",
            "          Conv2d-134          [32, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [32, 256, 14, 14]             512\n",
            "            ReLU-136          [32, 256, 14, 14]               0\n",
            "          Conv2d-137         [32, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [32, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [32, 1024, 14, 14]               0\n",
            "          Conv2d-141          [32, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [32, 512, 14, 14]           1,024\n",
            "            ReLU-143          [32, 512, 14, 14]               0\n",
            "          Conv2d-144            [32, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [32, 512, 7, 7]           1,024\n",
            "            ReLU-146            [32, 512, 7, 7]               0\n",
            "          Conv2d-147           [32, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [32, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [32, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [32, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [32, 2048, 7, 7]               0\n",
            "          Conv2d-153            [32, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [32, 512, 7, 7]           1,024\n",
            "            ReLU-155            [32, 512, 7, 7]               0\n",
            "          Conv2d-156            [32, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [32, 512, 7, 7]           1,024\n",
            "            ReLU-158            [32, 512, 7, 7]               0\n",
            "          Conv2d-159           [32, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [32, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [32, 2048, 7, 7]               0\n",
            "          Conv2d-163            [32, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [32, 512, 7, 7]           1,024\n",
            "            ReLU-165            [32, 512, 7, 7]               0\n",
            "          Conv2d-166            [32, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [32, 512, 7, 7]           1,024\n",
            "            ReLU-168            [32, 512, 7, 7]               0\n",
            "          Conv2d-169           [32, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [32, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [32, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [32, 2048, 1, 1]               0\n",
            "          Linear-174                  [32, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 23,712,932\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 18.38\n",
            "Forward/backward pass size (MB): 9169.65\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 9278.48\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer,epochs,max_lr,grad_clip=None):\n",
        "  size = len(dataloader.dataset)\n",
        "  sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(dataloader))\n",
        "  lrs=[]\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        if grad_clip: #gradient clipping\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        lrs.append(get_lr(optimizer))\n",
        "        sched.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(loss)\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  \n",
        "  size=len(dataloader.dataset)\n",
        "  num_batches=len(dataloader)\n",
        "  model.eval()\n",
        "  loss, correct=0,0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y=X.to(device), y.to(device)\n",
        "      pred=model(X)\n",
        "      loss+=loss_fn(pred,y).item()\n",
        "      correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  loss/=num_batches\n",
        "  correct/=size\n",
        "  print('accuracy:'+str(100*correct), 'loss:' +str(loss))\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "pLWz4Nj58E0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 20 #20 Epoch에 정확도 61% 수준,, \n",
        "for t in range(epoch):\n",
        "\n",
        "  print('epoch('+str(t+1)+'/'+str(epoch)+')')\n",
        "  train(train_db, model, loss_fn, optimizer,epoch, 0.01)\n",
        "  test(test_db, model, loss_fn)\n",
        "  \n",
        "print('done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFlTrHMy8H7M",
        "outputId": "9e5b7c61-aa02-4950-a491-9f136a5b126e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch(1/20)\n",
            "4.615495681762695\n",
            "4.376228332519531\n",
            "3.343193292617798\n",
            "3.0038888454437256\n",
            "3.0677719116210938\n",
            "2.8942923545837402\n",
            "2.7303531169891357\n",
            "3.1208972930908203\n",
            "3.1054129600524902\n",
            "2.762056350708008\n",
            "3.0382602214813232\n",
            "3.472717761993408\n",
            "2.252007007598877\n",
            "2.7657196521759033\n",
            "2.933149576187134\n",
            "3.0089261531829834\n",
            "accuracy:36.78 loss:2.5490293632300136\n",
            "epoch(2/20)\n",
            "2.3823137283325195\n",
            "2.423600435256958\n",
            "2.208503246307373\n",
            "2.263887882232666\n",
            "2.4532291889190674\n",
            "1.533050775527954\n",
            "2.629459857940674\n",
            "2.5157315731048584\n",
            "2.5312321186065674\n",
            "2.559492588043213\n",
            "1.6848491430282593\n",
            "2.600003719329834\n",
            "2.5988986492156982\n",
            "2.4901270866394043\n",
            "3.0182278156280518\n",
            "2.290137767791748\n",
            "accuracy:39.54 loss:2.439271952016666\n",
            "epoch(3/20)\n",
            "2.224228858947754\n",
            "2.2281625270843506\n",
            "2.099073648452759\n",
            "2.201167106628418\n",
            "2.2201578617095947\n",
            "1.859486699104309\n",
            "1.9062190055847168\n",
            "1.7283892631530762\n",
            "1.8501701354980469\n",
            "2.7545695304870605\n",
            "2.237600564956665\n",
            "2.3745172023773193\n",
            "2.3602795600891113\n",
            "2.871743679046631\n",
            "3.0025010108947754\n",
            "1.9429994821548462\n",
            "accuracy:40.5 loss:2.368562074134144\n",
            "epoch(4/20)\n",
            "2.855541229248047\n",
            "1.7348778247833252\n",
            "1.986913800239563\n",
            "1.708780288696289\n",
            "1.943291425704956\n",
            "1.5149223804473877\n",
            "2.041292428970337\n",
            "1.8811759948730469\n",
            "2.197421073913574\n",
            "2.7835195064544678\n",
            "1.9422272443771362\n",
            "1.7053325176239014\n",
            "2.11541485786438\n",
            "2.4413769245147705\n",
            "2.812018632888794\n",
            "2.0106661319732666\n",
            "accuracy:41.980000000000004 loss:2.2734769053352526\n",
            "epoch(5/20)\n",
            "2.207261085510254\n",
            "1.8625801801681519\n",
            "2.2339508533477783\n",
            "1.8425315618515015\n",
            "2.098937511444092\n",
            "2.2426156997680664\n",
            "1.752704381942749\n",
            "2.258552312850952\n",
            "2.0413336753845215\n",
            "1.9281049966812134\n",
            "2.157921075820923\n",
            "2.205125331878662\n",
            "2.472829580307007\n",
            "1.9454593658447266\n",
            "2.5657520294189453\n",
            "2.0988054275512695\n",
            "accuracy:46.89 loss:2.1059492057123883\n",
            "epoch(6/20)\n",
            "2.1526925563812256\n",
            "2.3109328746795654\n",
            "1.9948248863220215\n",
            "2.451653242111206\n",
            "1.7286949157714844\n",
            "1.9157984256744385\n",
            "1.2907058000564575\n",
            "2.4773647785186768\n",
            "1.967098355293274\n",
            "2.252457618713379\n",
            "1.6800556182861328\n",
            "1.9789347648620605\n",
            "1.9757132530212402\n",
            "1.653742790222168\n",
            "1.9054267406463623\n",
            "1.9284933805465698\n",
            "accuracy:48.41 loss:2.014692161029901\n",
            "epoch(7/20)\n",
            "2.552659034729004\n",
            "2.4299542903900146\n",
            "1.8939619064331055\n",
            "1.3848259449005127\n",
            "1.5961103439331055\n",
            "2.0972938537597656\n",
            "1.9766619205474854\n",
            "2.2203657627105713\n",
            "2.2589142322540283\n",
            "1.8410148620605469\n",
            "1.9340331554412842\n",
            "1.5914456844329834\n",
            "2.2287819385528564\n",
            "2.215834140777588\n",
            "2.3844854831695557\n",
            "2.37801456451416\n",
            "accuracy:50.0 loss:1.971849748120902\n",
            "epoch(8/20)\n",
            "2.111314058303833\n",
            "1.488059401512146\n",
            "1.8320552110671997\n",
            "2.4236016273498535\n",
            "1.628625512123108\n",
            "1.55997896194458\n",
            "2.280048370361328\n",
            "2.080353021621704\n",
            "1.883703589439392\n",
            "1.7149056196212769\n",
            "1.448932409286499\n",
            "2.05411434173584\n",
            "1.9463456869125366\n",
            "1.9491350650787354\n",
            "2.072334051132202\n",
            "2.269547700881958\n",
            "accuracy:51.67 loss:1.8790252684785154\n",
            "epoch(9/20)\n",
            "2.0542004108428955\n",
            "2.132127046585083\n",
            "1.471649408340454\n",
            "1.6442513465881348\n",
            "1.4529279470443726\n",
            "2.028696060180664\n",
            "1.6548634767532349\n",
            "2.0850462913513184\n",
            "1.9010339975357056\n",
            "2.140617609024048\n",
            "1.868816614151001\n",
            "1.9981744289398193\n",
            "1.7193139791488647\n",
            "2.2428178787231445\n",
            "1.914794683456421\n",
            "1.9530823230743408\n",
            "accuracy:53.02 loss:1.8466607549320013\n",
            "epoch(10/20)\n",
            "1.9940024614334106\n",
            "1.888357400894165\n",
            "1.485741376876831\n",
            "1.0119560956954956\n",
            "1.2743771076202393\n",
            "1.5253167152404785\n",
            "1.6959691047668457\n",
            "1.6654036045074463\n",
            "1.5731083154678345\n",
            "2.1837363243103027\n",
            "1.7976988554000854\n",
            "1.2814288139343262\n",
            "1.4788559675216675\n",
            "1.793055534362793\n",
            "1.9395220279693604\n",
            "1.6162605285644531\n",
            "accuracy:53.72 loss:1.79149770355834\n",
            "epoch(11/20)\n",
            "1.9733792543411255\n",
            "1.8585985898971558\n",
            "1.7608526945114136\n",
            "1.2728188037872314\n",
            "1.6268583536148071\n",
            "1.9530047178268433\n",
            "1.6240336894989014\n",
            "1.6048915386199951\n",
            "1.7085901498794556\n",
            "1.3955895900726318\n",
            "1.8126084804534912\n",
            "1.5161793231964111\n",
            "2.2091422080993652\n",
            "1.4868115186691284\n",
            "1.8742605447769165\n",
            "1.942233920097351\n",
            "accuracy:56.120000000000005 loss:1.7268591422242479\n",
            "epoch(12/20)\n",
            "1.8088878393173218\n",
            "1.7074332237243652\n",
            "1.654364824295044\n",
            "1.5279474258422852\n",
            "1.427123785018921\n",
            "1.0951833724975586\n",
            "1.5738786458969116\n",
            "1.8005520105361938\n",
            "1.4805916547775269\n",
            "1.2964295148849487\n",
            "1.6189066171646118\n",
            "1.9617750644683838\n",
            "1.865372657775879\n",
            "1.4992212057113647\n",
            "2.1327295303344727\n",
            "1.590216040611267\n",
            "accuracy:56.86 loss:1.6644268843312613\n",
            "epoch(13/20)\n",
            "1.6099138259887695\n",
            "1.808521032333374\n",
            "1.2675656080245972\n",
            "1.6434664726257324\n",
            "1.5941489934921265\n",
            "1.740057349205017\n",
            "1.3805584907531738\n",
            "1.589726448059082\n",
            "1.0895472764968872\n",
            "1.5988006591796875\n",
            "1.3587034940719604\n",
            "1.6336528062820435\n",
            "1.5154731273651123\n",
            "2.008894205093384\n",
            "1.5445014238357544\n",
            "2.178219795227051\n",
            "accuracy:56.68 loss:1.6999110398581996\n",
            "epoch(14/20)\n",
            "1.6543197631835938\n",
            "1.1450273990631104\n",
            "1.7620919942855835\n",
            "1.3618838787078857\n",
            "1.320246934890747\n",
            "1.622493863105774\n",
            "1.3794881105422974\n",
            "1.1916897296905518\n",
            "1.4395389556884766\n",
            "1.744241714477539\n",
            "1.318670630455017\n",
            "1.1151214838027954\n",
            "1.6105908155441284\n",
            "1.823549747467041\n",
            "2.023367404937744\n",
            "1.9007697105407715\n",
            "accuracy:56.910000000000004 loss:1.6848845219078916\n",
            "epoch(15/20)\n",
            "1.7471328973770142\n",
            "1.265297532081604\n",
            "1.2282439470291138\n",
            "1.0500109195709229\n",
            "1.508636713027954\n",
            "1.8251947164535522\n",
            "1.3864948749542236\n",
            "1.5530781745910645\n",
            "1.2970670461654663\n",
            "1.7522052526474\n",
            "1.2220159769058228\n",
            "1.768107295036316\n",
            "1.7892000675201416\n",
            "2.0192179679870605\n",
            "1.5028003454208374\n",
            "0.9429417252540588\n",
            "accuracy:57.31 loss:1.6686706874317254\n",
            "epoch(16/20)\n",
            "1.6037639379501343\n",
            "1.3132622241973877\n",
            "1.8231000900268555\n",
            "1.4692384004592896\n",
            "1.0668818950653076\n",
            "1.4279662370681763\n",
            "1.7076656818389893\n",
            "0.9277599453926086\n",
            "1.6117298603057861\n",
            "1.3770314455032349\n",
            "1.6500389575958252\n",
            "1.6018736362457275\n",
            "1.818623423576355\n",
            "1.742618203163147\n",
            "1.9931766986846924\n",
            "1.5376176834106445\n",
            "accuracy:59.150000000000006 loss:1.5864598880560634\n",
            "epoch(17/20)\n",
            "1.6766858100891113\n",
            "1.5150902271270752\n",
            "1.668839454650879\n",
            "1.6942963600158691\n",
            "1.7465708255767822\n",
            "0.9817440509796143\n",
            "1.2628884315490723\n",
            "1.6506435871124268\n",
            "1.3911948204040527\n",
            "1.7026050090789795\n",
            "1.0226181745529175\n",
            "1.7258634567260742\n",
            "1.321455717086792\n",
            "2.2428526878356934\n",
            "1.0092523097991943\n",
            "1.7763042449951172\n",
            "accuracy:60.47 loss:1.544215509304985\n",
            "epoch(18/20)\n",
            "1.7500526905059814\n",
            "1.450964093208313\n",
            "1.048156499862671\n",
            "1.8640098571777344\n",
            "1.4312909841537476\n",
            "1.3655844926834106\n",
            "1.392220377922058\n",
            "1.6228114366531372\n",
            "1.4608137607574463\n",
            "1.6656012535095215\n",
            "1.3310242891311646\n",
            "1.671126365661621\n",
            "1.1750000715255737\n",
            "2.5368473529815674\n",
            "1.720243215560913\n",
            "1.2737126350402832\n",
            "accuracy:58.550000000000004 loss:1.5982683390474166\n",
            "epoch(19/20)\n",
            "1.789236068725586\n",
            "0.7934487462043762\n",
            "1.0928202867507935\n",
            "1.445289134979248\n",
            "0.8921941518783569\n",
            "1.4588768482208252\n",
            "1.3198051452636719\n",
            "1.2520751953125\n",
            "1.3137634992599487\n",
            "1.9183987379074097\n",
            "1.334098219871521\n",
            "1.9189503192901611\n",
            "1.3224974870681763\n",
            "1.6321851015090942\n",
            "2.102367639541626\n",
            "1.7960960865020752\n",
            "accuracy:61.44 loss:1.4734377967663848\n",
            "epoch(20/20)\n",
            "1.0385727882385254\n",
            "1.1948555707931519\n",
            "0.9283813238143921\n",
            "1.32077157497406\n",
            "1.2313741445541382\n",
            "1.1043157577514648\n",
            "1.2432475090026855\n",
            "1.5167068243026733\n",
            "1.8013081550598145\n",
            "1.3316060304641724\n",
            "0.7261907458305359\n",
            "1.621702790260315\n",
            "1.2083066701889038\n",
            "1.7957621812820435\n",
            "1.9033763408660889\n",
            "1.3156479597091675\n",
            "accuracy:60.57 loss:1.5218736144681326\n",
            "done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}