{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "nmQ5F7UAeKB_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task1\n",
        "\n",
        "빈 칸을 채워주세요!\n",
        "\n",
        "단계별 output이 github 파일에는 남아있으니 그 output과 동일한 형태인지 확인하면서 진행해주시면 됩니다~"
      ],
      "metadata": {
        "id": "Sgxd6SxmeVcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"Brick walls are there for a reason and you must not think \"\n",
        "            \"that the brick walls aren't there to keep us out, but rather \"\n",
        "            \"in this way that the brick walls are there to show us how badly we want things.\")"
      ],
      "metadata": {
        "id": "NDvUeC8BoUb6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {j : idx for idx,j in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "b9lkrKyZf8ie"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0we5Y-gYDq",
        "outputId": "68fcbffc-9ed0-4681-c67e-3a0e36f6916f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'w': 0, 'l': 1, 'k': 2, 'p': 3, 'r': 4, 't': 5, 'i': 6, 'a': 7, 'e': 8, 'm': 9, 'g': 10, 'f': 11, 'n': 12, \"'\": 13, 's': 14, 'b': 15, 'd': 16, 'B': 17, 'u': 18, '.': 19, 'c': 20, ' ': 21, ',': 22, 'h': 23, 'y': 24, 'o': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpKupU6lgpfT",
        "outputId": "b1c7addf-6b33-4160-e220-fd6a5145baab"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 10  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "wFDZJHSMg9In"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i + sequence_length]\n",
        "  y_str = sentence[i + 1 : i + sequence_length+1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbDcmJmghN7V",
        "outputId": "cfaf56d1-082b-47ac-a863-2640daa9a59e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Brick wall -> rick walls\n",
            "1 rick walls -> ick walls \n",
            "2 ick walls  -> ck walls a\n",
            "3 ck walls a -> k walls ar\n",
            "4 k walls ar ->  walls are\n",
            "5  walls are -> walls are \n",
            "6 walls are  -> alls are t\n",
            "7 alls are t -> lls are th\n",
            "8 lls are th -> ls are the\n",
            "9 ls are the -> s are ther\n",
            "10 s are ther ->  are there\n",
            "11  are there -> are there \n",
            "12 are there  -> re there f\n",
            "13 re there f -> e there fo\n",
            "14 e there fo ->  there for\n",
            "15  there for -> there for \n",
            "16 there for  -> here for a\n",
            "17 here for a -> ere for a \n",
            "18 ere for a  -> re for a r\n",
            "19 re for a r -> e for a re\n",
            "20 e for a re ->  for a rea\n",
            "21  for a rea -> for a reas\n",
            "22 for a reas -> or a reaso\n",
            "23 or a reaso -> r a reason\n",
            "24 r a reason ->  a reason \n",
            "25  a reason  -> a reason a\n",
            "26 a reason a ->  reason an\n",
            "27  reason an -> reason and\n",
            "28 reason and -> eason and \n",
            "29 eason and  -> ason and y\n",
            "30 ason and y -> son and yo\n",
            "31 son and yo -> on and you\n",
            "32 on and you -> n and you \n",
            "33 n and you  ->  and you m\n",
            "34  and you m -> and you mu\n",
            "35 and you mu -> nd you mus\n",
            "36 nd you mus -> d you must\n",
            "37 d you must ->  you must \n",
            "38  you must  -> you must n\n",
            "39 you must n -> ou must no\n",
            "40 ou must no -> u must not\n",
            "41 u must not ->  must not \n",
            "42  must not  -> must not t\n",
            "43 must not t -> ust not th\n",
            "44 ust not th -> st not thi\n",
            "45 st not thi -> t not thin\n",
            "46 t not thin ->  not think\n",
            "47  not think -> not think \n",
            "48 not think  -> ot think t\n",
            "49 ot think t -> t think th\n",
            "50 t think th ->  think tha\n",
            "51  think tha -> think that\n",
            "52 think that -> hink that \n",
            "53 hink that  -> ink that t\n",
            "54 ink that t -> nk that th\n",
            "55 nk that th -> k that the\n",
            "56 k that the ->  that the \n",
            "57  that the  -> that the b\n",
            "58 that the b -> hat the br\n",
            "59 hat the br -> at the bri\n",
            "60 at the bri -> t the bric\n",
            "61 t the bric ->  the brick\n",
            "62  the brick -> the brick \n",
            "63 the brick  -> he brick w\n",
            "64 he brick w -> e brick wa\n",
            "65 e brick wa ->  brick wal\n",
            "66  brick wal -> brick wall\n",
            "67 brick wall -> rick walls\n",
            "68 rick walls -> ick walls \n",
            "69 ick walls  -> ck walls a\n",
            "70 ck walls a -> k walls ar\n",
            "71 k walls ar ->  walls are\n",
            "72  walls are -> walls aren\n",
            "73 walls aren -> alls aren'\n",
            "74 alls aren' -> lls aren't\n",
            "75 lls aren't -> ls aren't \n",
            "76 ls aren't  -> s aren't t\n",
            "77 s aren't t ->  aren't th\n",
            "78  aren't th -> aren't the\n",
            "79 aren't the -> ren't ther\n",
            "80 ren't ther -> en't there\n",
            "81 en't there -> n't there \n",
            "82 n't there  -> 't there t\n",
            "83 't there t -> t there to\n",
            "84 t there to ->  there to \n",
            "85  there to  -> there to k\n",
            "86 there to k -> here to ke\n",
            "87 here to ke -> ere to kee\n",
            "88 ere to kee -> re to keep\n",
            "89 re to keep -> e to keep \n",
            "90 e to keep  ->  to keep u\n",
            "91  to keep u -> to keep us\n",
            "92 to keep us -> o keep us \n",
            "93 o keep us  ->  keep us o\n",
            "94  keep us o -> keep us ou\n",
            "95 keep us ou -> eep us out\n",
            "96 eep us out -> ep us out,\n",
            "97 ep us out, -> p us out, \n",
            "98 p us out,  ->  us out, b\n",
            "99  us out, b -> us out, bu\n",
            "100 us out, bu -> s out, but\n",
            "101 s out, but ->  out, but \n",
            "102  out, but  -> out, but r\n",
            "103 out, but r -> ut, but ra\n",
            "104 ut, but ra -> t, but rat\n",
            "105 t, but rat -> , but rath\n",
            "106 , but rath ->  but rathe\n",
            "107  but rathe -> but rather\n",
            "108 but rather -> ut rather \n",
            "109 ut rather  -> t rather i\n",
            "110 t rather i ->  rather in\n",
            "111  rather in -> rather in \n",
            "112 rather in  -> ather in t\n",
            "113 ather in t -> ther in th\n",
            "114 ther in th -> her in thi\n",
            "115 her in thi -> er in this\n",
            "116 er in this -> r in this \n",
            "117 r in this  ->  in this w\n",
            "118  in this w -> in this wa\n",
            "119 in this wa -> n this way\n",
            "120 n this way ->  this way \n",
            "121  this way  -> this way t\n",
            "122 this way t -> his way th\n",
            "123 his way th -> is way tha\n",
            "124 is way tha -> s way that\n",
            "125 s way that ->  way that \n",
            "126  way that  -> way that t\n",
            "127 way that t -> ay that th\n",
            "128 ay that th -> y that the\n",
            "129 y that the ->  that the \n",
            "130  that the  -> that the b\n",
            "131 that the b -> hat the br\n",
            "132 hat the br -> at the bri\n",
            "133 at the bri -> t the bric\n",
            "134 t the bric ->  the brick\n",
            "135  the brick -> the brick \n",
            "136 the brick  -> he brick w\n",
            "137 he brick w -> e brick wa\n",
            "138 e brick wa ->  brick wal\n",
            "139  brick wal -> brick wall\n",
            "140 brick wall -> rick walls\n",
            "141 rick walls -> ick walls \n",
            "142 ick walls  -> ck walls a\n",
            "143 ck walls a -> k walls ar\n",
            "144 k walls ar ->  walls are\n",
            "145  walls are -> walls are \n",
            "146 walls are  -> alls are t\n",
            "147 alls are t -> lls are th\n",
            "148 lls are th -> ls are the\n",
            "149 ls are the -> s are ther\n",
            "150 s are ther ->  are there\n",
            "151  are there -> are there \n",
            "152 are there  -> re there t\n",
            "153 re there t -> e there to\n",
            "154 e there to ->  there to \n",
            "155  there to  -> there to s\n",
            "156 there to s -> here to sh\n",
            "157 here to sh -> ere to sho\n",
            "158 ere to sho -> re to show\n",
            "159 re to show -> e to show \n",
            "160 e to show  ->  to show u\n",
            "161  to show u -> to show us\n",
            "162 to show us -> o show us \n",
            "163 o show us  ->  show us h\n",
            "164  show us h -> show us ho\n",
            "165 show us ho -> how us how\n",
            "166 how us how -> ow us how \n",
            "167 ow us how  -> w us how b\n",
            "168 w us how b ->  us how ba\n",
            "169  us how ba -> us how bad\n",
            "170 us how bad -> s how badl\n",
            "171 s how badl ->  how badly\n",
            "172  how badly -> how badly \n",
            "173 how badly  -> ow badly w\n",
            "174 ow badly w -> w badly we\n",
            "175 w badly we ->  badly we \n",
            "176  badly we  -> badly we w\n",
            "177 badly we w -> adly we wa\n",
            "178 adly we wa -> dly we wan\n",
            "179 dly we wan -> ly we want\n",
            "180 ly we want -> y we want \n",
            "181 y we want  ->  we want t\n",
            "182  we want t -> we want th\n",
            "183 we want th -> e want thi\n",
            "184 e want thi ->  want thin\n",
            "185  want thin -> want thing\n",
            "186 want thing -> ant things\n",
            "187 ant things -> nt things.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(x_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVFlILiOixdc",
        "outputId": "862e9715-7dfe-4654-c861-b3432f86f5b6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17, 4, 6, 20, 2, 21, 0, 7, 1, 1]\n",
            "[4, 6, 20, 2, 21, 0, 7, 1, 1, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.concatenate([np.eye(1,26,i[j]) for j in range(10)]) for i in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTesor 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "5lPes1dvjlNb"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMZzZlaymMk8",
        "outputId": "cb659deb-38b9-4353-8eb4-a5494249b216"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([188, 10, 26])\n",
            "레이블의 크기 : torch.Size([188, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knx1DE_AmSFB",
        "outputId": "8a8a5772-79f3-43b6-b315-8f5c3c5d5d99"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pWDiH1SmYT_",
        "outputId": "1626f020-29c1-4810-cbd6-7b9f633fd1aa"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4,  6, 20,  2, 21,  0,  7,  1,  1, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim,batch_first = True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias = True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, hidden = self.rnn(x)\n",
        "    x, hidden = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "-Ww22xu8mfUc"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "No2GRvTpnLBl"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "9-zuJLeUnQLB"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RxRaiHnh9U",
        "outputId": "9770e133-d6c9-4c3f-a1f5-24e339352a6f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([188, 10, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxrxCd2nwoo",
        "outputId": "2d6c5872-f660-4972-86f6-afb508beff1a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
            "ooooooooooooooooooooooooooooooooooooooooooooooooooooooooioooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
            "e e              eo             e                    e     e    e                      e     e            e        e       e        e    e                   eo    e  ee                        e    \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "               t     t                    t                                                t                                  t                            t     t       t      t                    \n",
            "     t     t   t     t   t t      t   t   t    t         t    t         t     t      t     t          t               t       t   t    t         t     t   t     t       t  t   t        t    t      \n",
            "     t     t   t     t   t t      t   t   t    t   th    t    th  t     t     t      th    t  t    t  t    t   t      t  t    t   th   th  t     t     t   t     t  t    t  t   t     t  t    th     \n",
            "     t t   t   th    t   t th     t   t   th   t   th    th   th  t     t t   t      th    th t    t  t    t   t      t  th   t t th   th  t     t t   t   th    th t    t  t   th    t  t t  th     \n",
            "     t t   t   th    th  thth     th  tht th   th  th    th   th  t     t t   t      th    th t    t  t    t   t      t  th   t t th   th  t     t t   t   th    th t    th t t tht   t  t t  th     \n",
            "     tht   t   th    th  thth     th  tht th   th  th    th   th  t     tht   t   t  th    th t    t  t    th  t      t  th   tht th   th  t     tht   t   th    th t    th t t tht   th t t  th     \n",
            "     tht   t   th    th  thth t   th  tht th   th  th    th t th  t     tht   t   t  th    th th   t  t    th  t      t  th t tht th t th  t     tht   t   th    th t  t th tht tht   th tht  th     \n",
            "     tht   t   th    th  thth t   th  tht th   th  th t  th t th  t     tht   t   t  th    th th   t  t    th  t      t  th t t t th t th  t     tht   t   th    th th t th tht th    th tht  th t   \n",
            "     tht   t   th    th  thth t   th  tht th   th  th t  th t the t     tht   t   t  th    th th   t  t    th  t      t  thet t   th t the t     tht   t   th    th th t t  tht th    th tht  th t   \n",
            "     tht   tr  the   th  t th t   th  tht th   th  thet  thet the t     tht   tr  t  the   th th   t  t    t   t         thet t   thet the t     tht   tr  the   th th t w  tht th    wh tht  thet   \n",
            "     tat   tr  the   th  t wh t  twh  w t th   th  thet  thet the t     thtl  tr  t  the   th th   t  t    t   t   e     thet t   thet the t     thtl  tr  the   th th t w  tht wat   wh tht  thet   \n",
            "     tatl  tre the   th  t wh t   wh  w t th   th  thet  thet the t     tatl  tre t  the   th th   t  ta   t   t t e     thet ta  thet the t     tatl  tre the   th thet w  tht wat   wh tht  thet   \n",
            "     tatls tre the   th  t wh t   wh  t t th   th  thet  thet the th    tatls tre t  the   th th   t  ta   th  tet e   a thet ta  thet the th    tatls tre the   th thet w  tht tat   wh tht  thet   \n",
            "     tatls tre the e th  thwh t   wh  t w th   th  thet  thet the to    tatls tre t  the e th th   t  ta   th  tet e   a thes tat thet the to    tatls tre the e th thet w  tet tat   wh tht  thet   \n",
            "     tatls tre the e th  thwh t   whl t w th   th  thet  theththe toe   tatls tre t  the e th th   t  ta   th  tethe   a thes tat theththe toe   tatls tre the e th thet w  tet tat t wh tot  thes   \n",
            "     talls tre the e th  thwh t   whl t w th   tht thet  theththe toe   talls tre t  the e th th   t  ta  eto  tethe e a thes tat theththe toe   talls tre the e th thet w  tet tat t wr tot  thes   \n",
            "   k talls tre the e th  thwe t   wrlst w th   tht thet  theththe toe k talls tre t  the e thrth   t  ra  eto  tethe e u thes tat theththe toe k talls tre the e thrthet w  tet tat l wr tot  thes   \n",
            " e k talls are the e th  trwe t   wrlst w th   th  thet  theththe toe k talls are t  the e thrth   t  aa   ta  rethe e u thes tat theththe toe k talls are the e thrtoet w  aet tat l wr tot  thet   \n",
            " e k talls are the e th  trwe t   wrlsk w ths  to  thetk theththe toe k talls are t  the e thrth   t  aa   ta  rethe e u thes  at theththe toe k talls are the e thrtoet ws aet tat y wr tot  thet   \n",
            " e k talls are the e to  trwe t   arlsk w tos  to  thetk theththe boe k talls are t  the e thrth   t  aa   tat rethe e ukthes  at theththe boe k talls are the e thrtoet ws  et tat y wr tot  thet   \n",
            " e k talls are the e to  trwe t   arlsk w tos  tot thetk theththe boe k talls are t  the e thrto t w  aa   tat rethe e ukthes aat theththe boe k talls are the e thrtoet ws  et talsy wr tott thetk  \n",
            " e k talls are the e tor trwe t   arlsk w tos  tot thetk theththe boe k talls are t  the e thrto t w  ha   tut rethe e ukthes aat theththe boe k talls are the e thrtoet ws  et talsy wa toll thetk  \n",
            " e k talls are the e tor  rue t   arlst w tos  tot thetk theththe boe k walls are t  the e thrte t ws ha   tut rothere ukthes aat theththe boe k walls are the e thrt et ws  et talsy wa toll thetk  \n",
            " e k talls are the e tor  rue t   arlst w tos  tot thetk theththe boe k walls are t  the e thrte t ws ha   tut rothere uuthes aat theththe boe k walls are the e thrt et ws  et tulsy wa toll thet   \n",
            " e k walls are there tor  rue t   arlst w tos  tot thetk thet the boe k walls are t  the e thrte t ws ha   tut rothere uuthes aal thet the boe k walls are there thrt et ws  et tully wa toll thet   \n",
            " e k walls are there tor  rue t   arlst w tos  tot thetk thet the boe k walls are t  the e thrte t us ha   tut rothere uuthes aal thet the boe k walls are there thrt et ws  ew tully wa toll thet   \n",
            " e k walls are there tor  rue t   arlst w tos  tot thetk thet the bre k walls are t  the e th te t us ha   tut rothere uuthes aal thet the bre k walls are there th t et ws  ew tully wa toll thet   \n",
            " eck walls are there tor  rue t   arlstow tos  tot thetk thet the breck walls are t  the e th te t us ha   but rothere uuthes aal thet the breck walls are there th t et ws  aw wully wa toll thetk  \n",
            "  ck walls are there tor  rue t   arlstow tos  tot thetk thet the brick walls are t  the e th te t us hr   but rothere nuthes ual thet the brick walls are there th t et ws aaw wully wa tolt thetk  \n",
            "  ck walls are there tor true t n arl tow tos  tot thetk thet the brick walls are t  the e th te t us hr   but rothere nuthes way thet the brick walls are there th t et ws raw wully wa tolt thetk  \n",
            "  ck walls are there tor true t n arl tow tos  tot thetk thet the brick walls are '  the e th te t us or   but rothere nkthes way thet the brick walls are there th t et ws raw wally wa tolt thetk  \n",
            "  ck walls are there ton true t n arl yow tos  tot thetk thet the brick walls are '  the e th te t us or   but rothere nkthes way thet the brick walls are there th thet ws row wally wa tolt thenk  \n",
            "  ck walls are there ton true l n arl yoa tos  tot thenk thet the brick walls are '  there th te t us ors  but rothere   thes way thet the brick walls are there th thet ws row wally wa talt thenk  \n",
            "  ck walls are there ton true l n arl yoa tos  tot thenk thet the brick walls are '  there th te t us ors  but rothere   thes way thet the brick walls are there th thet ws row wally wa tant thenk  \n",
            "  ck walls are there ton  rue t n arl yoa ,os  tot thetk thet therbrick walls are 't there th te t us ors  but rothere   thes way thet therbrick walls are there th thet us row wally wa tant thenk  \n",
            "  ck walls are there ton  rue t n arl yoa ,os  tot thetk thet therbuick walls are '  there th teet us ous  but rother    thes way thet therbuick walls are there th thet us aow wally wa tant thenk  \n",
            "  ck walls are there ton  rue t n arl yoa ,os  tot thenk thet therbuick walls are '  there th teet us ous  but rather    thes way thet therbuick walls are there th thet us aow wally wa tant thenk  \n",
            "  ck walls are there ton  rue t n arl yoa ,os  tot thenk thet therbuick walls are '  there th teet us ous  but rather    thes way thet therbuick walls are there th thot us how wally wa tant thenk  \n",
            "  ck walls are there tor  rue t n arl yoa ,os  tot thenk thet therbrick walls are '  there th teet us ous  but rather    thes way thet therbrick walls are there th thot us how wally wa tant thenk  \n",
            "  ck walls are there tor  rue t n arl yoa ,ost tot thenk thet therbrick walls are 't there th teet us ous  but rather  n thes way thet therbrick walls are there th thot us how wally wa tant thenk  \n",
            "  ck walls are there tor arue t n arl yoa ,ost tot thenk thet therbrick walls are 't there th teel us out  but rather  n thes way thet the brick walls are there th thow us how wally wa tant thenk  \n",
            "  ck walls are there tor arue t n ard yow ,ost tot thenk thet the brick walls are 't there th teep us out, but rather  n thes way thet the brick walls are there th thow us how wally wa tant thenk  \n",
            "  ck walls are there tor arue t n ard yow ,ost tot thenk that the brick walls are 't the e th teep us out, but rather  n thes way thet the brick walls are there th thow us how wally wa tant thenk  \n",
            "  ck walls are there tor a ue ton ard you ,ost tut thenk that the brick walls are 't the e th teep us out, but rather  n this way thet the brick walls are there th thow us how bally wa tant thenk  \n",
            "  ck walls are there tor a ue ton and you ,ost tut thenk that the brick walls are 't the e th teep us out, but rather  n this way thet the brick walls are there th thow us how ually wa tant thenk  \n",
            "  ck walls are there tor a ueaton and you ,ust tot thenk that the brick walls are 't there th teep us out, but rather  n this way thet the brick walls are there th thow us how bally wa want thenk  \n",
            "  ck walls are there tor a ueaton and you ,ust tot thenk that the brick walls are 't there th seep us out, but rather  n this way thet the brick walls are there th show us how bally wa want thenkt \n",
            "  ck walls are there tor a ueaton and you ,ust tot thenk that the brick walls are 't there th seep us out, but rather  n this way thet the brick walls are there th show us how bally wa want thenkt \n",
            "  ck walls are there tor a ueaton and you ,ust tot thenk that the brick walls are 't there th seep us out, but rather  n this way thet the brick walls are there th show us how bally wa want thenk  \n",
            "  ck walls are there tor a ueaton and you must tot think that the brick walls are 't there th seep us out, but rather  n this way thet the brick walls are there th show us how bally wa want think  \n",
            "  ck walls are there tor a aeason and you must tot think that the brick walls are 't there th seep us out, but rather  n this way that the brick walls are there th show us how bally wa want think  \n",
            "  ck walls are there tor a aeason and you must tot think that the brick walls are 't there th keep us out, but rather an this way that the brick walls are there to khow us how bally wa want thinkt \n",
            "  ck walls are there tor a aeason and you must tot think that the brick walls are 't there to keep us out, but rather an this way that the brick walls are there to khow us how bally wa want thinkt \n",
            "  ck walls are there tor a aeason and you must tot think that the brick walls are 't there to keep us out, but ratherean this way that the brick walls are there to khow us how badly wa want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but ratherean this way that the brick walls are there to khow us how badly wa want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but ratherean this way that the brick walls are there to khow us how badly wa want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather an this way that the brick walls are there to khow us how badly wa want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather an this way that the brick walls are there to khow us how badly wa want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather an this way that the brick walls are there to show us how badly wa want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather an this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            "  ck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " eck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " eck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " eck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " eck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " eck walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n",
            " ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8qUkbiw2t0Il",
        "outputId": "008d75a3-b966-4794-d905-b8554681e31f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" ick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkt \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과가 어떤가요?? 마지막 에폭의 문장이 그럴싸한가요?"
      ],
      "metadata": {
        "id": "PkIzDTdyvTHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task2\n",
        "\n",
        "위 sentence는 제가 임의로 생성한 문장들입니다.\n",
        "\n",
        "마음에 드시는 문구 가져오셔서 문장이 어떻게 생성되는지 확인해보세요! \n",
        "\n",
        "영어가 아닌 한국어로 시도해보는 것도 좋겠죠? \n",
        "\n",
        "수정이 많이 필요(토큰화 등) 할 수 있으나 한번 시도해보시는 것 권장드립니다 :)\n",
        "\n",
        "위 베이스라인은 어디든 수정하셔도 좋고 조금 더 자연스러운 문장이 나올 수 있게 다양한 시도를 해보세요!\n",
        "\n",
        "조건 : 문장 3개 이상, 연결성이 있는 문장을 \" \" 으로 구분하여 ( )에 넣기"
      ],
      "metadata": {
        "id": "kN1zL8Dpvane"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "sentence = (\"Anyone who stops learning is old, whether at twenty or eighty.\"\n",
        "            \"Anyone who keeps learning stays young.\" \n",
        "            \"The greatest thing in life is to keep your mind young.\")"
      ],
      "metadata": {
        "id": "IKp-lKrjvXR9"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "\n",
        "#각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {j : idx for idx,j in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "5GyfHIY82usg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD3JlN7b2zvQ",
        "outputId": "c828b783-c366-40ea-b599-507014d98fd7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'w': 0, 'l': 1, 'k': 2, 'p': 3, 'r': 4, 't': 5, 'i': 6, 'a': 7, 'e': 8, 'm': 9, 'g': 10, 'n': 11, 'f': 12, 's': 13, 'd': 14, 'u': 15, '.': 16, 'T': 17, 'A': 18, ' ': 19, ',': 20, 'h': 21, 'y': 22, 'o': 23}\n",
            "문자 집합 크기 : 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터 설정\n",
        "hidden_size = vocab_size\n",
        "sequence_length = 8\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "JBWDIK2d233l"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i + sequence_length]\n",
        "  y_str = sentence[i + 1 : i + sequence_length+1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1opVTyF29-k",
        "outputId": "537a0404-056d-44d7-c81a-dde0eac996ad"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Anyone w -> nyone wh\n",
            "1 nyone wh -> yone who\n",
            "2 yone who -> one who \n",
            "3 one who  -> ne who s\n",
            "4 ne who s -> e who st\n",
            "5 e who st ->  who sto\n",
            "6  who sto -> who stop\n",
            "7 who stop -> ho stops\n",
            "8 ho stops -> o stops \n",
            "9 o stops  ->  stops l\n",
            "10  stops l -> stops le\n",
            "11 stops le -> tops lea\n",
            "12 tops lea -> ops lear\n",
            "13 ops lear -> ps learn\n",
            "14 ps learn -> s learni\n",
            "15 s learni ->  learnin\n",
            "16  learnin -> learning\n",
            "17 learning -> earning \n",
            "18 earning  -> arning i\n",
            "19 arning i -> rning is\n",
            "20 rning is -> ning is \n",
            "21 ning is  -> ing is o\n",
            "22 ing is o -> ng is ol\n",
            "23 ng is ol -> g is old\n",
            "24 g is old ->  is old,\n",
            "25  is old, -> is old, \n",
            "26 is old,  -> s old, w\n",
            "27 s old, w ->  old, wh\n",
            "28  old, wh -> old, whe\n",
            "29 old, whe -> ld, whet\n",
            "30 ld, whet -> d, wheth\n",
            "31 d, wheth -> , whethe\n",
            "32 , whethe ->  whether\n",
            "33  whether -> whether \n",
            "34 whether  -> hether a\n",
            "35 hether a -> ether at\n",
            "36 ether at -> ther at \n",
            "37 ther at  -> her at t\n",
            "38 her at t -> er at tw\n",
            "39 er at tw -> r at twe\n",
            "40 r at twe ->  at twen\n",
            "41  at twen -> at twent\n",
            "42 at twent -> t twenty\n",
            "43 t twenty ->  twenty \n",
            "44  twenty  -> twenty o\n",
            "45 twenty o -> wenty or\n",
            "46 wenty or -> enty or \n",
            "47 enty or  -> nty or e\n",
            "48 nty or e -> ty or ei\n",
            "49 ty or ei -> y or eig\n",
            "50 y or eig ->  or eigh\n",
            "51  or eigh -> or eight\n",
            "52 or eight -> r eighty\n",
            "53 r eighty ->  eighty.\n",
            "54  eighty. -> eighty.A\n",
            "55 eighty.A -> ighty.An\n",
            "56 ighty.An -> ghty.Any\n",
            "57 ghty.Any -> hty.Anyo\n",
            "58 hty.Anyo -> ty.Anyon\n",
            "59 ty.Anyon -> y.Anyone\n",
            "60 y.Anyone -> .Anyone \n",
            "61 .Anyone  -> Anyone w\n",
            "62 Anyone w -> nyone wh\n",
            "63 nyone wh -> yone who\n",
            "64 yone who -> one who \n",
            "65 one who  -> ne who k\n",
            "66 ne who k -> e who ke\n",
            "67 e who ke ->  who kee\n",
            "68  who kee -> who keep\n",
            "69 who keep -> ho keeps\n",
            "70 ho keeps -> o keeps \n",
            "71 o keeps  ->  keeps l\n",
            "72  keeps l -> keeps le\n",
            "73 keeps le -> eeps lea\n",
            "74 eeps lea -> eps lear\n",
            "75 eps lear -> ps learn\n",
            "76 ps learn -> s learni\n",
            "77 s learni ->  learnin\n",
            "78  learnin -> learning\n",
            "79 learning -> earning \n",
            "80 earning  -> arning s\n",
            "81 arning s -> rning st\n",
            "82 rning st -> ning sta\n",
            "83 ning sta -> ing stay\n",
            "84 ing stay -> ng stays\n",
            "85 ng stays -> g stays \n",
            "86 g stays  ->  stays y\n",
            "87  stays y -> stays yo\n",
            "88 stays yo -> tays you\n",
            "89 tays you -> ays youn\n",
            "90 ays youn -> ys young\n",
            "91 ys young -> s young.\n",
            "92 s young. ->  young.T\n",
            "93  young.T -> young.Th\n",
            "94 young.Th -> oung.The\n",
            "95 oung.The -> ung.The \n",
            "96 ung.The  -> ng.The g\n",
            "97 ng.The g -> g.The gr\n",
            "98 g.The gr -> .The gre\n",
            "99 .The gre -> The grea\n",
            "100 The grea -> he great\n",
            "101 he great -> e greate\n",
            "102 e greate ->  greates\n",
            "103  greates -> greatest\n",
            "104 greatest -> reatest \n",
            "105 reatest  -> eatest t\n",
            "106 eatest t -> atest th\n",
            "107 atest th -> test thi\n",
            "108 test thi -> est thin\n",
            "109 est thin -> st thing\n",
            "110 st thing -> t thing \n",
            "111 t thing  ->  thing i\n",
            "112  thing i -> thing in\n",
            "113 thing in -> hing in \n",
            "114 hing in  -> ing in l\n",
            "115 ing in l -> ng in li\n",
            "116 ng in li -> g in lif\n",
            "117 g in lif ->  in life\n",
            "118  in life -> in life \n",
            "119 in life  -> n life i\n",
            "120 n life i ->  life is\n",
            "121  life is -> life is \n",
            "122 life is  -> ife is t\n",
            "123 ife is t -> fe is to\n",
            "124 fe is to -> e is to \n",
            "125 e is to  ->  is to k\n",
            "126  is to k -> is to ke\n",
            "127 is to ke -> s to kee\n",
            "128 s to kee ->  to keep\n",
            "129  to keep -> to keep \n",
            "130 to keep  -> o keep y\n",
            "131 o keep y ->  keep yo\n",
            "132  keep yo -> keep you\n",
            "133 keep you -> eep your\n",
            "134 eep your -> ep your \n",
            "135 ep your  -> p your m\n",
            "136 p your m ->  your mi\n",
            "137  your mi -> your min\n",
            "138 your min -> our mind\n",
            "139 our mind -> ur mind \n",
            "140 ur mind  -> r mind y\n",
            "141 r mind y ->  mind yo\n",
            "142  mind yo -> mind you\n",
            "143 mind you -> ind youn\n",
            "144 ind youn -> nd young\n",
            "145 nd young -> d young.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "x_one_hot = [np.concatenate([np.eye(1,24,i[j]) for j in range(8)]) for i in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "metadata": {
        "id": "mx06irAu3BaR"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIXDzReg3E_f",
        "outputId": "83851a2f-c4b2-484b-805a-9b647ea560c0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([146, 8, 24])\n",
            "레이블의 크기 : torch.Size([146, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26HVGpUs3LNc",
        "outputId": "7aca3b3d-31a7-4486-f540-1a258b3bcb78"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44bACLR53NaH",
        "outputId": "a2ef27e0-bed7-4bc4-e4d6-f248fd907847"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 22, 23, 11,  8, 19,  0, 21])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim,batch_first = True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias = True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, hidden = self.rnn(x)\n",
        "    x, hidden = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "YCR0Eclm3PCK"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "xi7cBoY33RgT"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "Jtal5Q203TIB"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDMezJG03UDa",
        "outputId": "673d9c2d-63db-41ca-ec7d-d534224d9144"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([146, 8, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A51G7UZl3VCC",
        "outputId": "23538b7f-5293-417a-cdbd-91b013c19b27"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mmuumuuAmyuAmyuummuuumuummuumAummuAmmummuumummAuuAmuAumuummmuuuuAumuuAmyuAusaummuuumuummAmmuummumummummummuummummmmmummuukmuuuumummmuAusmuAumumuuukumsmum\n",
            "ssssssusssusssussAsssuussuussssssuAsssssauuusssssssussuusssssssussssusssuAssssuusssuussuussusuyssussussussssssusuassussuusuusssuussssAsssuysssuusssusssus\n",
            "sssssssssssssssss ssssssssssssssssssssssss ssssssssssssssssssssssssssssssssssss ssssssssss sssssssssssssssssssssssssssssss sssssssssssssssssss ssssssssss\n",
            "ss ss s s s s s        s   s   s   s ssss      ss  s    sss ssss ss s s s  s         s   s s s sss s s s   ss ss   ss s s   s s     s  s   ss   sss  sss \n",
            "s                                                                                                                                                        \n",
            "                                                                                                                                                         \n",
            "                                                                                                                                                         \n",
            "                                                                                                                                                         \n",
            "                                                                                                                                                         \n",
            "                                                                                                                                                         \n",
            "                                                                                                                                                         \n",
            "                                                                                                                                                         \n",
            "                       e                                                             e                                  e                        e       \n",
            "          n            e i         e            e                 e     n            e i   n                        e   e   e                    e       \n",
            "    e   e e            e i         e            e                 e   e e     i      e i   n     e   e            e e i e i e i                  e i     \n",
            "    e e e e     i      e i e       e     e      e     i    o      e e e e     i e    e i   n e   e e e            e e i e i e i           o   i  e i     \n",
            "    e i e e i   i e  i g i e i   i e   i e o i  e     i   ioe ii  e i e e     i e  i g i   i e   e e e          e e e i g i e i e         o   i  e i     \n",
            " e  e i e e i n i e  i g i e i   i e   i e o i  e     i   ioe ii  e i e e     i e  i g i e i e   e e e n i    n e e e i g i e i e i       o   io e i   i \n",
            " e  e i e e i n i    i g i e o   i e   i e o i  e o   i   ioe ii  e i e e     i   ii g i e i e   e e e n i    n e e e i g i e i e i i     o   io e i   i \n",
            " e  e i e e i n i    i g i e o   i e   i e o i ne o   i   ioe ii  e i e e     i    i g i   i e   e e e e i    n   e e i g i e i e i i     o   io e i     \n",
            " e ne i e e i n i    i g i e o   i e   i   o i ne oo  i   io  ii  e i e e     i    i g i   i i n e e e e i    n e e e i g i e i e i i     o   io e i   e \n",
            " e ne i e e i n i    i g i e o   i e      io i ne io  i   io   i  e i e e     i    i g i e n i n e e e e i    n e e e i g i e i e o       o   ii e io  e \n",
            " e ne i e e i n i    i g i eio   i e e o  io i ne io  io  ioe  i ne i e e     i    i g i e n i n e e e e i    n i e e i e i e i eio e     o   iine io  e \n",
            " e ne i e e i n i n  ing i eioe  i e e o  io i ne io  io  ioe  ione e e e     i    ing i e n i n e e e e i    n i ene ioe ioe i eio e     o   iine io  e \n",
            " e ne e e e i n ion  ing ioeioe  e e g n  in iene io  ion ioe  yone e e e     ioe  ing i e n ion e e e g i    n i eng ioe ioe i eio e    yo   iine io  e \n",
            " e ng e e g o n ion  ing ioeioe  e e g n  ie iene io  ion ioe  yone e e g     ioa  ing i e n ion e e e g i    n i eng ioeyioe ioeio s e  yon  iine io  e \n",
            " e ng ehe g o n ioa  ing ioeioe  ehe g n  ie iene io  iou ioer yong ehe g     ioa  ing i e n iou e e e g io   n i eng ioeyioe ioeio s e  your iing iou e \n",
            " e ng ehe g o n ioa  ing ioeioe  ehe g n  ie iene io  iou iour youg ehe g     ioa  ing i e n iou e e e g ia   n iheng ioeyioe ineio s e  your iing ioure \n",
            " e ng ehe s o n ioa  ing ioeioe  ehe g n  ie iene io  iou iour youg ehe s e   ioa  ing ioe n ioure e e g ia   n iheng ioeyioe ineio s e  your iing ioure \n",
            " eong ehe s o n iea  ing ioeiog  ihe g n  ie iene io  iou iour youg ghe s e   ioa  ing ioe n ioure e e g ia   n iheng ioeyin  ineio see  your iing ioure \n",
            " eong ghe s o n iea  ing ioeiogr ihe g n yie iene in  iou iour youg ghe s e   ioa  ing ioe n ioung ene g ian  n iheng ineyin  ineio see  youn iing ioure \n",
            " iong ghe s o n iea  ing io iogr ihe g n yie iene in  iop iouu youg ghe s e   iea  ing i e n ioung ene g tan  n iheng ineyin  ineii see  youn iing ioung \n",
            " iong whe s o n iea  ing io iogr ihe n n yie iene io  iop i nu yone whe s e n iea  ing i e n ioung ine g tan  n iheng ineyis  in ii see  youn yiog ioung \n",
            " iong whe s o n iea  ing io iogr whe nen yietiene io  iop i nu yone whe s e n iea  ing i e n ioung ine g t n  n iheng ineyis  in ii see nyoun yiog ioung \n",
            " iong whe k o n iea  ing io iog, whe nen yietiene io  iop i  u yone whe kee n iea  ing i e s ioung Tne k t n  n iheng ineyis  in io see nyoun yiog ioung \n",
            " iong whe k o n iea  ing io iog, whe gen ytetiene il  iop i  u youe whe kee n iea  ing i a s ioung T e k t n  n iheng ineyis  in io see nyoun yiog ioung \n",
            "tiong whe k o n iea  ing is iog, whe gen ktetiene il  iop e  u youe whe kee n iea  ing itats young T e k tan  n iheng ineyis  in io see nyoun yiog ioung \n",
            "tiong who k o n iea  ing is iog, whe gen ktetiene ol  iop ey u youe who kee n iea  ing itats young T e k tane n iheng ineyis  in io kee nyoun yiog young \n",
            "tiong who k o n lea  ing is iog, whe gen ktetiene ol  iop ey u youe who kee n iea  ing itats young T e k tane n iheng iseyis  in io kee nyoun yiog young \n",
            "tione who kto n lea  ing is ioe, whe geo ktetieneytl  iop ey u youe who kee n iea  ing it ts young T e k tane n iheng ineyis  in io kee nyoun ying young \n",
            "tione who kto n lea  ing is ioe, whe neo ktetieneytl  ion ey A youe who kee n iea  ing it ts young The k tane n iheng ineyis  in io see nyoun ying young \n",
            "tione who kto n lea ning is ioe, whe net ktetieneytl  ion ey A youe who keepn iearning it ts young The k tane n iheng ineyis  in io seepnyoun ying young \n",
            "tione who ktonn lea ning is ioe, whe net ktetieneytl  iop ey A youe who keepn iearning itats young The k tane n iheng ineyis  in lo seepnyoun ying young \n",
            "tione who ktonn lea ning is iod, whe net ktetieneytl  iog ey A youe who keepn iearning itats young The g tane n iheng ineyis  in lo seepnyoun ying young \n",
            "nione who ktopn lea ning is iod, whe het ktetieneytl  iog ey A youe who keepn learning itats young The g tate t iheng iseyis  in lo seepnyoun ying young \n",
            "nioue who ktopn lea ning is lod, whe het itetieneytl  iog ey A youe who keepn learning itats young The g tate t iheng iseyis  in lo seepnyoun ying young \n",
            "nione who ktopn lea ning is lsd, whe het itetieneytlr eog ey A youe who keepn learning itats young The g tate t theng iseyise in lo keepnyoun ying young \n",
            "nione who ktopn learning is lsd, whe het itetieneytlr eog ey Anyone who keepn learning itats young The g tate t theng iseyise in lo keepnyoun ying young \n",
            "nione who stopn learning is lsd, whe het itetieney lr aig ey Anyone who seepn learning itats young The greate t theng iseyise in lo keepsyour ying young \n",
            "nione who stopn learning is lsd, whe het atetieney lr aig ey Anyone who seepn learning itats young The greate t theng iseyise in lo keepsyour ying young \n",
            "nione who stopn learning is lsd, whe het atetieney or aig ey Anyone who seepn learning itats young The greate t theng iseyise in lo keepsyour ying young \n",
            "nione who stopn learning is lsd, whe het atetieney or aig ey Anyone who seepn learning itats young The greate t theng iseyise in lo seepsyour ying young.\n",
            "nione who stopn learning is lsd, whe het at tieney or aighty Anyone who seepn learning itats young.The greate t theng iseyise in to keepsyour aing young.\n",
            "nione who stops learning is tld, whe het at tieney or eighty Anyone who seepn learning itats young.The greate t thing iseyise in to keepsyour aing young.\n",
            "nione who stops learning is tld, whe het at tieney or eighty Anyone who seeps learning itats young.The greate t thing iseyife is to keepsyour aing young.\n",
            "nione who stops learning is tld, whe het at tieney or eighty Anyone who seeps learning itats young.The greate t thing iselife is to keepsyour aing young.\n",
            "nione who stops learning is tld, whe het at tieney or eighty Anyone who seeps learning itats young.The greate t thing iselife is to keepsyour aing young.\n",
            "nyone who stops learning is tld, whe het at tieney or eighty Anyone who seeps learning itats young.The greateat thing iselife is to keepsyour aing young.\n",
            "nyone who stops learning is tld, whethet at tieney or eighty Anyone who seeps learning itats young.The greateat thing iselife is to keepsyour ming young.\n",
            "nyone who stops learning is tld, whethet at tieney or eighty Anyone who seeps learning itats young.The greateat thing inelife is to keepsyour ming young.\n",
            "nyone who stops learning is tld, whethet at tieney or eighty Anyone who seeps learning itats young.The greateat thing inelife is to keepsyour ming young.\n",
            "nyone who stops learning is tld, whethet at tieney or eighty Anyone who seeps learning itats young.The greateat thing inelife is to keepsyour ming young.\n",
            "nyone who stops learning is tld, whether at tweney or eighty Anyone who seeps learning itats young.The greateat thing inelife is to keepsyour ming young.\n",
            "nyone who stops learning is tld, whether at tweney or eighty Anyone who seeps learning itats young.The greateat thing inelife is to keepsyour ming young.\n",
            "nyone who stops learning is tld, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is tld, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning ss old, whether at tweney or eighty.Anyone who seeps learning stats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at tweney or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itats young.The greateat thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your ming young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n",
            "nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_sBNI0z-3WHU",
        "outputId": "2bcd2310-8abb-4410-cc50-52a587759a22"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nyone who stops learning is old, whether at twenty or eighty.Anyone who seeps learning itays young.The greatest thing in life is to keep your mind young.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ]
}